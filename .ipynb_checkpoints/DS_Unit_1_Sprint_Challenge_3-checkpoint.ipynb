{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NooAiTdnafkz"
   },
   "source": [
    "# Data Science Unit 1 Sprint Challenge 3\n",
    "\n",
    "## Exploring Data, Testing Hypotheses\n",
    "\n",
    "In this sprint challenge you will look at a dataset of people being approved or rejected for credit.\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Credit+Approval\n",
    "\n",
    "Data Set Information: This file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data. This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values. There are also a few missing values.\n",
    "\n",
    "Attribute Information:\n",
    "- A1: b, a.\n",
    "- A2: continuous.\n",
    "- A3: continuous.\n",
    "- A4: u, y, l, t.\n",
    "- A5: g, p, gg.\n",
    "- A6: c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n",
    "- A7: v, h, bb, j, n, z, dd, ff, o.\n",
    "- A8: continuous.\n",
    "- A9: t, f.\n",
    "- A10: t, f.\n",
    "- A11: continuous.\n",
    "- A12: t, f.\n",
    "- A13: g, p, s.\n",
    "- A14: continuous.\n",
    "- A15: continuous.\n",
    "- A16: +,- (class attribute)\n",
    "\n",
    "Yes, most of that doesn't mean anything. A16 (the class attribute) is the most interesting, as it separates the 307 approved cases from the 383 rejected cases. The remaining variables have been obfuscated for privacy - a challenge you may have to deal with in your data science career.\n",
    "\n",
    "Sprint challenges are evaluated based on satisfactory completion of each part. It is suggested you work through it in order, getting each aspect reasonably working, before trying to deeply explore, iterate, or refine any given step. Once you get to the end, if you want to go back and improve things, go for it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5wch6ksCbJtZ"
   },
   "source": [
    "## Part 1 - Load and validate the data\n",
    "\n",
    "- Load the data as a `pandas` data frame.\n",
    "- Validate that it has the appropriate number of observations (you can check the raw file, and also read the dataset description from UCI).\n",
    "- UCI says there should be missing data - check, and if necessary change the data so pandas recognizes it as na\n",
    "- Make sure that the loaded features are of the types described above (continuous values should be treated as float), and correct as necessary\n",
    "\n",
    "This is review, but skills that you'll use at the start of any data exploration. Further, you may have to do some investigation to figure out which file to load from - that is part of the puzzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q79xDLckzibS"
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "link = \"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "from snippets import files\n",
    "\n",
    "# Localize the data\n",
    "filename = files.DownloadFile(link, 'creditapproval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column-names:  ['A1', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12', 'A13', 'A14', 'A15', 'A16']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>30.83</td>\n",
       "      <td>0.000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.25</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00202</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>58.67</td>\n",
       "      <td>4.460</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>3.04</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00043</td>\n",
       "      <td>560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>24.50</td>\n",
       "      <td>0.500</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>1.50</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>00280</td>\n",
       "      <td>824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>27.83</td>\n",
       "      <td>1.540</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>3.75</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>00100</td>\n",
       "      <td>3</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>20.17</td>\n",
       "      <td>5.625</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>1.71</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>00120</td>\n",
       "      <td>0</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 A16\n",
       "0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0   +\n",
       "1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560   +\n",
       "2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824   +\n",
       "3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3   +\n",
       "4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0   +"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data into memory\n",
    "import pandas as pd\n",
    "columns = ['A'+str(x) for x in range(1,17)]\n",
    "print('column-names: ', columns)\n",
    "df = pd.read_csv('creditapproval.data', header=None, names=columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_d = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tf_col = ['A9', 'A10', 'A12']\n",
    "def encode_tf(x):\n",
    "    if x == 't':\n",
    "        return True\n",
    "    elif x == 'f':\n",
    "        return False\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "for col in tf_col:\n",
    "    clean_d[col] = clean_d[col].apply(encode_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "placeholder = clean_d['A1'].unique()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1     12\n",
       "A2     12\n",
       "A3      0\n",
       "A4      6\n",
       "A5      6\n",
       "A6      9\n",
       "A7      9\n",
       "A8      0\n",
       "A9      0\n",
       "A10     0\n",
       "A11     0\n",
       "A12     0\n",
       "A13     0\n",
       "A14    13\n",
       "A15     0\n",
       "A16     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_d = clean_d.replace(placeholder, np.nan)\n",
    "# Correct number of missing instances - matches with information file crx.\n",
    "clean_d.isna().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1      object\n",
       "A2     float64\n",
       "A3     float64\n",
       "A4      object\n",
       "A5      object\n",
       "A6      object\n",
       "A7      object\n",
       "A8     float64\n",
       "A9        bool\n",
       "A10       bool\n",
       "A11    float64\n",
       "A12       bool\n",
       "A13     object\n",
       "A14    float64\n",
       "A15    float64\n",
       "A16     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change all continuous data to float\n",
    "cont_var = ['A2', 'A3', 'A11', 'A14', 'A15']\n",
    "for col in cont_var:\n",
    "    clean_d[col] = clean_d[col].astype(float)\n",
    "clean_d.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G7rLytbrO38L"
   },
   "source": [
    "## Part 2 - Exploring data, Testing hypotheses\n",
    "\n",
    "The only thing we really know about this data is that A16 is the class label. Besides that, we have 6 continuous (float) features and 9 categorical features.\n",
    "\n",
    "Explore the data: you can use whatever approach (tables, utility functions, visualizations) to get an impression of the distributions and relationships of the variables. In general, your goal is to understand how the features are different when grouped by the two class labels (`+` and `-`).\n",
    "\n",
    "For the 6 continuous features, how are they different when split between the two class labels? Choose two features to run t-tests (again split by class label) - specifically, select one feature that is *extremely* different between the classes, and another feature that is notably less different (though perhaps still \"statistically significantly\" different). You may have to explore more than two features to do this.\n",
    "\n",
    "For the categorical features, explore by creating \"cross tabs\" (aka [contingency tables](https://en.wikipedia.org/wiki/Contingency_table)) between them and the class label, and apply the Chi-squared test to them. [pandas.crosstab](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html) can create contingency tables, and [scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) can calculate the Chi-squared statistic for them.\n",
    "\n",
    "There are 9 categorical features - as with the t-test, try to find one where the Chi-squared test returns an extreme result (rejecting the null that the data are independent), and one where it is less extreme.\n",
    "\n",
    "**NOTE** - \"less extreme\" just means smaller test statistic/larger p-value. Even the least extreme differences may be strongly statistically significant.\n",
    "\n",
    "Your *main* goal is the hypothesis tests, so don't spend too much time on the exploration/visualization piece. That is just a means to an end - use simple visualizations, such as boxplots or a scatter matrix (both built in to pandas), to get a feel for the overall distribution of the variables.\n",
    "\n",
    "This is challenging, so manage your time and aim for a baseline of at least running two t-tests and two Chi-squared tests before polishing. And don't forget to answer the questions in part 3, even if your results in this part aren't what you want them to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_nqcgc0yzm68"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A16</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+</th>\n",
       "      <td>33.720492</td>\n",
       "      <td>5.904951</td>\n",
       "      <td>3.427899</td>\n",
       "      <td>0.925081</td>\n",
       "      <td>0.680782</td>\n",
       "      <td>4.605863</td>\n",
       "      <td>0.475570</td>\n",
       "      <td>164.421927</td>\n",
       "      <td>2038.859935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>29.808231</td>\n",
       "      <td>3.839948</td>\n",
       "      <td>1.257924</td>\n",
       "      <td>0.201044</td>\n",
       "      <td>0.224543</td>\n",
       "      <td>0.631854</td>\n",
       "      <td>0.443864</td>\n",
       "      <td>199.699468</td>\n",
       "      <td>198.605744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            A2        A3        A8        A9       A10       A11       A12  \\\n",
       "A16                                                                          \n",
       "+    33.720492  5.904951  3.427899  0.925081  0.680782  4.605863  0.475570   \n",
       "-    29.808231  3.839948  1.257924  0.201044  0.224543  0.631854  0.443864   \n",
       "\n",
       "            A14          A15  \n",
       "A16                           \n",
       "+    164.421927  2038.859935  \n",
       "-    199.699468   198.605744  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for significant differences in means across numerical categories\n",
    "grouped_df = clean_d.groupby('A16').mean()\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percent differ\n",
    "def sort_spread(df):\n",
    "    cols = df.columns\n",
    "    slist = []\n",
    "    for col in cols:\n",
    "        slist.append((col, df[col].min()/df[col].max()))\n",
    "    def getkey(item):\n",
    "        return item[1]\n",
    "    return sorted(slist, key=getkey)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A15', 0.09741019514398606),\n",
       " ('A11', 0.1371846621439466),\n",
       " ('A9', 0.21732615011216122),\n",
       " ('A10', 0.3298312241558085),\n",
       " ('A8', 0.36696655111980236),\n",
       " ('A3', 0.6502928965194601),\n",
       " ('A14', 0.823346844570597),\n",
       " ('A2', 0.883979709931288),\n",
       " ('A12', 0.9333309488894452)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_spread(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It appears that A15 and A11 are good candidates for means testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=11.667004222431277, pvalue=7.957718568079967e-29) \n",
      "\n",
      "Ttest_indResult(statistic=4.680216020964486, pvalue=3.4520256956287944e-06) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "def t_class(data, col):\n",
    "    filter_a = data['A16'] == '+'\n",
    "    filter_b = data['A16'] == '-'\n",
    "    \n",
    "    a = data[filter_a][col]\n",
    "    b = data[filter_b][col]\n",
    "    \n",
    "    return stats.ttest_ind(a, b, nan_policy='omit')\n",
    "\n",
    "# Test 1, A11\n",
    "print(t_class(clean_d, 'A11'), '\\n')\n",
    "# Test 2, A15\n",
    "print(t_class(clean_d, 'A15'), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categoricals, let's pull all of those variables first\n",
    "cat_d = clean_d.select_dtypes(include=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Produce histograms of the data\n",
    "import matplotlib.pyplot as plt\n",
    "cat_d = cat_d.dropna(how='any')\n",
    "\n",
    "num_graph = len(cat_d.columns)-1\n",
    "filter_a = cat_d['A16'] == '+'\n",
    "filter_b = cat_d['A16'] == '-'\n",
    "\n",
    "fig, ax = plt.subplots(num_graph, 2)\n",
    "\n",
    "for count, col in enumerate(cat_d.columns[0:num_graph]):\n",
    "    ax[count,0].hist(cat_d[filter_a][col])\n",
    "    ax[count,1].hist(cat_d[filter_b][col])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A1', 'A4', 'A5', 'A6', 'A7', 'A13', 'A16'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_d.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So!  Plotting is quite computationally intensive.  Multi-threaded plotting is definitely something to look into.**\n",
    "\n",
    "**In looking at these, I wish I could have heat-mapped the difference in their histograms.  It looks like the last two pair (A7, A13) are good candidates for further analysis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>A7</th>\n",
       "      <th>bb</th>\n",
       "      <th>dd</th>\n",
       "      <th>ff</th>\n",
       "      <th>h</th>\n",
       "      <th>j</th>\n",
       "      <th>n</th>\n",
       "      <th>o</th>\n",
       "      <th>v</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A16</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>167</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "A7   bb  dd  ff   h  j  n  o    v  z\n",
       "A16                                 \n",
       "+    24   2   8  87  3  2  1  167  6\n",
       "-    33   4  49  50  5  2  1  225  2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the crosstabs of those variables\n",
    "# A7\n",
    "pd.crosstab(cat_d['A16'], cat_d['A7'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>A13</th>\n",
       "      <th>g</th>\n",
       "      <th>p</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A16</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+</th>\n",
       "      <td>284</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-</th>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "A13    g  p   s\n",
       "A16            \n",
       "+    284  1  15\n",
       "-    330  1  40"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A13\n",
    "pd.crosstab(cat_d['A16'], cat_d['A13'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167  87  24   8   6   3   2   2   1]\n",
      "[225  50  49  33   5   4   2   2   1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=74.47560709132138, pvalue=6.281460618677129e-13)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the chi2 values & chi2 contingency table\n",
    "\n",
    "# A7\n",
    "a = cat_d[filter_a]['A7'].value_counts().values\n",
    "\n",
    "b = cat_d[filter_b]['A7'].value_counts().values\n",
    "print(a)\n",
    "print(b)\n",
    "stats.chisquare(a, f_exp=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[284  15   1]\n",
      "[330  40   1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=22.037121212121214, pvalue=1.6394566220386258e-05)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A11\n",
    "a = cat_d[filter_a]['A13'].value_counts().values\n",
    "\n",
    "b = cat_d[filter_b]['A13'].value_counts().values\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "stats.chisquare(a, f_exp=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZM8JckA2bgnp"
   },
   "source": [
    "## Part 3 - Analysis and Interpretation\n",
    "\n",
    "Now that you've looked at the data, answer the following questions:\n",
    "\n",
    "- Interpret and explain the two t-tests you ran - what do they tell you about the relationships between the continuous features you selected and the class labels?\n",
    "- Interpret and explain the two Chi-squared tests you ran - what do they tell you about the relationships between the categorical features you selected and the class labels?\n",
    "- What was the most challenging part of this sprint challenge?\n",
    "\n",
    "Answer with text, but feel free to intersperse example code/results or refer to it from earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LIozLDNG2Uhu"
   },
   "source": [
    "# *Your words here!*\n",
    "**Interpreting ttest_ind (difference in means)**\n",
    "\n",
    "The ttests show significant difference in class means for both categories A11 and A15.  Their 1-pvalue yields the confidence from our given statistic, which in both cases is >99%.\n",
    "\n",
    "**Interpreting Chi2 (difference in frequency distribution)**\n",
    "\n",
    "Chi2 testing is a very powerful technique to get approximate quanitification of differences in distributions of categorical data where means testing is unavailable (data can not be encoded into meaningful, ordinal, space).  \n",
    "\n",
    "In both instances, the Chi2 test yielded significant differences (>99% confidence that distributions differ).  This is backed up by the visualization of paired histograms.\n",
    "\n",
    "## Some Interesting Findings, Difficulties ##\n",
    "The most difficult part was syntax.  Cleaning data was not 'hard' per se, but did require a lot of discovery - re-encoding variables and using unique-finding to identify the dataset's proxy for missing values, then applying the replace for analysis, and proper functioning of Pandas functions.  I find it interesting that None/NaN are not more common to the datasets in question.  I think it would be useful for dataset authors to identify the unicode replacement for NA values.\n",
    "\n",
    "Interestingly, the chi2 is a reasonable way to quantify the difference manually observed in historgram differences.  The difference in distribution is tested with the chi2.  In future analysis, it will be important to be able to get around the computational difficulty of visualization or using pd.sample() and plotting mean of means might be more efficient for ealy exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DS_Unit_1_Sprint_Challenge_3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
