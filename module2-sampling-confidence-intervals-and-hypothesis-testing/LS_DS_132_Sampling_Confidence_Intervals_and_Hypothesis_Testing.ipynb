{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_132_Sampling_Confidence_Intervals_and_Hypothesis_Testing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElisabethShah/DS-Unit-1-Sprint-3-Statistical-Tests-and-Experiments/blob/master/module2-sampling-confidence-intervals-and-hypothesis-testing/LS_DS_132_Sampling_Confidence_Intervals_and_Hypothesis_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "838Dmw1kM2LK",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science Module 132\n",
        "## Sampling, Confidence Intervals, and Hypothesis Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbcPKIo5M6Ny",
        "colab_type": "text"
      },
      "source": [
        "## Prepare - examine other available hypothesis tests\n",
        "\n",
        "If you had to pick a single hypothesis test in your toolbox, t-test would probably be the best choice - but the good news is you don't have to pick just one! Here's some of the others to be aware of:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlBel8j9M6tB",
        "colab_type": "code",
        "outputId": "b0666a50-a349-4d37-b677-df6f7af3b085",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chisquare  # One-way chi square test\n",
        "\n",
        "# Chi square can take any crosstab/table and test the independence of rows/cols\n",
        "# The null hypothesis is that the rows/cols are independent -> low chi square\n",
        "# The alternative is that there is a dependence -> high chi square\n",
        "# Be aware! Chi square does *not* tell you direction/causation\n",
        "\n",
        "ind_obs = np.array([[1, 1], [2, 2]]).T\n",
        "print(ind_obs)\n",
        "print(chisquare(ind_obs, axis=None))\n",
        "\n",
        "dep_obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T\n",
        "print(dep_obs)\n",
        "print(chisquare(dep_obs, axis=None))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [1 2]]\n",
            "Power_divergenceResult(statistic=0.6666666666666666, pvalue=0.8810148425137847)\n",
            "[[16 32]\n",
            " [18 24]\n",
            " [16 16]\n",
            " [14 28]\n",
            " [12 20]\n",
            " [12 24]]\n",
            "Power_divergenceResult(statistic=23.31034482758621, pvalue=0.015975692534127565)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN0BdNiDPxbk",
        "colab_type": "code",
        "outputId": "2cecdb2d-2774-47f0-d0d5-436ea431f9ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Distribution tests:\n",
        "# We often assume that something is normal, but it can be important to *check*\n",
        "\n",
        "# For example, later on with predictive modeling, a typical assumption is that\n",
        "# residuals (prediction errors) are normal - checking is a good diagnostic\n",
        "\n",
        "from scipy.stats import normaltest\n",
        "# Poisson models arrival times and is related to the binomial (coinflip)\n",
        "sample = np.random.poisson(5, 1000)\n",
        "print(normaltest(sample))  # Pretty clearly not normal"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NormaltestResult(statistic=40.0270084408004, pvalue=2.033506446573421e-09)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5t0WhkDReFO",
        "colab_type": "code",
        "outputId": "016f4654-e935-40a2-e832-821e0ca7fb92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Kruskal-Wallis H-test - compare the median rank between 2+ groups\n",
        "# Can be applied to ranking decisions/outcomes/recommendations\n",
        "# The underlying math comes from chi-square distribution, and is best for n>5\n",
        "from scipy.stats import kruskal\n",
        "\n",
        "x1 = [1, 3, 5, 7, 9]\n",
        "y1 = [2, 4, 6, 8, 10]\n",
        "print(kruskal(x1, y1))  # x1 is a little better, but not \"significantly\" so\n",
        "\n",
        "x2 = [1, 1, 1]\n",
        "y2 = [2, 2, 2]\n",
        "z = [2, 2]  # Hey, a third group, and of different size!\n",
        "print(kruskal(x2, y2, z))  # x clearly dominates"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KruskalResult(statistic=0.2727272727272734, pvalue=0.6015081344405895)\n",
            "KruskalResult(statistic=7.0, pvalue=0.0301973834223185)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pT3IP36Rh0b",
        "colab_type": "text"
      },
      "source": [
        "And there's many more! `scipy.stats` is fairly comprehensive, though there are even more available if you delve into the extended world of statistics packages. As tests get increasingly obscure and specialized, the importance of knowing them by heart becomes small - but being able to look them up and figure them out when they *are* relevant is still important."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1_KRuHCM7BW",
        "colab_type": "text"
      },
      "source": [
        "## Live Lecture - let's explore some more of scipy.stats\n",
        "\n",
        "Candidate topics to explore:\n",
        "\n",
        "- `scipy.stats.chi2` - the Chi-squared distribution, which we can use to reproduce the Chi-squared test\n",
        "- Calculate the Chi-Squared test statistic \"by hand\" (with code), and feed it into `chi2`\n",
        "- Build a confidence interval with `stats.t.ppf`, the t-distribution percentile point function (the inverse of the CDF) - we can write a function to return a tuple of `(mean, lower bound, upper bound)` that you can then use for the assignment (visualizing confidence intervals)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qW6k0dorM7Lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Taking requests! Come to lecture with a topic or problem and we'll try it."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11OzdxWTM7UR",
        "colab_type": "text"
      },
      "source": [
        "## Assignment - Build a confidence interval\n",
        "\n",
        "A confidence interval refers to a neighborhood around some point estimate, the size of which is determined by the desired p-value. For instance, we might say that 52% of Americans prefer tacos to burritos, with a 95% confidence interval of +/- 5%.\n",
        "\n",
        "52% (0.52) is the point estimate, and +/- 5% (the interval $[0.47, 0.57]$) is the confidence interval. \"95% confidence\" means a p-value $\\leq 1 - 0.95 = 0.05$.\n",
        "\n",
        "In this case, the confidence interval includes $0.5$ - which is the natural null hypothesis (that half of Americans prefer tacos and half burritos, thus there is no clear favorite). So in this case, we could use the confidence interval to report that we've failed to reject the null hypothesis.\n",
        "\n",
        "But providing the full analysis with a confidence interval, including a graphical representation of it, can be a helpful and powerful way to tell your story. Done well, it is also more intuitive to a layperson than simply saying \"fail to reject the null hypothesis\" - it shows that in fact the data does *not* give a single clear result (the point estimate) but a whole range of possibilities.\n",
        "\n",
        "How is a confidence interval built, and how should it be interpreted? It does *not* mean that 95% of the data lies in that interval - instead, the frequentist interpretation is \"if we were to repeat this experiment 100 times, we would expect the average result to lie in this interval ~95 times.\"\n",
        "\n",
        "For a 95% confidence interval and a normal(-ish) distribution, you can simply remember that +/-2 standard deviations contains 95% of the probability mass, and so the 95% confidence interval based on a given sample is centered at the mean (point estimate) and has a range of +/- 2 (or technically 1.96) standard deviations.\n",
        "\n",
        "Different distributions/assumptions (90% confidence, 99% confidence) will require different math, but the overall process and interpretation (with a frequentist approach) will be the same.\n",
        "\n",
        "Your assignment - using the data from the prior module ([congressional voting records](https://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records)):\n",
        "\n",
        "1. Generate and numerically represent a confidence interval\n",
        "2. Graphically (with a plot) represent the confidence interval\n",
        "3. Interpret the confidence interval - what does it tell you about the data and its distribution?\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "1. Write a summary of your findings, mixing prose and math/code/results. *Note* - yes, this is by definition a political topic. It is challenging but important to keep your writing voice *neutral* and stick to the facts of the data. Data science often involves considering controversial issues, so it's important to be sensitive about them (especially if you want to publish).\n",
        "2. Apply the techniques you learned today to your project data or other data of your choice, and write/discuss your findings here.\n",
        "3. Refactor your code so it is elegant, readable, and can be easily run for all issues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckcr4A4FM7cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO - your code!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyJ3ySr7R2k9",
        "colab_type": "text"
      },
      "source": [
        "## Resources\n",
        "\n",
        "- [Interactive visualize the Chi-Squared test](https://homepage.divms.uiowa.edu/~mbognar/applets/chisq.html)\n",
        "- [Calculation of Chi-Squared test statistic](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)\n",
        "- [Visualization of a confidence interval generated by R code](https://commons.wikimedia.org/wiki/File:Confidence-interval.svg)\n",
        "- [Expected value of a squared standard normal](https://math.stackexchange.com/questions/264061/expected-value-calculation-for-squared-normal-distribution) (it's 1 - which is why the expected value of a Chi-Squared with $n$ degrees of freedom is $n$, as it's the sum of $n$ squared standard normals)"
      ]
    }
  ]
}
