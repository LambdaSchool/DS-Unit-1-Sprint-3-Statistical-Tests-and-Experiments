{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_132_Sampling_Confidence_Intervals_and_Hypothesis_Testing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Johnnyr81/DS-Unit-1-Sprint-3-Statistical-Tests-and-Experiments/blob/master/module2-sampling-confidence-intervals-and-hypothesis-testing/LS_DS_132_Sampling_Confidence_Intervals_and_Hypothesis_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "838Dmw1kM2LK",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science Module 142\n",
        "## Sampling, Confidence Intervals, and Hypothesis Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbcPKIo5M6Ny",
        "colab_type": "text"
      },
      "source": [
        "## Prepare - examine other available hypothesis tests\n",
        "\n",
        "If you had to pick a single hypothesis test in your toolbox, t-test would probably be the best choice - but the good news is you don't have to pick just one! Here's some of the others to be aware of:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlBel8j9M6tB",
        "colab_type": "code",
        "outputId": "0ccd66f6-2321-4c4b-aa59-318099e47a15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chisquare  # One-way chi square test\n",
        "\n",
        "# Chi square can take any crosstab/table and test the independence of rows/cols\n",
        "# The null hypothesis is that the rows/cols are independent -> low chi square\n",
        "# The alternative is that there is a dependence -> high chi square\n",
        "# Be aware! Chi square does *not* tell you direction/causation\n",
        "\n",
        "ind_obs = np.array([[1, 1], [2, 2]]).T\n",
        "print(ind_obs)\n",
        "print(chisquare(ind_obs, axis=None))\n",
        "\n",
        "dep_obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T\n",
        "print(dep_obs)\n",
        "print(chisquare(dep_obs, axis=None))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [1 2]]\n",
            "Power_divergenceResult(statistic=0.6666666666666666, pvalue=0.8810148425137847)\n",
            "[[16 32]\n",
            " [18 24]\n",
            " [16 16]\n",
            " [14 28]\n",
            " [12 20]\n",
            " [12 24]]\n",
            "Power_divergenceResult(statistic=23.31034482758621, pvalue=0.015975692534127565)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN0BdNiDPxbk",
        "colab_type": "code",
        "outputId": "d02db207-684f-4fa6-faac-729247f181ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Distribution tests:\n",
        "# We often assume that something is normal, but it can be important to *check*\n",
        "\n",
        "# For example, later on with predictive modeling, a typical assumption is that\n",
        "# residuals (prediction errors) are normal - checking is a good diagnostic\n",
        "\n",
        "from scipy.stats import normaltest\n",
        "# Poisson models arrival times and is related to the binomial (coinflip)\n",
        "sample = np.random.poisson(5, 1000)\n",
        "print(normaltest(sample))  # Pretty clearly not normal"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NormaltestResult(statistic=30.983363928689077, pvalue=1.8708889394674903e-07)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5t0WhkDReFO",
        "colab_type": "code",
        "outputId": "14596b97-2418-4cda-8bd5-d9e95384698d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Kruskal-Wallis H-test - compare the median rank between 2+ groups\n",
        "# Can be applied to ranking decisions/outcomes/recommendations\n",
        "# The underlying math comes from chi-square distribution, and is best for n>5\n",
        "from scipy.stats import kruskal\n",
        "\n",
        "x1 = [1, 3, 5, 7, 9]\n",
        "y1 = [2, 4, 6, 8, 10]\n",
        "print(kruskal(x1, y1))  # x1 is a little better, but not \"significantly\" so\n",
        "\n",
        "x2 = [1, 1, 1]\n",
        "y2 = [2, 2, 2]\n",
        "z = [2, 2]  # Hey, a third group, and of different size!\n",
        "print(kruskal(x2, y2, z))  # x clearly dominates"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KruskalResult(statistic=0.2727272727272734, pvalue=0.6015081344405895)\n",
            "KruskalResult(statistic=7.0, pvalue=0.0301973834223185)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pT3IP36Rh0b",
        "colab_type": "text"
      },
      "source": [
        "And there's many more! `scipy.stats` is fairly comprehensive, though there are even more available if you delve into the extended world of statistics packages. As tests get increasingly obscure and specialized, the importance of knowing them by heart becomes small - but being able to look them up and figure them out when they *are* relevant is still important."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JqroCQYQqhy",
        "colab_type": "text"
      },
      "source": [
        "## T-test Assumptions\n",
        "\n",
        "<https://statistics.laerd.com/statistical-guides/independent-t-test-statistical-guide.php>\n",
        "\n",
        "- Independence of means\n",
        "\n",
        "Are the means of our voting data independent (do not affect the outcome of one another)?\n",
        "  \n",
        "The best way to increase thel likelihood of our means being independent is to randomly sample (which we did not do).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqy2hEFRZnvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "?ttest_ind"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xI-PcK5sZ1A9",
        "colab_type": "text"
      },
      "source": [
        "- \"Homogeneity\" of Variance? \n",
        "\n",
        "Is the magnitude of the variance between the two roughly the same?\n",
        "\n",
        "I think we're OK on this one for the voting data, although it probably could be better, one party was larger than the other.\n",
        "\n",
        "If we suspect this to be a problem then we can use Welch's T-test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P02dL0waauN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "?ttest_ind"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjgoHHwGayoC",
        "colab_type": "text"
      },
      "source": [
        "- \"Dependent Variable\" (sample means) are Distributed Normally\n",
        "\n",
        "<https://stats.stackexchange.com/questions/9573/t-test-for-non-normal-when-n50>\n",
        "\n",
        "Lots of statistical tests depend on normal distributions. We can test for normality using Scipy as was shown above.\n",
        "\n",
        "This assumption is often assumed even if the assumption is a weak one. If you strongly suspect that things are not normally distributed, you can transform your data to get it looking more normal and then run your test. This problem typically goes away for large sample sizes (yay Central Limit Theorem) and is often why you don't hear it brought up. People declare the assumption to be satisfied either way. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvvPV-RJN2vA",
        "colab_type": "text"
      },
      "source": [
        "## Central Limit Theorem\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBLoOF8qOJeJ",
        "colab_type": "code",
        "outputId": "78c1da14-f400-4232-a2ac-801941f5bbcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "sample_means = []\n",
        "for x in range(0,3000):\n",
        "  coinflips = np.random.binomial(n=1, p=.5, size=12)\n",
        "  one_sample = coinflips\n",
        "  sample_means.append(coinflips.mean())\n",
        "\n",
        "print(len(sample_means))\n",
        "print(sample_means)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n",
            "[0.25, 0.6666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5, 0.3333333333333333, 0.5, 0.8333333333333334, 0.3333333333333333, 0.75, 0.3333333333333333, 0.4166666666666667, 0.5, 0.5833333333333334, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.5, 0.5, 0.4166666666666667, 0.25, 0.08333333333333333, 0.4166666666666667, 0.4166666666666667, 0.5, 0.5, 0.25, 0.5, 0.3333333333333333, 0.25, 0.5833333333333334, 0.75, 0.4166666666666667, 0.5, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5833333333333334, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.16666666666666666, 0.4166666666666667, 0.8333333333333334, 0.5, 0.8333333333333334, 0.25, 0.5, 0.5, 0.4166666666666667, 0.75, 0.6666666666666666, 0.5, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.5, 0.8333333333333334, 0.25, 0.3333333333333333, 0.5, 0.4166666666666667, 0.4166666666666667, 0.16666666666666666, 0.5833333333333334, 0.3333333333333333, 0.5, 0.3333333333333333, 0.5, 0.4166666666666667, 0.5, 0.6666666666666666, 0.5, 0.4166666666666667, 0.3333333333333333, 0.5833333333333334, 0.5, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.25, 0.08333333333333333, 0.4166666666666667, 0.4166666666666667, 0.25, 0.75, 0.75, 0.5, 0.5, 0.8333333333333334, 0.3333333333333333, 0.4166666666666667, 0.5, 0.6666666666666666, 0.5, 0.5833333333333334, 0.16666666666666666, 0.3333333333333333, 0.75, 0.5, 0.5, 0.8333333333333334, 0.5, 0.6666666666666666, 0.75, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.5833333333333334, 0.3333333333333333, 0.25, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.5, 0.6666666666666666, 0.5833333333333334, 0.8333333333333334, 0.4166666666666667, 0.5833333333333334, 0.5, 0.75, 0.5833333333333334, 0.25, 0.6666666666666666, 0.4166666666666667, 0.5, 0.5, 0.4166666666666667, 0.5833333333333334, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5, 0.5, 0.5833333333333334, 0.3333333333333333, 0.4166666666666667, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5833333333333334, 0.6666666666666666, 0.25, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.25, 0.3333333333333333, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.5, 0.5833333333333334, 0.6666666666666666, 0.3333333333333333, 0.75, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.4166666666666667, 0.4166666666666667, 0.3333333333333333, 0.25, 0.5, 0.6666666666666666, 0.5, 0.3333333333333333, 0.5, 0.5833333333333334, 0.6666666666666666, 0.5, 0.5833333333333334, 0.5833333333333334, 0.25, 0.4166666666666667, 0.5, 0.6666666666666666, 0.5, 0.4166666666666667, 0.5, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5833333333333334, 0.5, 0.5, 0.5833333333333334, 0.6666666666666666, 0.5, 0.5833333333333334, 0.75, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.75, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.75, 0.5, 0.75, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.5, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.5, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.5833333333333334, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5, 0.5, 0.5833333333333334, 0.3333333333333333, 0.5, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.16666666666666666, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.75, 0.75, 0.5, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.5, 0.5, 0.5, 0.5, 0.3333333333333333, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.5, 0.08333333333333333, 0.16666666666666666, 0.5, 0.5833333333333334, 0.5, 0.75, 0.5833333333333334, 0.4166666666666667, 0.25, 0.6666666666666666, 0.6666666666666666, 0.5, 0.3333333333333333, 0.4166666666666667, 0.75, 0.4166666666666667, 0.4166666666666667, 0.5, 0.3333333333333333, 0.5833333333333334, 0.5833333333333334, 0.16666666666666666, 0.6666666666666666, 0.4166666666666667, 0.5, 0.5, 0.3333333333333333, 0.5, 0.5833333333333334, 0.5, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.5833333333333334, 0.5, 0.3333333333333333, 0.75, 0.4166666666666667, 0.5, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5, 0.75, 0.5, 0.3333333333333333, 0.5, 0.3333333333333333, 0.4166666666666667, 0.4166666666666667, 0.3333333333333333, 0.5, 0.6666666666666666, 0.8333333333333334, 0.4166666666666667, 0.8333333333333334, 0.3333333333333333, 0.8333333333333334, 0.5, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.5833333333333334, 0.6666666666666666, 0.75, 0.5833333333333334, 0.4166666666666667, 0.75, 0.6666666666666666, 0.4166666666666667, 0.5, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.5, 0.6666666666666666, 0.5, 0.5, 0.5, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.3333333333333333, 0.5, 0.6666666666666666, 0.25, 0.5833333333333334, 0.9166666666666666, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.75, 0.5, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.5833333333333334, 0.6666666666666666, 0.5, 0.5833333333333334, 0.3333333333333333, 0.3333333333333333, 0.5, 0.5833333333333334, 0.5, 0.4166666666666667, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.5, 0.4166666666666667, 0.75, 0.6666666666666666, 0.3333333333333333, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.4166666666666667, 0.75, 0.5833333333333334, 0.4166666666666667, 0.9166666666666666, 0.4166666666666667, 0.8333333333333334, 0.4166666666666667, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5833333333333334, 0.25, 0.5, 0.4166666666666667, 0.5, 0.25, 0.5, 0.4166666666666667, 0.5833333333333334, 0.25, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5, 0.5, 0.6666666666666666, 0.3333333333333333, 0.25, 0.5833333333333334, 0.6666666666666666, 0.5, 0.25, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.5833333333333334, 0.5833333333333334, 0.3333333333333333, 0.5833333333333334, 0.75, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.8333333333333334, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.5, 0.5, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5, 0.75, 0.8333333333333334, 0.6666666666666666, 0.4166666666666667, 0.5833333333333334, 0.5, 0.5, 0.4166666666666667, 0.6666666666666666, 0.6666666666666666, 0.5833333333333334, 0.16666666666666666, 0.5, 0.75, 0.8333333333333334, 0.25, 0.6666666666666666, 0.5, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.5, 0.4166666666666667, 0.3333333333333333, 0.5, 0.4166666666666667, 0.5, 0.5, 0.16666666666666666, 0.3333333333333333, 0.5, 0.5, 0.5833333333333334, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5, 0.16666666666666666, 0.5833333333333334, 0.8333333333333334, 0.5, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5, 0.75, 0.25, 0.5, 0.6666666666666666, 0.3333333333333333, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.5, 0.4166666666666667, 0.5, 0.3333333333333333, 0.25, 0.5833333333333334, 0.6666666666666666, 0.5, 0.5, 0.3333333333333333, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.5, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.5, 0.4166666666666667, 0.8333333333333334, 0.3333333333333333, 0.6666666666666666, 0.25, 0.5833333333333334, 0.25, 0.5, 0.4166666666666667, 0.6666666666666666, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5833333333333334, 0.6666666666666666, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.5, 0.25, 0.5, 0.4166666666666667, 0.9166666666666666, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.4166666666666667, 0.5, 0.5, 0.75, 0.6666666666666666, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.6666666666666666, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5, 0.75, 0.25, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.5, 0.4166666666666667, 0.16666666666666666, 0.5833333333333334, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.5, 0.4166666666666667, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.25, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.6666666666666666, 0.4166666666666667, 0.5, 0.5, 0.3333333333333333, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.5, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.08333333333333333, 0.6666666666666666, 0.6666666666666666, 0.5, 0.5, 0.25, 0.5, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.75, 0.5833333333333334, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.5833333333333334, 0.5, 0.5, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.8333333333333334, 0.5, 0.6666666666666666, 0.6666666666666666, 0.75, 0.75, 0.5, 0.3333333333333333, 0.75, 0.5, 0.5, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5833333333333334, 0.6666666666666666, 0.6666666666666666, 0.5, 0.4166666666666667, 0.25, 0.5833333333333334, 0.3333333333333333, 0.5833333333333334, 0.5833333333333334, 0.3333333333333333, 0.5, 0.5833333333333334, 0.5, 0.6666666666666666, 0.5, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5, 0.3333333333333333, 0.5, 0.4166666666666667, 0.5, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.6666666666666666, 0.5, 0.16666666666666666, 0.4166666666666667, 0.3333333333333333, 0.25, 0.5833333333333334, 0.5, 0.5833333333333334, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.5, 0.3333333333333333, 0.5, 0.5833333333333334, 0.5, 0.75, 0.5, 0.5, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.5833333333333334, 0.5, 0.6666666666666666, 0.4166666666666667, 0.5, 0.5833333333333334, 0.6666666666666666, 0.16666666666666666, 0.6666666666666666, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.6666666666666666, 0.5833333333333334, 0.5, 0.3333333333333333, 0.3333333333333333, 0.5, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.75, 0.5, 0.4166666666666667, 0.5833333333333334, 0.5, 0.5, 0.6666666666666666, 0.5833333333333334, 0.6666666666666666, 0.5, 0.6666666666666666, 0.6666666666666666, 0.5, 0.3333333333333333, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.3333333333333333, 0.5, 0.5, 0.5, 0.4166666666666667, 0.5, 0.25, 0.5833333333333334, 0.9166666666666666, 0.4166666666666667, 0.5833333333333334, 0.5833333333333334, 0.5, 0.5833333333333334, 0.6666666666666666, 0.5833333333333334, 0.75, 0.5, 0.5833333333333334, 0.08333333333333333, 0.5, 0.5833333333333334, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.5833333333333334, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.4166666666666667, 0.5, 0.3333333333333333, 0.6666666666666666, 0.4166666666666667, 0.3333333333333333, 0.5, 0.5833333333333334, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.5833333333333334, 0.5, 0.5, 0.5833333333333334, 0.25, 0.4166666666666667, 0.3333333333333333, 0.5, 0.3333333333333333, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.6666666666666666, 0.5, 0.6666666666666666, 0.75, 0.3333333333333333, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.5833333333333334, 0.75, 0.5833333333333334, 0.6666666666666666, 0.5, 0.3333333333333333, 0.5, 0.8333333333333334, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.5, 0.4166666666666667, 0.6666666666666666, 0.75, 0.5833333333333334, 0.8333333333333334, 0.5833333333333334, 0.5, 0.75, 0.25, 0.5, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.5, 0.75, 0.3333333333333333, 0.5833333333333334, 0.5, 0.5, 0.75, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5, 0.5, 0.5833333333333334, 0.25, 0.5, 0.5, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.4166666666666667, 0.5, 0.6666666666666666, 0.4166666666666667, 0.5, 0.4166666666666667, 0.3333333333333333, 0.75, 0.5833333333333334, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.16666666666666666, 0.25, 0.25, 0.5, 0.5, 0.25, 0.75, 0.6666666666666666, 0.3333333333333333, 0.5, 0.4166666666666667, 0.75, 0.4166666666666667, 0.4166666666666667, 0.5, 0.75, 0.4166666666666667, 0.6666666666666666, 0.25, 0.5, 0.6666666666666666, 0.5, 0.5, 0.4166666666666667, 0.6666666666666666, 0.5, 0.5833333333333334, 0.75, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5833333333333334, 0.5, 0.75, 0.4166666666666667, 0.25, 0.5833333333333334, 0.3333333333333333, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.5, 0.3333333333333333, 0.8333333333333334, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.25, 0.4166666666666667, 0.25, 0.75, 0.4166666666666667, 0.5, 0.6666666666666666, 0.4166666666666667, 0.8333333333333334, 0.4166666666666667, 0.3333333333333333, 0.5, 0.5833333333333334, 0.6666666666666666, 0.6666666666666666, 0.5833333333333334, 0.5, 0.6666666666666666, 0.5, 0.75, 0.5, 0.6666666666666666, 0.9166666666666666, 0.5, 0.25, 0.25, 0.25, 0.4166666666666667, 0.5, 0.5, 0.6666666666666666, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.5, 0.5, 0.3333333333333333, 0.25, 0.3333333333333333, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5, 0.6666666666666666, 0.6666666666666666, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.5, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.16666666666666666, 0.5, 0.5, 0.5, 0.25, 0.6666666666666666, 0.75, 0.5, 0.5833333333333334, 0.5833333333333334, 0.75, 0.3333333333333333, 0.3333333333333333, 0.5833333333333334, 0.3333333333333333, 0.5, 0.16666666666666666, 0.5833333333333334, 0.5833333333333334, 0.5, 0.75, 0.5, 0.16666666666666666, 0.4166666666666667, 0.8333333333333334, 0.5833333333333334, 0.6666666666666666, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.5, 0.3333333333333333, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.5, 0.4166666666666667, 0.5, 0.5, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.5, 0.3333333333333333, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.3333333333333333, 0.5, 0.3333333333333333, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.5, 0.4166666666666667, 0.75, 0.4166666666666667, 0.4166666666666667, 0.3333333333333333, 0.5, 0.5, 0.5833333333333334, 0.5, 0.4166666666666667, 0.75, 0.5833333333333334, 0.3333333333333333, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.6666666666666666, 0.6666666666666666, 0.5, 0.5, 0.4166666666666667, 0.3333333333333333, 0.16666666666666666, 0.5, 0.4166666666666667, 0.4166666666666667, 0.5, 0.5, 0.6666666666666666, 0.5833333333333334, 0.3333333333333333, 0.5, 0.4166666666666667, 0.5833333333333334, 0.5, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.75, 0.5, 0.3333333333333333, 0.5, 0.5, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.25, 0.4166666666666667, 0.5, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.5, 0.5, 0.5833333333333334, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.75, 0.5, 0.4166666666666667, 0.5, 0.4166666666666667, 0.4166666666666667, 0.5, 0.75, 0.5, 0.4166666666666667, 0.5833333333333334, 0.5, 0.5, 0.5833333333333334, 0.3333333333333333, 0.5833333333333334, 0.6666666666666666, 0.5, 0.75, 0.4166666666666667, 0.3333333333333333, 0.25, 0.5833333333333334, 0.25, 0.3333333333333333, 0.4166666666666667, 0.5, 0.5, 0.6666666666666666, 0.6666666666666666, 0.5, 0.3333333333333333, 0.4166666666666667, 0.5, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.5, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.3333333333333333, 0.5, 0.4166666666666667, 0.25, 0.3333333333333333, 0.25, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.4166666666666667, 0.5, 0.16666666666666666, 0.5833333333333334, 0.25, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.75, 0.5833333333333334, 0.5833333333333334, 0.3333333333333333, 0.5, 0.75, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.25, 0.5, 0.6666666666666666, 0.4166666666666667, 0.16666666666666666, 0.5833333333333334, 0.5, 0.4166666666666667, 0.6666666666666666, 0.5, 0.25, 0.6666666666666666, 0.4166666666666667, 0.5833333333333334, 0.25, 0.6666666666666666, 0.75, 0.3333333333333333, 0.16666666666666666, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.75, 0.6666666666666666, 0.5833333333333334, 0.5, 0.4166666666666667, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.25, 0.4166666666666667, 0.5, 0.25, 0.3333333333333333, 0.5, 0.6666666666666666, 0.3333333333333333, 0.5, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.5, 0.9166666666666666, 0.25, 0.3333333333333333, 0.5, 0.4166666666666667, 0.8333333333333334, 0.6666666666666666, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.5, 0.4166666666666667, 0.5, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.5, 0.6666666666666666, 0.6666666666666666, 0.25, 0.5, 0.4166666666666667, 0.5, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.75, 0.5, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.3333333333333333, 0.25, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.4166666666666667, 0.5, 0.8333333333333334, 0.3333333333333333, 0.5833333333333334, 0.25, 0.4166666666666667, 0.5, 0.5, 0.3333333333333333, 0.6666666666666666, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.25, 0.5, 0.25, 0.4166666666666667, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.5, 0.75, 0.3333333333333333, 0.5833333333333334, 0.3333333333333333, 0.4166666666666667, 0.5, 0.25, 0.5, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.5, 0.75, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5, 0.6666666666666666, 0.25, 0.5833333333333334, 0.5833333333333334, 0.6666666666666666, 0.4166666666666667, 0.5, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.5, 0.3333333333333333, 0.4166666666666667, 0.6666666666666666, 0.6666666666666666, 0.75, 0.8333333333333334, 0.25, 0.5, 0.5833333333333334, 0.75, 0.6666666666666666, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.8333333333333334, 0.6666666666666666, 0.5833333333333334, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.4166666666666667, 0.8333333333333334, 0.5, 0.5, 0.5, 0.3333333333333333, 0.5, 0.25, 0.6666666666666666, 0.25, 0.6666666666666666, 0.5, 0.25, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.5, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.5, 0.4166666666666667, 0.5, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.75, 0.3333333333333333, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5, 0.4166666666666667, 0.6666666666666666, 0.6666666666666666, 0.8333333333333334, 1.0, 0.3333333333333333, 0.5833333333333334, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.6666666666666666, 0.5, 0.6666666666666666, 0.5833333333333334, 0.75, 0.08333333333333333, 0.4166666666666667, 0.5, 0.75, 0.5833333333333334, 0.5833333333333334, 0.6666666666666666, 0.25, 0.6666666666666666, 0.5833333333333334, 0.5, 0.3333333333333333, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.8333333333333334, 0.5833333333333334, 0.25, 0.75, 0.6666666666666666, 0.4166666666666667, 0.25, 0.25, 0.8333333333333334, 0.5833333333333334, 0.5, 0.4166666666666667, 0.5, 0.6666666666666666, 0.5, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.5, 0.5, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5833333333333334, 0.5, 0.5, 0.6666666666666666, 0.16666666666666666, 0.5833333333333334, 0.5, 0.75, 0.4166666666666667, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5, 0.3333333333333333, 0.4166666666666667, 0.75, 0.25, 0.5833333333333334, 0.5, 0.6666666666666666, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.3333333333333333, 0.4166666666666667, 0.0, 0.6666666666666666, 0.3333333333333333, 0.5, 0.5, 0.4166666666666667, 0.5, 0.4166666666666667, 0.3333333333333333, 0.5, 0.4166666666666667, 0.3333333333333333, 0.5833333333333334, 0.5833333333333334, 0.5, 0.5, 0.5, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.5, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.75, 0.25, 0.3333333333333333, 0.5, 0.6666666666666666, 0.3333333333333333, 0.5, 0.5, 0.5, 0.6666666666666666, 0.75, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.5, 0.5, 0.3333333333333333, 0.5, 0.4166666666666667, 0.4166666666666667, 0.5, 0.6666666666666666, 0.6666666666666666, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.16666666666666666, 0.5, 0.3333333333333333, 0.4166666666666667, 0.75, 0.4166666666666667, 0.5, 0.5833333333333334, 0.16666666666666666, 0.16666666666666666, 0.3333333333333333, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.25, 0.5, 0.3333333333333333, 0.4166666666666667, 0.3333333333333333, 0.5833333333333334, 0.5, 0.4166666666666667, 0.6666666666666666, 0.5, 0.3333333333333333, 0.08333333333333333, 0.3333333333333333, 0.4166666666666667, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5, 0.5, 0.4166666666666667, 0.75, 0.5, 0.16666666666666666, 0.5833333333333334, 0.5, 0.4166666666666667, 0.3333333333333333, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.75, 0.4166666666666667, 0.3333333333333333, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5833333333333334, 0.6666666666666666, 0.5, 0.75, 0.3333333333333333, 0.75, 0.8333333333333334, 0.5833333333333334, 0.3333333333333333, 0.6666666666666666, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.3333333333333333, 0.5, 0.4166666666666667, 0.5, 0.5, 0.75, 0.5, 0.5, 0.4166666666666667, 0.5833333333333334, 0.5833333333333334, 0.75, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.25, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5, 0.6666666666666666, 0.6666666666666666, 0.25, 0.25, 0.5833333333333334, 0.3333333333333333, 0.5833333333333334, 0.5, 0.5, 0.5, 0.5, 0.75, 0.3333333333333333, 0.8333333333333334, 0.5, 0.5, 0.4166666666666667, 0.5833333333333334, 1.0, 0.25, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.16666666666666666, 0.6666666666666666, 0.3333333333333333, 0.5, 0.6666666666666666, 0.75, 0.6666666666666666, 0.5, 0.75, 0.75, 0.3333333333333333, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.5, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.75, 0.5, 0.5833333333333334, 0.16666666666666666, 0.5, 0.5, 0.5, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.75, 0.4166666666666667, 0.25, 0.5833333333333334, 0.3333333333333333, 0.5833333333333334, 0.5, 0.75, 0.5833333333333334, 0.25, 0.4166666666666667, 0.5, 0.5, 0.5, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.8333333333333334, 0.25, 0.5, 0.3333333333333333, 0.6666666666666666, 0.5, 0.3333333333333333, 0.5, 0.5, 0.16666666666666666, 0.6666666666666666, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.5833333333333334, 0.6666666666666666, 0.5, 0.5, 0.75, 0.5833333333333334, 0.16666666666666666, 0.4166666666666667, 0.5, 0.6666666666666666, 0.4166666666666667, 0.6666666666666666, 0.16666666666666666, 0.6666666666666666, 0.5, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.5, 0.5833333333333334, 0.4166666666666667, 0.75, 0.5, 0.3333333333333333, 0.3333333333333333, 0.5, 0.3333333333333333, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5, 0.8333333333333334, 0.5833333333333334, 0.25, 0.8333333333333334, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.5, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.75, 0.75, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.5, 0.6666666666666666, 0.5, 0.6666666666666666, 0.75, 0.6666666666666666, 0.5, 0.6666666666666666, 0.4166666666666667, 0.6666666666666666, 0.5, 0.08333333333333333, 0.4166666666666667, 0.5833333333333334, 0.5, 0.3333333333333333, 0.6666666666666666, 0.75, 0.4166666666666667, 0.5833333333333334, 0.16666666666666666, 0.5, 0.75, 0.4166666666666667, 0.5, 0.5, 0.25, 0.6666666666666666, 0.5833333333333334, 0.25, 0.3333333333333333, 0.5, 0.4166666666666667, 0.5, 0.5833333333333334, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.5, 0.5833333333333334, 0.5, 0.6666666666666666, 0.8333333333333334, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.5, 0.3333333333333333, 0.5833333333333334, 0.5833333333333334, 0.5, 0.75, 0.5, 0.75, 0.6666666666666666, 0.5, 0.6666666666666666, 0.6666666666666666, 0.8333333333333334, 0.8333333333333334, 0.5833333333333334, 0.5, 0.3333333333333333, 0.5, 0.5, 0.25, 0.6666666666666666, 0.5, 0.4166666666666667, 0.5, 0.8333333333333334, 0.6666666666666666, 0.5, 0.3333333333333333, 0.75, 0.5, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.5, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.5, 0.25, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.5, 0.5, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.5, 0.5, 0.3333333333333333, 0.5, 0.8333333333333334, 0.4166666666666667, 0.5, 0.5, 0.3333333333333333, 0.6666666666666666, 0.5, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.5833333333333334, 0.5, 0.3333333333333333, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.5, 0.4166666666666667, 0.5, 0.3333333333333333, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.6666666666666666, 0.4166666666666667, 0.5, 0.6666666666666666, 0.5833333333333334, 0.25, 0.4166666666666667, 0.5, 0.16666666666666666, 0.3333333333333333, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.3333333333333333, 0.75, 0.3333333333333333, 0.25, 0.8333333333333334, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.6666666666666666, 0.4166666666666667, 0.5, 0.16666666666666666, 0.5, 0.4166666666666667, 0.25, 0.5, 0.6666666666666666, 0.25, 0.25, 0.5833333333333334, 0.5, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.5, 0.6666666666666666, 0.5, 0.3333333333333333, 0.75, 0.5833333333333334, 0.4166666666666667, 0.5, 0.75, 0.8333333333333334, 0.5833333333333334, 0.4166666666666667, 0.25, 0.4166666666666667, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5, 0.6666666666666666, 0.5, 0.5833333333333334, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.5, 0.4166666666666667, 0.3333333333333333, 0.5, 0.5, 0.4166666666666667, 0.5, 0.25, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.6666666666666666, 0.5, 0.5, 0.5, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.25, 0.5, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.3333333333333333, 0.5, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5, 0.5833333333333334, 0.6666666666666666, 0.4166666666666667, 0.3333333333333333, 0.5, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.08333333333333333, 0.3333333333333333, 0.5833333333333334, 0.5, 0.5, 0.5833333333333334, 0.6666666666666666, 0.5, 0.4166666666666667, 0.5, 0.75, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.5, 0.3333333333333333, 0.75, 0.6666666666666666, 0.5, 0.6666666666666666, 0.6666666666666666, 0.5, 0.5833333333333334, 0.16666666666666666, 0.5833333333333334, 0.5833333333333334, 0.25, 0.5833333333333334, 0.25, 0.6666666666666666, 0.5, 0.5, 0.4166666666666667, 0.75, 0.5, 0.5, 0.16666666666666666, 0.75, 0.5, 0.5, 0.5, 0.3333333333333333, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.4166666666666667, 0.5833333333333334, 0.5833333333333334, 0.25, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.75, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.5, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.25, 0.5, 0.25, 0.75, 0.75, 0.5833333333333334, 0.16666666666666666, 0.25, 0.75, 0.25, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.5833333333333334, 0.5, 0.4166666666666667, 0.5, 0.75, 0.75, 0.5, 0.4166666666666667, 0.16666666666666666, 0.5, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.3333333333333333, 0.5, 0.5, 0.4166666666666667, 0.5833333333333334, 0.5, 0.6666666666666666, 0.4166666666666667, 0.5, 0.25, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.5, 0.4166666666666667, 0.4166666666666667, 0.8333333333333334, 0.6666666666666666, 0.5, 0.4166666666666667, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.5, 0.4166666666666667, 0.5, 0.5, 0.4166666666666667, 0.5833333333333334, 0.75, 0.5, 0.3333333333333333, 0.4166666666666667, 0.5, 0.5, 0.5833333333333334, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.5833333333333334, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.5, 0.5, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.5, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.5, 0.3333333333333333, 0.5833333333333334, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.5, 0.3333333333333333, 0.5, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.3333333333333333, 0.5, 0.25, 0.4166666666666667, 0.5, 0.25, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5, 0.5, 0.6666666666666666, 0.3333333333333333, 0.4166666666666667, 0.6666666666666666, 0.5, 0.4166666666666667, 0.5833333333333334, 0.75, 0.3333333333333333, 0.3333333333333333, 0.5833333333333334, 0.75, 0.5833333333333334, 0.6666666666666666, 0.5833333333333334, 0.25, 0.4166666666666667, 0.5833333333333334, 0.25, 0.5833333333333334, 0.6666666666666666, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.25, 0.5833333333333334, 0.4166666666666667, 0.75, 0.5, 0.8333333333333334, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.25, 0.8333333333333334, 0.3333333333333333, 0.5833333333333334, 0.3333333333333333, 0.4166666666666667, 0.3333333333333333, 0.5, 0.3333333333333333, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.75, 0.4166666666666667, 0.16666666666666666, 0.4166666666666667, 0.25, 0.6666666666666666, 0.3333333333333333, 0.4166666666666667, 0.6666666666666666, 0.5, 0.3333333333333333, 0.4166666666666667, 0.6666666666666666, 0.5, 0.5, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.5, 0.75, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.5, 0.4166666666666667, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.5833333333333334, 0.6666666666666666, 0.6666666666666666, 0.8333333333333334, 0.5, 0.5, 0.5833333333333334, 0.6666666666666666, 0.5833333333333334, 0.16666666666666666, 0.5, 0.4166666666666667, 0.25, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.75, 0.5833333333333334, 0.5833333333333334, 0.5, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.6666666666666666, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.75, 0.5833333333333334, 0.75, 0.5833333333333334, 0.5, 0.75, 0.5833333333333334, 0.25, 0.3333333333333333, 0.5, 0.5833333333333334, 0.6666666666666666, 0.5, 0.08333333333333333, 0.6666666666666666, 0.5, 0.5, 0.25, 0.5833333333333334, 0.3333333333333333, 0.5, 0.5, 0.5833333333333334, 0.8333333333333334, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.5833333333333334, 0.5, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.5833333333333334, 0.6666666666666666, 0.5, 0.75, 0.5, 0.25, 0.3333333333333333, 0.3333333333333333, 0.5833333333333334, 0.6666666666666666, 0.3333333333333333, 0.5, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.5, 0.5, 0.25, 0.5, 0.5, 0.8333333333333334, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.3333333333333333, 0.5, 0.5833333333333334, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5, 0.4166666666666667, 0.6666666666666666, 0.75, 0.5, 0.16666666666666666, 0.75, 0.75, 0.8333333333333334, 0.5, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.4166666666666667, 0.16666666666666666, 0.25, 0.3333333333333333, 0.5833333333333334, 0.75, 0.75, 0.5833333333333334, 0.5, 0.5, 0.4166666666666667, 0.5833333333333334, 0.5, 0.5, 0.8333333333333334, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.5833333333333334, 0.5, 0.4166666666666667, 0.5, 0.5833333333333334, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.3333333333333333, 0.16666666666666666, 0.25, 0.3333333333333333, 0.25, 0.8333333333333334, 0.75, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5, 0.3333333333333333, 0.4166666666666667, 0.5, 0.5833333333333334, 0.75, 0.4166666666666667, 0.4166666666666667, 0.5, 0.5, 0.4166666666666667, 0.3333333333333333, 0.8333333333333334, 0.4166666666666667, 0.5833333333333334, 0.5833333333333334, 0.5, 0.75, 0.3333333333333333, 0.4166666666666667, 0.25, 0.4166666666666667, 0.6666666666666666, 0.5, 0.5, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5833333333333334, 0.3333333333333333, 0.6666666666666666, 0.5, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.3333333333333333, 0.5, 0.5, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.8333333333333334, 0.5, 0.4166666666666667, 0.5, 0.5, 0.5833333333333334, 0.5833333333333334, 0.75, 0.75, 0.75, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5, 0.4166666666666667, 0.25, 0.3333333333333333, 0.5833333333333334, 0.3333333333333333, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.5, 0.4166666666666667, 0.4166666666666667, 0.25, 0.5833333333333334, 0.6666666666666666, 0.75, 0.5, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5, 0.5833333333333334, 0.25, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.3333333333333333, 0.5, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.5, 0.5, 0.5, 0.5, 0.4166666666666667, 0.3333333333333333, 0.25, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.16666666666666666, 0.5, 0.5, 0.5833333333333334, 0.5, 0.6666666666666666, 0.08333333333333333, 0.4166666666666667, 0.25, 0.4166666666666667, 0.6666666666666666, 0.6666666666666666, 0.5, 0.3333333333333333, 0.3333333333333333, 0.25, 0.25, 0.16666666666666666, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.4166666666666667, 0.75, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.3333333333333333, 0.4166666666666667, 0.5, 0.4166666666666667, 0.6666666666666666, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.25, 0.5833333333333334, 0.25, 0.75, 0.4166666666666667, 0.5, 0.25, 0.5, 0.4166666666666667, 0.5, 0.5, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333, 0.25, 0.5833333333333334, 0.16666666666666666, 0.3333333333333333, 0.5833333333333334, 0.5, 0.6666666666666666, 0.5833333333333334, 0.3333333333333333, 0.25, 0.4166666666666667, 0.75, 0.5, 0.3333333333333333, 0.5, 0.4166666666666667, 0.6666666666666666, 0.6666666666666666, 0.5833333333333334, 0.5833333333333334, 0.75, 0.5, 0.4166666666666667, 0.3333333333333333, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.75, 0.5833333333333334, 0.5, 0.5, 0.3333333333333333, 0.5833333333333334, 0.5, 0.6666666666666666, 0.4166666666666667, 0.25, 0.5833333333333334, 0.5833333333333334, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.8333333333333334, 0.16666666666666666, 0.5, 0.5833333333333334, 0.5, 0.5833333333333334, 0.6666666666666666, 0.5, 0.75, 0.5, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.5, 0.3333333333333333, 0.3333333333333333, 0.75, 0.25, 0.25, 0.5, 0.4166666666666667, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.5833333333333334, 0.5, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.75, 0.75, 0.6666666666666666, 0.6666666666666666, 0.4166666666666667, 0.6666666666666666, 0.6666666666666666, 0.08333333333333333, 0.25, 0.5833333333333334, 0.4166666666666667, 0.5833333333333334, 0.75, 0.75, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.5, 0.25, 0.3333333333333333, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.5, 0.5, 0.25, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.5, 0.5, 0.5, 0.3333333333333333, 0.3333333333333333, 0.6666666666666666, 0.4166666666666667, 0.3333333333333333, 0.75, 0.4166666666666667, 0.4166666666666667, 0.25, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.4166666666666667, 0.5, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.5, 0.5833333333333334, 0.5833333333333334, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.16666666666666666, 0.75, 0.75, 0.5, 0.16666666666666666, 0.3333333333333333, 0.5833333333333334, 0.5, 0.25, 0.4166666666666667, 0.5833333333333334, 0.5833333333333334, 0.6666666666666666, 0.5, 0.25, 0.5833333333333334, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5, 0.5833333333333334, 0.25, 0.5833333333333334, 0.5, 0.5, 0.5, 0.4166666666666667, 0.5, 0.5, 0.3333333333333333, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.3333333333333333, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.3333333333333333, 0.8333333333333334, 0.75, 0.25, 0.3333333333333333, 0.3333333333333333, 0.5, 0.3333333333333333, 0.75, 0.75, 0.6666666666666666, 0.4166666666666667, 0.5, 0.5, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5, 0.25, 0.3333333333333333, 0.5, 0.6666666666666666, 0.5833333333333334, 0.75, 0.75, 0.4166666666666667, 0.5, 0.6666666666666666, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.5, 0.5, 0.5, 0.6666666666666666, 0.6666666666666666, 0.5833333333333334, 0.5833333333333334, 0.5, 0.6666666666666666, 0.5, 0.5, 0.5, 0.3333333333333333, 0.5, 0.5, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5, 0.5, 0.5833333333333334, 0.5, 0.5, 0.75, 0.6666666666666666, 0.5, 0.25, 0.5833333333333334, 0.5, 0.4166666666666667, 0.75, 0.4166666666666667, 0.8333333333333334, 0.3333333333333333, 0.5, 0.4166666666666667, 0.6666666666666666, 0.5833333333333334, 0.6666666666666666, 0.5833333333333334, 0.6666666666666666, 0.8333333333333334, 0.5833333333333334, 0.5, 0.5833333333333334, 0.75, 0.5, 0.4166666666666667, 0.16666666666666666, 0.3333333333333333, 0.5, 0.25, 0.3333333333333333, 0.5, 0.3333333333333333, 0.3333333333333333, 0.5, 0.75, 0.5, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.25, 0.5833333333333334, 0.5833333333333334, 0.5, 0.5, 0.5833333333333334, 0.5833333333333334, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.3333333333333333, 0.5, 0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.25, 0.4166666666666667, 0.5, 0.5, 0.4166666666666667, 0.6666666666666666, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.75, 0.75, 0.5833333333333334, 0.5833333333333334, 0.16666666666666666, 0.5, 0.3333333333333333, 0.5833333333333334, 0.8333333333333334, 0.5833333333333334, 0.25, 0.6666666666666666, 0.5, 0.4166666666666667, 0.25, 0.4166666666666667, 0.5, 0.3333333333333333, 0.3333333333333333, 0.5, 0.5833333333333334, 0.5833333333333334, 0.3333333333333333, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.3333333333333333, 0.3333333333333333, 0.16666666666666666, 0.5833333333333334, 0.4166666666666667, 0.6666666666666666, 0.75, 0.6666666666666666, 0.4166666666666667, 0.5, 0.25, 0.4166666666666667, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.25, 0.4166666666666667, 0.4166666666666667, 0.4166666666666667, 0.8333333333333334, 0.5833333333333334, 0.5, 0.6666666666666666, 0.5, 0.5, 0.5833333333333334, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5833333333333334, 0.5, 0.4166666666666667, 0.5833333333333334, 0.3333333333333333, 0.4166666666666667, 0.5833333333333334, 0.6666666666666666, 0.6666666666666666, 0.5, 0.5, 0.5, 0.4166666666666667, 0.3333333333333333, 0.5833333333333334, 0.5, 0.5833333333333334, 0.5, 0.6666666666666666, 0.5, 0.8333333333333334, 0.4166666666666667, 0.6666666666666666, 0.3333333333333333, 0.4166666666666667, 0.6666666666666666, 0.5, 0.6666666666666666, 0.3333333333333333, 0.16666666666666666, 0.5833333333333334, 0.5, 0.5833333333333334, 0.4166666666666667, 0.5, 0.4166666666666667, 0.5, 0.6666666666666666, 0.4166666666666667, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667, 0.5, 0.5833333333333334, 0.6666666666666666, 0.3333333333333333, 0.9166666666666666, 0.4166666666666667, 0.5833333333333334, 0.4166666666666667]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfeA06evOT2K",
        "colab_type": "code",
        "outputId": "6594eb1e-bb97-4fa5-8b64-11a98fb68a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df = pd.DataFrame({'a': one_sample})\n",
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   a\n",
              "0  0\n",
              "1  1\n",
              "2  1\n",
              "3  0\n",
              "4  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlMSNFX6OmBV",
        "colab_type": "code",
        "outputId": "f32ed481-a85b-4fb8-97a6-389851e88007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "df.a.hist()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fea1bd9c0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jie4ypgLOs5M",
        "colab_type": "code",
        "outputId": "13ecfcf3-b638-4f17-9122-c1a5233abab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "ax = plt.hist(sample_means, bins=24)\n",
        "plt.title('Distribution of 3000 sample means \\n (of 12 coinflips each)');"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEXCAYAAACjyo8UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsEAjc4rOylm",
        "colab_type": "text"
      },
      "source": [
        "What does the Central Limit Theorem State? That no matter the initial distribution of the population, the distribution of sample means taken will approximate a normal distribution as $n \\rightarrow \\infty$.\n",
        "\n",
        "This has very important implications for hypothesis testing and is precisely the reason why the t-distribution begins to approximate the normal distribution as our sample size increases. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYqo5vZZSFUr",
        "colab_type": "text"
      },
      "source": [
        "## Standard Error of the Mean\n",
        "\n",
        "What does it mean to \"estimate\"? the Population mean?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puGXH6vbSIE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfdQf8QYUUmw",
        "colab_type": "text"
      },
      "source": [
        "## Build and Interpret a Confidence Interval\n",
        "\n",
        "<img src=\"https://github.com/ryanallredblog/ryanallredblog.github.io/blob/master/img/Confidence_Interval.png?raw=true\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBx71Kf0UjT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confidence_interval(data, confidence=0.95):\n",
        "  \"\"\"\n",
        "  Calculate a confidence interval around a sample mean for given data.\n",
        "  Using t-distribution and two-tailed test, default 95% confidence. \n",
        "  \n",
        "  Arguments:\n",
        "    data - iterable (list or numpy array) of sample observations\n",
        "    confidence - level of confidence for the interval\n",
        "  \n",
        "  Returns:\n",
        "    tuple of (mean, lower bound, upper bound)\n",
        "  \"\"\"\n",
        "  data = np.array(data)\n",
        "  mean = np.mean(data)\n",
        "  n = len(data)\n",
        "  stderr = stats.sem(data)\n",
        "  interval = stderr * stats.t.ppf((1 + confidence) / 2.0, n - 1)\n",
        "  return (mean, mean - interval, mean + interval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4rtc8luVUAK",
        "colab_type": "text"
      },
      "source": [
        "## Graphically Represent a Confidence Interval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz6F9_3_VmKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oy0uoBGeoEb",
        "colab_type": "text"
      },
      "source": [
        "## Relationship between Confidence Intervals and T-tests\n",
        "\n",
        "Confidence Interval == Bounds of statistical significance for our t-test\n",
        "\n",
        "A sample mean that falls inside of our confidence interval will \"FAIL TO REJECT\" our null hypothesis\n",
        "\n",
        "A sample mean that falls outside of our confidence interval will \"REJECT\" our null hypothesis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izIyVavzfCXS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import t, ttest_1samp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7HwdMwDfL1N",
        "colab_type": "code",
        "outputId": "acf1b779-0f88-4c70-e52a-688c509f245c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "coinflip_means = []\n",
        "for x in range(0,100):\n",
        "  coinflips = np.random.binomial(n=1, p=.5, size=30)\n",
        "  coinflip_means.append(coinflips.mean())\n",
        "\n",
        "print(coinflip_means)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.43333333333333335, 0.6, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.4, 0.4666666666666667, 0.43333333333333335, 0.4666666666666667, 0.5, 0.5, 0.5, 0.6666666666666666, 0.4666666666666667, 0.7333333333333333, 0.4666666666666667, 0.5666666666666667, 0.43333333333333335, 0.43333333333333335, 0.6, 0.5333333333333333, 0.4, 0.43333333333333335, 0.5, 0.4666666666666667, 0.26666666666666666, 0.5, 0.5, 0.36666666666666664, 0.5333333333333333, 0.6666666666666666, 0.43333333333333335, 0.4, 0.4666666666666667, 0.43333333333333335, 0.3333333333333333, 0.4, 0.6333333333333333, 0.6333333333333333, 0.5333333333333333, 0.5666666666666667, 0.43333333333333335, 0.5333333333333333, 0.5666666666666667, 0.5, 0.7, 0.5, 0.5333333333333333, 0.6, 0.4, 0.4, 0.5333333333333333, 0.5333333333333333, 0.4666666666666667, 0.4666666666666667, 0.4666666666666667, 0.36666666666666664, 0.43333333333333335, 0.5333333333333333, 0.43333333333333335, 0.5333333333333333, 0.6, 0.5333333333333333, 0.5333333333333333, 0.4, 0.5333333333333333, 0.43333333333333335, 0.6333333333333333, 0.5333333333333333, 0.6, 0.5, 0.6, 0.43333333333333335, 0.4, 0.6333333333333333, 0.5666666666666667, 0.4, 0.6, 0.4666666666666667, 0.6333333333333333, 0.5666666666666667, 0.6, 0.5, 0.3333333333333333, 0.36666666666666664, 0.6, 0.3333333333333333, 0.5, 0.5333333333333333, 0.4666666666666667, 0.4, 0.4666666666666667, 0.43333333333333335, 0.5333333333333333, 0.3333333333333333, 0.5333333333333333, 0.43333333333333335, 0.6, 0.5333333333333333, 0.5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQDo-ZXlfOvR",
        "colab_type": "code",
        "outputId": "ebdcf68c-63cb-4555-ea0c-b61cf5e1d6ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Sample Size\n",
        "n = len(coinflip_means)\n",
        "# Degrees of Freedom\n",
        "dof = n-1\n",
        "# The Mean of Means:\n",
        "mean = np.mean(coinflip_means)\n",
        "# Sample Standard Deviation\n",
        "sample_std = np.std(coinflip_means, ddof=1)\n",
        "# Standard Error\n",
        "std_err = sample_std/n**.5\n",
        "\n",
        "CI = t.interval(.95, dof, loc=mean, scale=std_err)\n",
        "print(\"95% Confidence Interval: \", CI)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95% Confidence Interval:  (0.4804172168839329, 0.5155827831160669)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiaALHSNfWou",
        "colab_type": "code",
        "outputId": "e8daa1ef-a396-473b-a99e-6591b9a881a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "'''You can roll your own CI calculation pretty easily. \n",
        "The only thing that's a little bit challenging \n",
        "is understanding the t stat lookup'''\n",
        "\n",
        "# 95% confidence interval\n",
        "t_stat = t.ppf(.975, dof)\n",
        "print(\"t Statistic:\", t_stat)\n",
        "\n",
        "CI = (mean-(t_stat*std_err), mean+(t_stat*std_err))\n",
        "print(\"Confidence Interval\", CI)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t Statistic: 1.9842169515086827\n",
            "Confidence Interval (0.4804172168839329, 0.5155827831160669)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EamZNJhAf-fY",
        "colab_type": "text"
      },
      "source": [
        "A null hypothesis that's just inside of our confidence interval == fail to reject\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNpzYbjpfirR",
        "colab_type": "code",
        "outputId": "0a21d9ae-66dc-4013-986d-d0116efa8b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ttest_1samp(coinflip_means, .49)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_1sampResult(statistic=0.9027999439726917, pvalue=0.3688234626093373)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO34mbL9gHn1",
        "colab_type": "text"
      },
      "source": [
        "A null hypothesis that's just outside of our confidence interval == reject\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4SUjj82gKlv",
        "colab_type": "code",
        "outputId": "4244da92-edfb-4c60-8d71-d0ad8bf6dd65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ttest_1samp(coinflip_means, .4818927)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_1sampResult(statistic=1.8177086921939272, pvalue=0.0721332212231356)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTIzrkKdUaLl",
        "colab_type": "text"
      },
      "source": [
        "## Run a $\\chi^{2}$ Test \"by hand\" (Using Numpy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDsovHUyUj3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Igz-XHcVbW3",
        "colab_type": "text"
      },
      "source": [
        "## Run a $\\chi^{2}$ Test using Scipy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X52Nwt7AVlvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11OzdxWTM7UR",
        "colab_type": "text"
      },
      "source": [
        "## Assignment - Build a confidence interval\n",
        "\n",
        "A confidence interval refers to a neighborhood around some point estimate, the size of which is determined by the desired p-value. For instance, we might say that 52% of Americans prefer tacos to burritos, with a 95% confidence interval of +/- 5%.\n",
        "\n",
        "52% (0.52) is the point estimate, and +/- 5% (the interval $[0.47, 0.57]$) is the confidence interval. \"95% confidence\" means a p-value $\\leq 1 - 0.95 = 0.05$.\n",
        "\n",
        "In this case, the confidence interval includes $0.5$ - which is the natural null hypothesis (that half of Americans prefer tacos and half burritos, thus there is no clear favorite). So in this case, we could use the confidence interval to report that we've failed to reject the null hypothesis.\n",
        "\n",
        "But providing the full analysis with a confidence interval, including a graphical representation of it, can be a helpful and powerful way to tell your story. Done well, it is also more intuitive to a layperson than simply saying \"fail to reject the null hypothesis\" - it shows that in fact the data does *not* give a single clear result (the point estimate) but a whole range of possibilities.\n",
        "\n",
        "How is a confidence interval built, and how should it be interpreted? It does *not* mean that 95% of the data lies in that interval - instead, the frequentist interpretation is \"if we were to repeat this experiment 100 times, we would expect the average result to lie in this interval ~95 times.\"\n",
        "\n",
        "For a 95% confidence interval and a normal(-ish) distribution, you can simply remember that +/-2 standard deviations contains 95% of the probability mass, and so the 95% confidence interval based on a given sample is centered at the mean (point estimate) and has a range of +/- 2 (or technically 1.96) standard deviations.\n",
        "\n",
        "Different distributions/assumptions (90% confidence, 99% confidence) will require different math, but the overall process and interpretation (with a frequentist approach) will be the same.\n",
        "\n",
        "Your assignment - using the data from the prior module ([congressional voting records](https://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records)):\n",
        "\n",
        "\n",
        "### Confidence Intervals:\n",
        "1. Generate and numerically represent a confidence interval\n",
        "2. Graphically (with a plot) represent the confidence interval\n",
        "3. Interpret the confidence interval - what does it tell you about the data and its distribution?\n",
        "\n",
        "### Chi-squared tests:\n",
        "4. Take a dataset that we have used in the past in class that has **categorical** variables. Pick two of those categorical variables and run a chi-squared tests on that data\n",
        "  - By hand using Numpy\n",
        "  - In a single line using Scipy\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "1. Write a summary of your findings, mixing prose and math/code/results. *Note* - yes, this is by definition a political topic. It is challenging but important to keep your writing voice *neutral* and stick to the facts of the data. Data science often involves considering controversial issues, so it's important to be sensitive about them (especially if you want to publish).\n",
        "2. Apply the techniques you learned today to your project data or other data of your choice, and write/discuss your findings here.\n",
        "3. Refactor your code so it is elegant, readable, and can be easily run for all issues."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ckcr4A4FM7cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data')\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkH_QO3boGKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8OUXnG4oJH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.replace(to_replace=['n', 'y', '?'], value=[0, 1, np.nan])\n",
        "df.head();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olriXbjloNU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns = ['Party',\n",
        "'handicapped',\n",
        "'water',\n",
        "'adoption',\n",
        "'physician',\n",
        "'salvador' ,\n",
        "'religious',\n",
        "'satellite',\n",
        "'nicaraguan',\n",
        "'missile',\n",
        "'immigration',\n",
        "'synfuels',\n",
        "'education',\n",
        "'superfund' ,\n",
        "'crime',\n",
        "'duty' ,\n",
        "'export']\n",
        "\n",
        "df.head();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPdxOpCWocHl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "11173d00-4c82-45ae-e376-fcd8b5a352bd"
      },
      "source": [
        "rep = df[df['Party'] == 'republican']\n",
        "rep.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>handicapped</th>\n",
              "      <th>water</th>\n",
              "      <th>adoption</th>\n",
              "      <th>physician</th>\n",
              "      <th>salvador</th>\n",
              "      <th>religious</th>\n",
              "      <th>satellite</th>\n",
              "      <th>nicaraguan</th>\n",
              "      <th>missile</th>\n",
              "      <th>immigration</th>\n",
              "      <th>synfuels</th>\n",
              "      <th>education</th>\n",
              "      <th>superfund</th>\n",
              "      <th>crime</th>\n",
              "      <th>duty</th>\n",
              "      <th>export</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>republican</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Party  handicapped  water  adoption  ...  superfund  crime  duty  export\n",
              "0   republican          0.0    1.0       0.0  ...        1.0    1.0   0.0     NaN\n",
              "6   republican          0.0    1.0       0.0  ...        1.0    1.0   NaN     1.0\n",
              "7   republican          0.0    1.0       0.0  ...        1.0    1.0   0.0     1.0\n",
              "9   republican          0.0    1.0       0.0  ...        1.0    1.0   0.0     0.0\n",
              "10  republican          0.0    1.0       0.0  ...        1.0    1.0   NaN     NaN\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwxjnUCJofKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "b6c4c135-9e2d-47ae-e0a1-37491ac429f1"
      },
      "source": [
        "dem = df[df['Party'] == 'democrat']\n",
        "dem.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Party</th>\n",
              "      <th>handicapped</th>\n",
              "      <th>water</th>\n",
              "      <th>adoption</th>\n",
              "      <th>physician</th>\n",
              "      <th>salvador</th>\n",
              "      <th>religious</th>\n",
              "      <th>satellite</th>\n",
              "      <th>nicaraguan</th>\n",
              "      <th>missile</th>\n",
              "      <th>immigration</th>\n",
              "      <th>synfuels</th>\n",
              "      <th>education</th>\n",
              "      <th>superfund</th>\n",
              "      <th>crime</th>\n",
              "      <th>duty</th>\n",
              "      <th>export</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>democrat</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>democrat</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>democrat</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>democrat</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>democrat</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Party  handicapped  water  adoption  ...  superfund  crime  duty  export\n",
              "1  democrat          NaN    1.0       1.0  ...        1.0    1.0   0.0     0.0\n",
              "2  democrat          0.0    1.0       1.0  ...        1.0    0.0   0.0     1.0\n",
              "3  democrat          1.0    1.0       1.0  ...        1.0    1.0   1.0     1.0\n",
              "4  democrat          0.0    1.0       1.0  ...        1.0    1.0   1.0     1.0\n",
              "5  democrat          0.0    1.0       0.0  ...        NaN    1.0   1.0     1.0\n",
              "\n",
              "[5 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOeRCuCJxI4a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c011a12e-cf48-491f-d0c8-79b6d6e5321d"
      },
      "source": [
        "print(\"Democrat Support: \", dem['crime'].mean())\n",
        "print(\"Republican Support: \", rep['crime'].mean())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Democrat Support:  0.35019455252918286\n",
            "Republican Support:  0.98125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWveEnU6xOec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "357d8c3e-6669-4cf1-aeb1-e222879873e7"
      },
      "source": [
        "print(\"Democrat Support: \", dem['crime'].std())\n",
        "print(\"Republican Support: \", rep['crime'].std())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Democrat Support:  0.4779615336263577\n",
            "Republican Support:  0.13606671504595172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hXRvb0Bxcpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "e70fead3-ab4a-47c2-8cfe-2752358b3b93"
      },
      "source": [
        "dem_crime= pd.DataFrame({'democrat_crime': dem['crime']})\n",
        "print(dem_crime.shape)\n",
        "dem_crime.head()\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(267, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>democrat_crime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   democrat_crime\n",
              "1             1.0\n",
              "2             0.0\n",
              "3             1.0\n",
              "4             1.0\n",
              "5             1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWgaHo9VysD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ad4de769-237f-455a-b5ca-8049103f93db"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sample_dv= np.std(dem_crime)\n",
        "print('sample standard deviation:', sample_dv)\n",
        "sample_size= len(dem_crime)\n",
        "print('sample size:', sample_size)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample standard deviation: democrat_crime    0.477031\n",
            "dtype: float64\n",
            "sample size: 267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEbvduGwBosN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5bee0574-92cf-4913-99eb-c602da04ef94"
      },
      "source": [
        "standard_error = sample_dv / (sample_size**(.5))\n",
        "\n",
        "print(\"standard error:\", standard_error)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "standard error: democrat_crime    0.029194\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE6iVSceDBrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats\n",
        "t = stats.t.ppf(.975 , sample_size-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa5f99WPEc7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_mean = dem_crime.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cCQXyVQEkqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "d0ed06c1-1908-4b3e-ff11-fb8df8050a9f"
      },
      "source": [
        "confidence_interval = (sample_mean - t*standard_error, sample_mean + t*standard_error)\n",
        "\n",
        "margin_of_error = t*standard_error\n",
        "\n",
        "print(\"Sample Mean\", sample_mean)\n",
        "print(\"Margin of Error:\", margin_of_error)\n",
        "print(\"Confidence Interval:\", confidence_interval)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample Mean democrat_crime    0.350195\n",
            "dtype: float64\n",
            "Margin of Error: democrat_crime    0.05748\n",
            "dtype: float64\n",
            "Confidence Interval: (democrat_crime    0.292714\n",
            "dtype: float64, democrat_crime    0.407675\n",
            "dtype: float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2cLODITFfsl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "86c85e1f-b9bb-4e5d-c13f-b96520623be1"
      },
      "source": [
        "confidence_interval[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "democrat_crime    0.292714\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsUwKm54Fiwm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a5352adc-d911-4d89-c7ac-8c251163cf6a"
      },
      "source": [
        "confidence_interval[1]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "democrat_crime    0.407675\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr3aTctCFnTg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "19690ca8-afd1-40b6-c2fc-9d3c1ee05bca"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.kdeplot(dem_crime)\n",
        "plt.axvline(x=confidence_interval[0], color='red')\n",
        "plt.axvline(x=confidence_interval[1], color='red')\n",
        "plt.axvline(x=sample_mean, color='k');\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-56172aa99c7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdem_crime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxvline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfidence_interval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxvline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfidence_interval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mkdeplot\u001b[0;34m(data, data2, shade, vertical, kernel, bw, gridsize, cut, clip, legend, cumulative, shade_lowest, cbar, cbar_ax, cbar_kws, ax, **kwargs)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mbivariate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdata2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mbivariate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1492\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1494\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1496\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_has_valid_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Too many indexers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 raise ValueError(\"Location based indexing can only have \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_key\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2068\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2071\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m             \u001b[0;31m# a tuple should already have been caught by this point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2137\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2139\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYfAlqQmDL0lNGHxJauJ/Acz2XLpusNoKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyJ3ySr7R2k9",
        "colab_type": "text"
      },
      "source": [
        "## Resources\n",
        "\n",
        "- [Interactive visualize the Chi-Squared test](https://homepage.divms.uiowa.edu/~mbognar/applets/chisq.html)\n",
        "- [Calculation of Chi-Squared test statistic](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)\n",
        "- [Visualization of a confidence interval generated by R code](https://commons.wikimedia.org/wiki/File:Confidence-interval.svg)\n",
        "- [Expected value of a squared standard normal](https://math.stackexchange.com/questions/264061/expected-value-calculation-for-squared-normal-distribution) (it's 1 - which is why the expected value of a Chi-Squared with $n$ degrees of freedom is $n$, as it's the sum of $n$ squared standard normals)"
      ]
    }
  ]
}