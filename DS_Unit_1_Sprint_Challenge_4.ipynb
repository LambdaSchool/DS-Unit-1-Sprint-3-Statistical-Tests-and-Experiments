{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_Unit_1_Sprint_Challenge_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/extrajp2014/DS-Unit-1-Sprint-4-Statistical-Tests-and-Experiments/blob/master/DS_Unit_1_Sprint_Challenge_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "NooAiTdnafkz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Science Unit 1 Sprint Challenge 4\n",
        "\n",
        "## Exploring Data, Testing Hypotheses\n",
        "\n",
        "In this sprint challenge you will look at a dataset of people being approved or rejected for credit.\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/Credit+Approval\n",
        "\n",
        "Data Set Information: This file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data. This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values. There are also a few missing values.\n",
        "\n",
        "Attribute Information:\n",
        "- A1: b, a.\n",
        "- A2: continuous.\n",
        "- A3: continuous.\n",
        "- A4: u, y, l, t.\n",
        "- A5: g, p, gg.\n",
        "- A6: c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n",
        "- A7: v, h, bb, j, n, z, dd, ff, o.\n",
        "- A8: continuous.\n",
        "- A9: t, f.\n",
        "- A10: t, f.\n",
        "- A11: continuous.\n",
        "- A12: t, f.\n",
        "- A13: g, p, s.\n",
        "- A14: continuous.\n",
        "- A15: continuous.\n",
        "- A16: +,- (class attribute)\n",
        "\n",
        "Yes, most of that doesn't mean anything. A16 (the class attribute) is the most interesting, as it separates the 307 approved cases from the 383 rejected cases. The remaining variables have been obfuscated for privacy - a challenge you may have to deal with in your data science career.\n",
        "\n",
        "Sprint challenges are evaluated based on satisfactory completion of each part. It is suggested you work through it in order, getting each aspect reasonably working, before trying to deeply explore, iterate, or refine any given step. Once you get to the end, if you want to go back and improve things, go for it!"
      ]
    },
    {
      "metadata": {
        "id": "5wch6ksCbJtZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 1 - Load and validate the data\n",
        "\n",
        "- Load the data as a `pandas` data frame.\n",
        "- Validate that it has the appropriate number of observations (you can check the raw file, and also read the dataset description from UCI).\n",
        "- UCI says there should be missing data - check, and if necessary change the data so pandas recognizes it as na\n",
        "- Make sure that the loaded features are of the types described above (continuous values should be treated as float), and correct as necessary\n",
        "\n",
        "This is review, but skills that you'll use at the start of any data exploration. Further, you may have to do some investigation to figure out which file to load from - that is part of the puzzle."
      ]
    },
    {
      "metadata": {
        "id": "Q79xDLckzibS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "1a1f455c-1578-4da9-ec7a-e43a30eb1324"
      },
      "cell_type": "code",
      "source": [
        "url=\"https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\"\n",
        "!wget $url\n",
        "!curl $url | wc"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-01 16:06:54--  https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32218 (31K) [text/plain]\n",
            "Saving to: ‘crx.data’\n",
            "\n",
            "crx.data            100%[===================>]  31.46K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-02-01 16:06:59 (1004 KB/s) - ‘crx.data’ saved [32218/32218]\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 32218  100 32218    0     0   154k      0 --:--:-- --:--:-- --:--:--  153k\n",
            "    690     690   32218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EOB244t20uz0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1472602e-6dd9-4584-f5fb-16c316cd7adb"
      },
      "cell_type": "code",
      "source": [
        "# load data\n",
        "from scipy.stats import chisquare\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "pd.set_option('display.height', 500)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 500)\n",
        "pd.options.display.float_format = '{:,}'.format\n",
        "\n",
        "names=[\"A\"+str(i) for i in range(1,17)]\n",
        "df = pd.read_csv('crx.data', header=None, names=names)\n",
        "df.head()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>A9</th>\n",
              "      <th>A10</th>\n",
              "      <th>A11</th>\n",
              "      <th>A12</th>\n",
              "      <th>A13</th>\n",
              "      <th>A14</th>\n",
              "      <th>A15</th>\n",
              "      <th>A16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.0</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.25</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00202</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.46</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>3.04</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>6</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00043</td>\n",
              "      <td>560</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>1.5</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>824</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.54</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>3.75</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00100</td>\n",
              "      <td>3</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.71</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>00120</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  A1     A2    A3 A4 A5 A6 A7   A8 A9 A10  A11 A12 A13    A14  A15 A16\n",
              "0  b  30.83   0.0  u  g  w  v 1.25  t   t    1   f   g  00202    0   +\n",
              "1  a  58.67  4.46  u  g  q  h 3.04  t   t    6   f   g  00043  560   +\n",
              "2  a  24.50   0.5  u  g  q  h  1.5  t   f    0   f   g  00280  824   +\n",
              "3  b  27.83  1.54  u  g  w  v 3.75  t   t    5   t   g  00100    3   +\n",
              "4  b  20.17 5.625  u  g  w  v 1.71  t   f    0   f   s  00120    0   +"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "j43u7y3h1I-D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "cb99f166-4f98-438b-8b20-465357a65e84"
      },
      "cell_type": "code",
      "source": [
        "# preview data\n",
        "print(\"df shape:\"), print(df.shape), print(\"\")\n",
        "print(\"df dtypes:\"), print(df.dtypes), print(\"\")\n",
        "print(\"df sample(7):\"), print(df.sample(7)), print(\"\")\n",
        "print(\"df isnull().sum().sum():\"), print(df.isnull().sum().sum()), print(\"\")\n",
        "print(\"df describe(include=np.number):\")\n",
        "print(df.describe(include=np.number))\n",
        "print(\"\")\n",
        "print(\"df describe(exclude=np.number):\")\n",
        "print(df.describe(exclude=np.number))\n",
        "print(\"\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df shape:\n",
            "(690, 16)\n",
            "\n",
            "df dtypes:\n",
            "A1      object\n",
            "A2     float64\n",
            "A3     float64\n",
            "A4      object\n",
            "A5      object\n",
            "A6      object\n",
            "A7      object\n",
            "A8     float64\n",
            "A9      object\n",
            "A10     object\n",
            "A11    float64\n",
            "A12     object\n",
            "A13     object\n",
            "A14    float64\n",
            "A15    float64\n",
            "A16     object\n",
            "dtype: object\n",
            "\n",
            "df sample(7):\n",
            "    A1    A2    A3 A4 A5  A6  A7    A8 A9 A10  A11 A12 A13   A14     A15 A16\n",
            "662  a  23.5   1.5  u  g   w   v 0.875  f   f  0.0   t   g 160.0     0.0   -\n",
            "280  b 21.17 0.875  y  p   c   h  0.25  f   f  0.0   f   g 280.0   204.0   -\n",
            "347  b 26.75   4.5  y  p   c  bb   2.5  f   f  0.0   f   g 200.0 1,210.0   -\n",
            "634  a 23.75  0.71  u  g   w   v  0.25  f   t  1.0   t   g 240.0     4.0   -\n",
            "229  b 22.08  11.0  u  g  cc   v 0.665  t   f  0.0   f   g 100.0     0.0   +\n",
            "547  b 23.92   1.5  u  g   d   h 1.875  t   t  6.0   f   g 200.0   327.0   +\n",
            "194  b  34.5  4.04  y  p   i  bb   8.5  t   t  7.0   t   g 195.0     0.0   +\n",
            "\n",
            "df isnull().sum().sum():\n",
            "67\n",
            "\n",
            "df describe(include=np.number):\n",
            "                      A2                 A3                 A8               A11                A14                 A15\n",
            "count              678.0              690.0              690.0             690.0              677.0               690.0\n",
            "mean   31.56817109144546 4.7587246376811585 2.2234057971014476               2.4 184.01477104874445 1,017.3855072463768\n",
            "std   11.957862498270877  4.978163248528541 3.3465133592781333 4.862940034226996 173.80676822523824 5,210.1025983026975\n",
            "min                13.75                0.0                0.0               0.0                0.0                 0.0\n",
            "25%              22.6025                1.0              0.165               0.0               75.0                 0.0\n",
            "50%                28.46               2.75                1.0               0.0              160.0                 5.0\n",
            "75%   38.230000000000004             7.2075              2.625               3.0              276.0               395.5\n",
            "max                80.25               28.0               28.5              67.0            2,000.0           100,000.0\n",
            "\n",
            "df describe(exclude=np.number):\n",
            "         A1   A4   A5   A6   A7   A9  A10  A12  A13  A16\n",
            "count   678  684  684  681  681  690  690  690  690  690\n",
            "unique    2    3    3   14    9    2    2    2    3    2\n",
            "top       b    u    g    c    v    t    f    f    g    -\n",
            "freq    468  519  519  137  399  361  395  374  625  383\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MS-N80Ry1aDt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Documentation: https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.names\n",
        "# A1: b, a.\n",
        "# A2: continuous.\n",
        "# A3: continuous.\n",
        "# A4: u, y, l, t.\n",
        "# A5: g, p, gg.\n",
        "# A6: c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n",
        "# A7: v, h, bb, j, n, z, dd, ff, o.\n",
        "# A8: continuous.\n",
        "# A9: t, f.\n",
        "# A10: t, f.\n",
        "# A11: continuous.\n",
        "# A12: t, f.\n",
        "# A13: g, p, s.\n",
        "# A14: continuous.\n",
        "# A15: continuous.\n",
        "# A16: +,- (class attribute)\n",
        "\n",
        "# 8.  Missing Attribute Values:\n",
        "#     37 cases (5%) have one or more missing values.  The missing\n",
        "#     values from particular attributes are:\n",
        "\n",
        "#     A1:  12\n",
        "#     A2:  12\n",
        "#     A4:   6\n",
        "#     A5:   6\n",
        "#     A6:   9\n",
        "#     A7:   9\n",
        "#     A14: 13"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TZHSAfU018d9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "b4a7fb4b-f0ed-4916-969f-7e02a8f9e457"
      },
      "cell_type": "code",
      "source": [
        "# UCI says there should be missing data - check, and if necessary change the data \n",
        "# so pandas recognizes it as na\n",
        "# Make sure that the loaded features are of the types described above (continuous \n",
        "# values should be treated as float), and correct as necessary\n",
        "\n",
        "df = df.replace({'?': np.nan})\n",
        "# convert to correct format\n",
        "for i in [\"A2\",\"A3\",\"A8\",\"A11\",\"A14\",\"A15\"]:\n",
        "  df[i] = df[i].astype(float)\n",
        "\n",
        "# preview data\n",
        "df2 = df.dropna()\n",
        "print(df.shape, df2.shape), print(\"\")\n",
        "print(df2['A16'].value_counts()), print(\"\")\n",
        "print(\"df isnull().sum():\"), print(df.isnull().sum()), print(\"\")\n",
        "print(\"df2 isnull().sum().sum():\"), print(df2.isnull().sum().sum()), print(\"\")\n",
        "print(\"df2 sample(7):\"), print(df2.sample(7)), print(\"\")\n",
        "print(\"df2 describe(include=np.number):\")\n",
        "print(df2.describe(include=np.number))\n",
        "print(\"\")\n",
        "print(\"df2 describe(exclude=np.number):\")\n",
        "print(df2.describe(exclude=np.number))\n",
        "print(\"\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(690, 16) (653, 16)\n",
            "\n",
            "-    357\n",
            "+    296\n",
            "Name: A16, dtype: int64\n",
            "\n",
            "df isnull().sum():\n",
            "A1     12\n",
            "A2     12\n",
            "A3      0\n",
            "A4      6\n",
            "A5      6\n",
            "A6      9\n",
            "A7      9\n",
            "A8      0\n",
            "A9      0\n",
            "A10     0\n",
            "A11     0\n",
            "A12     0\n",
            "A13     0\n",
            "A14    13\n",
            "A15     0\n",
            "A16     0\n",
            "dtype: int64\n",
            "\n",
            "df2 isnull().sum().sum():\n",
            "0\n",
            "\n",
            "df2 sample(7):\n",
            "    A1    A2    A3 A4 A5  A6 A7    A8 A9 A10  A11 A12 A13   A14     A15 A16\n",
            "285  b 17.58  10.0  u  g   w  h 0.165  f   t  1.0   f   g 120.0     1.0   -\n",
            "11   b 29.92 1.835  u  g   c  h 4.335  t   f  0.0   f   g 260.0   200.0   +\n",
            "220  a 50.08 12.54  u  g  aa  v  2.29  t   t  3.0   t   g 156.0     0.0   +\n",
            "166  b 19.33   9.5  u  g   q  v   1.0  t   f  0.0   t   g  60.0   400.0   +\n",
            "429  b 33.58 0.335  y  p  cc  v 0.085  f   f  0.0   f   g 180.0     0.0   -\n",
            "510  b 13.75   4.0  y  p   w  v  1.75  t   t  2.0   t   g 120.0 1,000.0   +\n",
            "28   b 57.42   8.5  u  g   e  h   7.0  t   t  3.0   f   g   0.0     0.0   +\n",
            "\n",
            "df2 describe(include=np.number):\n",
            "                      A2                A3                 A8                A11                A14                 A15\n",
            "count              653.0             653.0              653.0              653.0              653.0               653.0\n",
            "mean   31.50381316998472 4.829532924961714 2.2442955589586506 2.5022970903522204 180.35987748851454 1,013.7611026033691\n",
            "std   11.838267107399854 5.027077437761294  3.371120259441243  4.968496852464736 168.29681104695345  5,253.278503747187\n",
            "min                13.75               0.0                0.0                0.0                0.0                 0.0\n",
            "25%                22.58              1.04              0.165                0.0               73.0                 0.0\n",
            "50%                28.42             2.835                1.0                0.0              160.0                 5.0\n",
            "75%                38.25               7.5              2.625                3.0              272.0               400.0\n",
            "max                76.75              28.0               28.5               67.0            2,000.0           100,000.0\n",
            "\n",
            "df2 describe(exclude=np.number):\n",
            "         A1   A4   A5   A6   A7   A9  A10  A12  A13  A16\n",
            "count   653  653  653  653  653  653  653  653  653  653\n",
            "unique    2    3    3   14    9    2    2    2    3    2\n",
            "top       b    u    g    c    v    t    f    f    g    -\n",
            "freq    450  499  499  133  381  349  366  351  598  357\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G7rLytbrO38L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 2 - Exploring data, Testing hypotheses\n",
        "\n",
        "The only thing we really know about this data is that A16 is the class label. Besides that, we have 6 continuous (float) features and 9 categorical features.\n",
        "\n",
        "Explore the data: you can use whatever approach (tables, utility functions, visualizations) to get an impression of the distributions and relationships of the variables. In general, your goal is to understand how the features are different when grouped by the two class labels (`+` and `-`).\n",
        "\n",
        "For the 6 continuous features, how are they different when split between the two class labels? Choose two features to run t-tests (again split by class label) - specifically, select one feature that is *extremely* different between the classes, and another feature that is notably less different (though perhaps still \"statistically significantly\" different). You may have to explore more than two features to do this.\n",
        "\n",
        "For the categorical features, explore by creating \"cross tabs\" (aka [contingency tables](https://en.wikipedia.org/wiki/Contingency_table)) between them and the class label, and apply the Chi-squared test to them. [pandas.crosstab](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html) can create contingency tables, and [scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) can calculate the Chi-squared statistic for them.\n",
        "\n",
        "There are 9 categorical features - as with the t-test, try to find one where the Chi-squared test returns an extreme result (rejecting the null that the data are independent), and one where it is less extreme.\n",
        "\n",
        "**NOTE** - \"less extreme\" just means smaller test statistic/larger p-value. Even the least extreme differences may be strongly statistically significant.\n",
        "\n",
        "Your *main* goal is the hypothesis tests, so don't spend too much time on the exploration/visualization piece. That is just a means to an end - use simple visualizations, such as boxplots or a scatter matrix (both built in to pandas), to get a feel for the overall distribution of the variables.\n",
        "\n",
        "This is challenging, so manage your time and aim for a baseline of at least running two t-tests and two Chi-squared tests before polishing. And don't forget to answer the questions in part 3, even if your results in this part aren't what you want them to be."
      ]
    },
    {
      "metadata": {
        "id": "_nqcgc0yzm68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54fca01b-c660-4069-81c1-398b460c84e9"
      },
      "cell_type": "code",
      "source": [
        "# Split class into 2 df for stats calculation\n",
        "pos_df = df2[df2['A16']=='+']\n",
        "neg_df = df2[df2['A16']=='-']\n",
        "print(pos_df.shape,neg_df.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(296, 16) (357, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0c0j-v9v4h5q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "2c16314b-3e1c-410d-82d3-7dea5bda279c"
      },
      "cell_type": "code",
      "source": [
        "floatColumns=['A2','A3','A8','A11','A14','A15']\n",
        "categoricColumns=['A1','A4','A5','A6','A7','A9','A10','A12','A13']\n",
        "boolColumns=['A9','A10','A12']\n",
        "\n",
        "# Calculate 2 SAMPLE TTEST - Nonequal sample sizes\n",
        "print(\"Pvalue < 0.05\")\n",
        "print(\"Column\",\"       \",\"Statistic\",\"              \", \"Pvalue\")\n",
        "for i in floatColumns:\n",
        "  stat, pvalue = stats.ttest_ind(pos_df[i], neg_df[i], nan_policy='omit', equal_var=False)\n",
        "  if pvalue < 0.05: print(i,\"       \", stat,\"       \", pvalue)\n",
        "print(\"\")\n",
        "\n",
        "print(\"Pvalue > 0.05\")\n",
        "print(\"Column\",\"       \",\"Statistic\",\"              \", \"Pvalue\")\n",
        "for i in floatColumns:\n",
        "  stat, pvalue = stats.ttest_ind(pos_df[i], neg_df[i], nan_policy='omit', equal_var=False)\n",
        "  if pvalue > 0.05: print(i,\"       \", stat,\"       \", pvalue)\n",
        "print(\"\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pvalue < 0.05\n",
            "Column         Statistic                Pvalue\n",
            "A2         4.603105537295886         5.118622270751413e-06\n",
            "A3         5.290896422208584         1.7489090249152318e-07\n",
            "A8         8.497111846543877         3.6540467526389407e-16\n",
            "A11         10.4894892779921         1.702907212870187e-22\n",
            "A14         -2.193851777301385         0.02860488893016181\n",
            "A15         4.079693539983498         5.792817047242567e-05\n",
            "\n",
            "Pvalue > 0.05\n",
            "Column         Statistic                Pvalue\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qy90jjyu835L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "bc9d5f80-280c-49c5-e515-183ec09c78f3"
      },
      "cell_type": "code",
      "source": [
        "# Preview data for chi-square test\n",
        "for i in categoricColumns:\n",
        "  print(df2[i].value_counts())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b    450\n",
            "a    203\n",
            "Name: A1, dtype: int64\n",
            "u    499\n",
            "y    152\n",
            "l      2\n",
            "Name: A4, dtype: int64\n",
            "g     499\n",
            "p     152\n",
            "gg      2\n",
            "Name: A5, dtype: int64\n",
            "c     133\n",
            "q      75\n",
            "w      63\n",
            "i      55\n",
            "aa     52\n",
            "ff     50\n",
            "k      48\n",
            "cc     40\n",
            "m      38\n",
            "x      36\n",
            "d      26\n",
            "e      24\n",
            "j      10\n",
            "r       3\n",
            "Name: A6, dtype: int64\n",
            "v     381\n",
            "h     137\n",
            "ff     54\n",
            "bb     53\n",
            "z       8\n",
            "j       8\n",
            "dd      6\n",
            "n       4\n",
            "o       2\n",
            "Name: A7, dtype: int64\n",
            "t    349\n",
            "f    304\n",
            "Name: A9, dtype: int64\n",
            "f    366\n",
            "t    287\n",
            "Name: A10, dtype: int64\n",
            "f    351\n",
            "t    302\n",
            "Name: A12, dtype: int64\n",
            "g    598\n",
            "s     53\n",
            "p      2\n",
            "Name: A13, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "em2N4BSM7OtX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1462
        },
        "outputId": "faada7d8-cfb6-4df2-84f7-9ea005d4c748"
      },
      "cell_type": "code",
      "source": [
        "# Get significant Chi-Square crosstab\n",
        "def significantChi2(oneColumn,columns,df):\n",
        "  '''\n",
        "  For p-value < 0.05, print Pearson chisquare test results of 1 column cross with \n",
        "  all other categoric columns from chosen columns\n",
        "  '''\n",
        "  for i in columns:\n",
        "    temp=pd.crosstab(df[oneColumn], df[i])\n",
        "    if stats.chi2_contingency(temp)[1] < .05:\n",
        "      print(\"---------------------\")\n",
        "      print(temp)\n",
        "      print(\"---------------------\")\n",
        "      print(\"Chisquare of A16 crosstab\", i,\":\")\n",
        "      print(\"Chi2 Statistic,\", \"P-value,\", \"Degree of Freedom,\", \"Expected Frequency\")\n",
        "      print(stats.chi2_contingency(temp))\n",
        "      print(\"\")\n",
        "\n",
        "significantChi2('A16',categoricColumns,df2)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------\n",
            "A4   l    u    y\n",
            "A16             \n",
            "+    2  249   45\n",
            "-    0  250  107\n",
            "---------------------\n",
            "Chisquare of A16 crosstab A4 :\n",
            "Chi2 Statistic, P-value, Degree of Freedom, Expected Frequency\n",
            "(21.78325079317282, 1.8613463470618034e-05, 2, array([[  0.90658499, 226.19295559,  68.90045942],\n",
            "       [  1.09341501, 272.80704441,  83.09954058]]))\n",
            "\n",
            "---------------------\n",
            "A5     g  gg    p\n",
            "A16              \n",
            "+    249   2   45\n",
            "-    250   0  107\n",
            "---------------------\n",
            "Chisquare of A16 crosstab A5 :\n",
            "Chi2 Statistic, P-value, Degree of Freedom, Expected Frequency\n",
            "(21.78325079317282, 1.8613463470618034e-05, 2, array([[226.19295559,   0.90658499,  68.90045942],\n",
            "       [272.80704441,   1.09341501,  83.09954058]]))\n",
            "\n",
            "---------------------\n",
            "A6   aa   c  cc   d   e  ff   i  j   k   m   q  r   w   x\n",
            "A16                                                      \n",
            "+    19  60  29   7  14   7  14  3  13  16  49  2  33  30\n",
            "-    33  73  11  19  10  43  41  7  35  22  26  1  30   6\n",
            "---------------------\n",
            "Chisquare of A16 crosstab A6 :\n",
            "Chi2 Statistic, P-value, Degree of Freedom, Expected Frequency\n",
            "(89.76481160702343, 1.5500154549498966e-13, 13, array([[23.5712098 , 60.28790199, 18.13169985, 11.7856049 , 10.87901991,\n",
            "        22.66462481, 24.93108729,  4.53292496, 21.75803982, 17.22511485,\n",
            "        33.99693721,  1.35987749, 28.55742726, 16.31852986],\n",
            "       [28.4287902 , 72.71209801, 21.86830015, 14.2143951 , 13.12098009,\n",
            "        27.33537519, 30.06891271,  5.46707504, 26.24196018, 20.77488515,\n",
            "        41.00306279,  1.64012251, 34.44257274, 19.68147014]]))\n",
            "\n",
            "---------------------\n",
            "A7   bb  dd  ff   h  j  n  o    v  z\n",
            "A16                                 \n",
            "+    24   2   8  87  3  2  1  163  6\n",
            "-    29   4  46  50  5  2  1  218  2\n",
            "---------------------\n",
            "Chisquare of A16 crosstab A7 :\n",
            "Chi2 Statistic, P-value, Degree of Freedom, Expected Frequency\n",
            "(42.988254470828515, 8.829142688919391e-07, 8, array([[ 24.0245023 ,   2.71975498,  24.47779479,  62.10107198,\n",
            "          3.62633997,   1.81316998,   0.90658499, 172.70444104,\n",
            "          3.62633997],\n",
            "       [ 28.9754977 ,   3.28024502,  29.52220521,  74.89892802,\n",
            "          4.37366003,   2.18683002,   1.09341501, 208.29555896,\n",
            "          4.37366003]]))\n",
            "\n",
            "---------------------\n",
            "A9     f    t\n",
            "A16          \n",
            "+     18  278\n",
            "-    286   71\n",
            "---------------------\n",
            "Chisquare of A16 crosstab A9 :\n",
            "Chi2 Statistic, P-value, Degree of Freedom, Expected Frequency\n",
            "(353.4827159410316, 7.391616628555818e-79, 1, array([[137.80091884, 158.19908116],\n",
            "       [166.19908116, 190.80091884]]))\n",
            "\n",
            "---------------------\n",
            "A10    f    t\n",
            "A16          \n",
            "+     93  203\n",
            "-    273   84\n",
            "---------------------\n",
            "Chisquare of A16 crosstab A10 :\n",
            "Chi2 Statistic, P-value, Degree of Freedom, Expected Frequency\n",
            "(131.50867232095965, 1.9163536191857147e-30, 1, array([[165.9050536, 130.0949464],\n",
            "       [200.0949464, 156.9050536]]))\n",
            "\n",
            "---------------------\n",
            "A13    g  p   s\n",
            "A16            \n",
            "+    280  1  15\n",
            "-    318  1  38\n",
            "---------------------\n",
            "Chisquare of A16 crosstab A13 :\n",
            "Chi2 Statistic, P-value, Degree of Freedom, Expected Frequency\n",
            "(6.756491933104269, 0.03410722751542202, 2, array([[271.06891271,   0.90658499,  24.0245023 ],\n",
            "       [326.93108729,   1.09341501,  28.9754977 ]]))\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2UsSPD4nHSf1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "6d66410d-0c31-4a4d-85c1-b1da434777cb"
      },
      "cell_type": "code",
      "source": [
        "def nonSignificantChi2(oneColumn,columns,df):\n",
        "  '''\n",
        "  For p-value > 0.05, print Pearson chisquare test results of 1 column cross with \n",
        "  all other categoric columns from chosen columns\n",
        "  '''\n",
        "  for i in columns:\n",
        "    temp=pd.crosstab(df[oneColumn], df[i])\n",
        "    if stats.chi2_contingency(temp)[1] > .05:\n",
        "      print(\"---------------------\")\n",
        "      print(temp)\n",
        "      print(\"---------------------\")\n",
        "      print(\"Chisquare of A16 crosstab\", i,\":\")\n",
        "      print(\"Chi2 Statistic,\", \"P-value,\", \"Degree of Freedom,\", \"Expected Frequency\")\n",
        "      print(stats.chi2_contingency(temp))\n",
        "      print(\"\")\n",
        "nonSignificantChi2('A16',categoricColumns,df2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---------------------\n",
            "A1     a    b\n",
            "A16          \n",
            "+     95  201\n",
            "-    108  249\n",
            "---------------------\n",
            "Chisquare of A16 crosstab A1 :\n",
            "Chi2 Statistic, P-value, Degree of Freedom, Expected Frequency\n",
            "(0.17764082160253514, 0.6734085695133722, 1, array([[ 92.01837672, 203.98162328],\n",
            "       [110.98162328, 246.01837672]]))\n",
            "\n",
            "---------------------\n",
            "A12    f    t\n",
            "A16          \n",
            "+    151  145\n",
            "-    200  157\n",
            "---------------------\n",
            "Chisquare of A16 crosstab A12 :\n",
            "Chi2 Statistic, P-value, Degree of Freedom, Expected Frequency\n",
            "(1.4379377134356208, 0.23047335495661603, 1, array([[159.10566616, 136.89433384],\n",
            "       [191.89433384, 165.10566616]]))\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZM8JckA2bgnp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 3 - Analysis and Interpretation\n",
        "\n",
        "Now that you've looked at the data, answer the following questions:\n",
        "\n",
        "- Interpret and explain the two t-tests you ran - what do they tell you about the relationships between the continuous features you selected and the class labels?\n",
        "- Interpret and explain the two Chi-squared tests you ran - what do they tell you about the relationships between the categorical features you selected and the class labels?\n",
        "- What was the most challenging part of this sprint challenge?\n",
        "\n",
        "Answer with text, but feel free to intersperse example code/results or refer to it from earlier."
      ]
    },
    {
      "metadata": {
        "id": "LIozLDNG2Uhu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###t-test \n",
        "The 2 samples ttests with nonequal sample sizes  were used to see  how the features are different when grouped by the two class labels.  All tests return p-value < 0.05 so we can reject the null hypothesis, which originally stated that the means of compared samples are equals.  The most extreme p-value came from column A11 was 1.702907212870187e-22 with statistic value of 10.4894892779921.  We can interpret that mean of distribution for A11 is  much higher in the \"+\" class than the \"-\" class.\n",
        "\n",
        "###Chi-Square\n",
        "The Chi-Square tests were used on crosstab of A16 and all other categorical features to see if the two samples are independent.  All other tests except for crosstab table between A16 with A1 and A16 with A12 were significant with p-value < 0.05.  This means that we can reject the notion that they are independent.  As for Chi-Square result from A16 with A1 and A16 with A12, we would still keep the null hypothesis.  Since crosstab of A16 and A1 yields the highest p-value and lowest statistic value, we can interpret that they have the lowest significant association between the samples.\n",
        "\n",
        "###Challenging Part\n",
        "The most challenging part is making sure the tests return the correct results and analyze everything to make the correct interpretations."
      ]
    }
  ]
}