{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kim_Lowry_LS_DS_141_Statistics_Probability_and_Inference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hBar2013/DS-Unit-1-Sprint-4-Statistical-Tests-and-Experiments/blob/master/module1-statistics-probability-and-inference/Kim_Lowry_LS_DS_141_Statistics_Probability_and_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJGtmni-DezY",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science Module 141\n",
        "## Statistics, Probability, and Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krLt4QDz4psY",
        "colab_type": "text"
      },
      "source": [
        "just a quick change to commit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMhDKOFND0qY",
        "colab_type": "text"
      },
      "source": [
        "## Prepare - examine what's available in SciPy\n",
        "\n",
        "As we delve into statistics, we'll be using more libraries - in particular the [stats package from SciPy](https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ9rkLJmEbsk",
        "colab_type": "code",
        "outputId": "fdd415e4-88da-4aa7-e0d7-51cf7c61a50a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4386
        }
      },
      "source": [
        "from scipy import stats\n",
        "dir(stats)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__all__',\n",
              " '__builtins__',\n",
              " '__cached__',\n",
              " '__doc__',\n",
              " '__file__',\n",
              " '__loader__',\n",
              " '__name__',\n",
              " '__package__',\n",
              " '__path__',\n",
              " '__spec__',\n",
              " '_binned_statistic',\n",
              " '_constants',\n",
              " '_continuous_distns',\n",
              " '_discrete_distns',\n",
              " '_distn_infrastructure',\n",
              " '_distr_params',\n",
              " '_multivariate',\n",
              " '_rvs_sampling',\n",
              " '_stats',\n",
              " '_stats_mstats_common',\n",
              " '_tukeylambda_stats',\n",
              " 'absolute_import',\n",
              " 'alpha',\n",
              " 'anderson',\n",
              " 'anderson_ksamp',\n",
              " 'anglit',\n",
              " 'ansari',\n",
              " 'arcsine',\n",
              " 'argus',\n",
              " 'bartlett',\n",
              " 'bayes_mvs',\n",
              " 'bernoulli',\n",
              " 'beta',\n",
              " 'betaprime',\n",
              " 'binned_statistic',\n",
              " 'binned_statistic_2d',\n",
              " 'binned_statistic_dd',\n",
              " 'binom',\n",
              " 'binom_test',\n",
              " 'boltzmann',\n",
              " 'boxcox',\n",
              " 'boxcox_llf',\n",
              " 'boxcox_normmax',\n",
              " 'boxcox_normplot',\n",
              " 'bradford',\n",
              " 'brunnermunzel',\n",
              " 'burr',\n",
              " 'burr12',\n",
              " 'cauchy',\n",
              " 'chi',\n",
              " 'chi2',\n",
              " 'chi2_contingency',\n",
              " 'chisquare',\n",
              " 'circmean',\n",
              " 'circstd',\n",
              " 'circvar',\n",
              " 'combine_pvalues',\n",
              " 'contingency',\n",
              " 'cosine',\n",
              " 'crystalball',\n",
              " 'cumfreq',\n",
              " 'describe',\n",
              " 'dgamma',\n",
              " 'dirichlet',\n",
              " 'distributions',\n",
              " 'division',\n",
              " 'dlaplace',\n",
              " 'dweibull',\n",
              " 'energy_distance',\n",
              " 'entropy',\n",
              " 'erlang',\n",
              " 'expon',\n",
              " 'exponnorm',\n",
              " 'exponpow',\n",
              " 'exponweib',\n",
              " 'f',\n",
              " 'f_oneway',\n",
              " 'fatiguelife',\n",
              " 'find_repeats',\n",
              " 'fisher_exact',\n",
              " 'fisk',\n",
              " 'fligner',\n",
              " 'foldcauchy',\n",
              " 'foldnorm',\n",
              " 'frechet_l',\n",
              " 'frechet_r',\n",
              " 'friedmanchisquare',\n",
              " 'gamma',\n",
              " 'gausshyper',\n",
              " 'gaussian_kde',\n",
              " 'genexpon',\n",
              " 'genextreme',\n",
              " 'gengamma',\n",
              " 'genhalflogistic',\n",
              " 'genlogistic',\n",
              " 'gennorm',\n",
              " 'genpareto',\n",
              " 'geom',\n",
              " 'gilbrat',\n",
              " 'gmean',\n",
              " 'gompertz',\n",
              " 'gumbel_l',\n",
              " 'gumbel_r',\n",
              " 'halfcauchy',\n",
              " 'halfgennorm',\n",
              " 'halflogistic',\n",
              " 'halfnorm',\n",
              " 'hmean',\n",
              " 'hypergeom',\n",
              " 'hypsecant',\n",
              " 'invgamma',\n",
              " 'invgauss',\n",
              " 'invweibull',\n",
              " 'invwishart',\n",
              " 'iqr',\n",
              " 'itemfreq',\n",
              " 'jarque_bera',\n",
              " 'johnsonsb',\n",
              " 'johnsonsu',\n",
              " 'kappa3',\n",
              " 'kappa4',\n",
              " 'kde',\n",
              " 'kendalltau',\n",
              " 'kruskal',\n",
              " 'ks_2samp',\n",
              " 'ksone',\n",
              " 'kstat',\n",
              " 'kstatvar',\n",
              " 'kstest',\n",
              " 'kstwobign',\n",
              " 'kurtosis',\n",
              " 'kurtosistest',\n",
              " 'laplace',\n",
              " 'levene',\n",
              " 'levy',\n",
              " 'levy_l',\n",
              " 'levy_stable',\n",
              " 'linregress',\n",
              " 'loggamma',\n",
              " 'logistic',\n",
              " 'loglaplace',\n",
              " 'lognorm',\n",
              " 'logser',\n",
              " 'lomax',\n",
              " 'mannwhitneyu',\n",
              " 'matrix_normal',\n",
              " 'maxwell',\n",
              " 'median_test',\n",
              " 'mielke',\n",
              " 'mode',\n",
              " 'moment',\n",
              " 'mood',\n",
              " 'morestats',\n",
              " 'moyal',\n",
              " 'mstats',\n",
              " 'mstats_basic',\n",
              " 'mstats_extras',\n",
              " 'multinomial',\n",
              " 'multivariate_normal',\n",
              " 'mvn',\n",
              " 'mvsdist',\n",
              " 'nakagami',\n",
              " 'nbinom',\n",
              " 'ncf',\n",
              " 'nct',\n",
              " 'ncx2',\n",
              " 'norm',\n",
              " 'normaltest',\n",
              " 'norminvgauss',\n",
              " 'obrientransform',\n",
              " 'ortho_group',\n",
              " 'pareto',\n",
              " 'pearson3',\n",
              " 'pearsonr',\n",
              " 'percentileofscore',\n",
              " 'planck',\n",
              " 'pointbiserialr',\n",
              " 'poisson',\n",
              " 'power_divergence',\n",
              " 'powerlaw',\n",
              " 'powerlognorm',\n",
              " 'powernorm',\n",
              " 'ppcc_max',\n",
              " 'ppcc_plot',\n",
              " 'print_function',\n",
              " 'probplot',\n",
              " 'randint',\n",
              " 'random_correlation',\n",
              " 'rankdata',\n",
              " 'ranksums',\n",
              " 'rayleigh',\n",
              " 'rdist',\n",
              " 'recipinvgauss',\n",
              " 'reciprocal',\n",
              " 'relfreq',\n",
              " 'rice',\n",
              " 'rv_continuous',\n",
              " 'rv_discrete',\n",
              " 'rv_histogram',\n",
              " 'rvs_ratio_uniforms',\n",
              " 'scoreatpercentile',\n",
              " 'sem',\n",
              " 'semicircular',\n",
              " 'shapiro',\n",
              " 'siegelslopes',\n",
              " 'sigmaclip',\n",
              " 'skellam',\n",
              " 'skew',\n",
              " 'skewnorm',\n",
              " 'skewtest',\n",
              " 'spearmanr',\n",
              " 'special_ortho_group',\n",
              " 'statlib',\n",
              " 'stats',\n",
              " 't',\n",
              " 'test',\n",
              " 'theilslopes',\n",
              " 'tiecorrect',\n",
              " 'tmax',\n",
              " 'tmean',\n",
              " 'tmin',\n",
              " 'trapz',\n",
              " 'triang',\n",
              " 'trim1',\n",
              " 'trim_mean',\n",
              " 'trimboth',\n",
              " 'truncexpon',\n",
              " 'truncnorm',\n",
              " 'tsem',\n",
              " 'tstd',\n",
              " 'ttest_1samp',\n",
              " 'ttest_ind',\n",
              " 'ttest_ind_from_stats',\n",
              " 'ttest_rel',\n",
              " 'tukeylambda',\n",
              " 'tvar',\n",
              " 'uniform',\n",
              " 'unitary_group',\n",
              " 'variation',\n",
              " 'vonmises',\n",
              " 'vonmises_line',\n",
              " 'wald',\n",
              " 'wasserstein_distance',\n",
              " 'weibull_max',\n",
              " 'weibull_min',\n",
              " 'weightedtau',\n",
              " 'wilcoxon',\n",
              " 'wishart',\n",
              " 'wrapcauchy',\n",
              " 'yeojohnson',\n",
              " 'yeojohnson_llf',\n",
              " 'yeojohnson_normmax',\n",
              " 'yeojohnson_normplot',\n",
              " 'yulesimon',\n",
              " 'zipf',\n",
              " 'zmap',\n",
              " 'zscore']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxW4SG_gJGlZ",
        "colab_type": "code",
        "outputId": "4714f744-cf7d-433a-ea69-7891b14a1931",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# As usual, lots of stuff here! There's our friend, the normal distribution\n",
        "norm = stats.norm()\n",
        "print(norm.mean())\n",
        "print(norm.std())\n",
        "print(norm.var())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyNKPt_tJk86",
        "colab_type": "code",
        "outputId": "db64f558-1945-4fef-f7d7-3184212d8237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# And a new friend - t\n",
        "t1 = stats.t(5)  # 5 is df \"shape\" parameter\n",
        "print(t1.mean())\n",
        "print(t1.std())\n",
        "print(t1.var())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.2909944487358056\n",
            "1.6666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRn1zMuaKgxX",
        "colab_type": "text"
      },
      "source": [
        "![T distribution PDF with different shape parameters](https://upload.wikimedia.org/wikipedia/commons/4/41/Student_t_pdf.svg)\n",
        "\n",
        "*(Picture from [Wikipedia](https://en.wikipedia.org/wiki/Student's_t-distribution#/media/File:Student_t_pdf.svg))*\n",
        "\n",
        "The t-distribution is \"normal-ish\" - the larger the parameter (which reflects its degrees of freedom - more input data/features will increase it), the closer to true normal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seQv5unnJvpM",
        "colab_type": "code",
        "outputId": "ed35c474-c41b-4373-af2e-29e10887b76f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "t2 = stats.t(30)  # Will be closer to normal\n",
        "print(t2.mean())\n",
        "print(t2.std())\n",
        "print(t2.var())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "1.0350983390135313\n",
            "1.0714285714285714\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOvEGMysLaE2",
        "colab_type": "text"
      },
      "source": [
        "Why is it different from normal? To better reflect the tendencies of small data and situations with unknown population standard deviation. In other words, the normal distribution is still the nice pure ideal in the limit (thanks to the central limit theorem), but the t-distribution is much more useful in many real-world situations.\n",
        "\n",
        "History sidenote - this is \"Student\":\n",
        "\n",
        "![William Sealy Gosset](https://upload.wikimedia.org/wikipedia/commons/4/42/William_Sealy_Gosset.jpg)\n",
        "\n",
        "*(Picture from [Wikipedia](https://en.wikipedia.org/wiki/File:William_Sealy_Gosset.jpg))*\n",
        "\n",
        "His real name is William Sealy Gosset, and he published under the pen name \"Student\" because he was not an academic. He was a brewer, working at Guinness and using trial and error to determine the best ways to yield barley. He's also proof that, even 100 years ago, you don't need official credentials to do real data science!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yx_QilAEC6o",
        "colab_type": "text"
      },
      "source": [
        "## Live Lecture - let's perform and interpret a t-test\n",
        "\n",
        "We'll generate our own data, so we can know and alter the \"ground truth\" that the t-test should find. We will learn about p-values and how to interpret \"statistical significance\" based on the output of a hypothesis test. We will also dig a bit deeper into how the test statistic is calculated based on the sample error, and visually what it looks like to have 1 or 2 \"tailed\" t-tests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuysRPs-Ed0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO - during class, but please help!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egXb7YpqEcZF",
        "colab_type": "text"
      },
      "source": [
        "## Assignment - apply the t-test to real data\n",
        "\n",
        "Your assignment is to determine which issues have \"statistically significant\" differences between political parties in this [1980s congressional voting data](https://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records). The data consists of 435 instances (one for each congressperson), a class (democrat or republican), and 16 binary attributes (yes or no for voting for or against certain issues). Be aware - there are missing values!\n",
        "\n",
        "Your goals:\n",
        "\n",
        "1. Load and clean the data (or determine the best method to drop observations when running tests)\n",
        "2. Using hypothesis testing, find an issue that democrats support more than republicans with p < 0.01\n",
        "3. Using hypothesis testing, find an issue that republicans support more than democrats with p < 0.01\n",
        "4. Using hypothesis testing, find an issue where the difference between republicans and democrats has p > 0.1 (i.e. there may not be much of a difference)\n",
        "\n",
        "Note that this data will involve *2 sample* t-tests, because you're comparing averages across two groups (republicans and democrats) rather than a single group against a null hypothesis.\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "1. Refactor your code into functions so it's easy to rerun with arbitrary variables\n",
        "2. Apply hypothesis testing to your personal project data (for the purposes of this notebook you can type a summary of the hypothesis you formed and tested)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nstrmCG-Ecyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO - your code here!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiq83guLcuAE",
        "colab_type": "text"
      },
      "source": [
        "# Resources\n",
        "\n",
        "- https://homepage.divms.uiowa.edu/~mbognar/applets/t.html\n",
        "- https://rpsychologist.com/d3/tdist/\n",
        "- https://gallery.shinyapps.io/tdist/\n",
        "- https://en.wikipedia.org/wiki/Standard_deviation#Sample_standard_deviation_of_metabolic_rate_of_northern_fulmars"
      ]
    }
  ]
}