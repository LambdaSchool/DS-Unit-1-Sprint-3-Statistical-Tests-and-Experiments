{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "838Dmw1kM2LK"
   },
   "source": [
    "# Lambda School Data Science Module 142\n",
    "## Sampling, Confidence Intervals, and Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbcPKIo5M6Ny"
   },
   "source": [
    "## Prepare - examine other available hypothesis tests\n",
    "\n",
    "If you had to pick a single hypothesis test in your toolbox, t-test would probably be the best choice - but the good news is you don't have to pick just one! Here's some of the others to be aware of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "tlBel8j9M6tB",
    "outputId": "755e8d2a-48bb-4e0a-b8d9-4f1878274cd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [1 2]]\n",
      "Power_divergenceResult(statistic=0.6666666666666666, pvalue=0.8810148425137847)\n",
      "[[16 32]\n",
      " [18 24]\n",
      " [16 16]\n",
      " [14 28]\n",
      " [12 20]\n",
      " [12 24]]\n",
      "Power_divergenceResult(statistic=23.31034482758621, pvalue=0.015975692534127565)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n       Ins Outs\\nMale  [[2   1]\\nFemale [1   2]]\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chisquare  # One-way chi square test\n",
    "\n",
    "# Chi square can take any crosstab/table and test the independence of rows/cols\n",
    "# The null hypothesis is that the rows/cols are independent -> low chi square\n",
    "# The alternative is that there is a dependence -> high chi square\n",
    "# Be aware! Chi square does *not* tell you direction/causation\n",
    "\n",
    "ind_obs = np.array([[1, 1], [2, 2]]).T\n",
    "print(ind_obs)\n",
    "print(chisquare(ind_obs, axis=None))\n",
    "\n",
    "dep_obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T\n",
    "print(dep_obs)\n",
    "print(chisquare(dep_obs, axis=None))\n",
    "\n",
    "# Alternative to first table\n",
    "'''\n",
    "       Ins Outs\n",
    "Male  [[2   1]\n",
    "Female [1   2]]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nN0BdNiDPxbk",
    "outputId": "4738eec5-5f2e-4825-a6c1-494633e4a1db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NormaltestResult(statistic=36.2824569044155, pvalue=1.3224053216391557e-08)\n"
     ]
    }
   ],
   "source": [
    "# Distribution tests:\n",
    "# We often assume that something is normal, but it can be important to *check*\n",
    "\n",
    "# For example, later on with predictive modeling, a typical assumption is that\n",
    "# residuals (prediction errors) are normal - checking is a good diagnostic\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "# Poisson models arrival times and is related to the binomial (coinflip)\n",
    "sample = np.random.poisson(5, 1000)\n",
    "print(normaltest(sample))  # Pretty clearly not normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "P5t0WhkDReFO",
    "outputId": "e87c4005-9ce4-4dd8-94a9-0fcc5c646228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KruskalResult(statistic=0.2727272727272734, pvalue=0.6015081344405895)\n",
      "KruskalResult(statistic=7.0, pvalue=0.0301973834223185)\n"
     ]
    }
   ],
   "source": [
    "# Kruskal-Wallis H-test - compare the median rank between 2+ groups\n",
    "# Can be applied to ranking decisions/outcomes/recommendations\n",
    "# The underlying math comes from chi-square distribution, and is best for n>5\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "x1 = [1, 3, 5, 7, 9]\n",
    "y1 = [2, 4, 6, 8, 10]\n",
    "print(kruskal(x1, y1))  # x1 is a little better, but not \"significantly\" so\n",
    "\n",
    "x2 = [1, 1, 1]\n",
    "y2 = [2, 2, 2]\n",
    "z = [2, 2]  # Hey, a third group, and of different size!\n",
    "print(kruskal(x2, y2, z))  # x clearly dominates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7pT3IP36Rh0b"
   },
   "source": [
    "And there's many more! `scipy.stats` is fairly comprehensive, though there are even more available if you delve into the extended world of statistics packages. As tests get increasingly obscure and specialized, the importance of knowing them by heart becomes small - but being able to look them up and figure them out when they *are* relevant is still important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1_KRuHCM7BW"
   },
   "source": [
    "## Live Lecture - let's explore some more of scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "31BOV6ectO-M",
    "outputId": "feee5520-a962-4693-d441-3a24334eb221"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.stats._distn_infrastructure.rv_frozen at 0x10dab2fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing with distributions\n",
    "from scipy.stats import chi2\n",
    "\n",
    "chi2_5 = chi2(5)\n",
    "chi2_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Y49c6we2tbmD",
    "outputId": "84322cb6-06d0-462d-d174-d77795b00157"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_5.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lYQWvgnftfUJ",
    "outputId": "5b3dd6d4-084d-462f-ea67-37e54e45bc9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.351460191095526"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_5.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Ev0A1XF7trRJ",
    "outputId": "9320617f-2daa-44dd-eee8-2af9741b5670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n",
      "499.3334915888738\n"
     ]
    }
   ],
   "source": [
    "chi2_500 = chi2(500)\n",
    "print(chi2_500.mean())\n",
    "print(chi2_500.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "vvtjeumOuEEk",
    "outputId": "74f69e32-e9bf-4ba6-e354-afcb1788b331"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__func__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__self__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(chi2_5.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "4RTYs-U3uoz8",
    "outputId": "16614583-2e7f-4d0d-e62a-8234126fc54a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1e4d80b8>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From Cole\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data = scipy.stats.norm.rvs(size=100000, loc=0, scale=1.5, random_state=123)\n",
    "X = np.linspace(-5.0, 5.0, 100)\n",
    "hist = np.histogram(data, bins=100)\n",
    "hist_dist = scipy.stats.rv_histogram(hist)\n",
    "plt.plot(X, hist_dist.pdf(X), label='PDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5xbRAyhZu7CZ",
    "outputId": "0eea3d0c-7248-43d0-ecc9-3328be10c23d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NormaltestResult(statistic=230.1966099539023, pvalue=1.0314335933651229e-50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How do I test \"how normal\" a chisquare(500) is?\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "normaltest(chi2_500.rvs(100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 986
    },
    "colab_type": "code",
    "id": "JWWjSBYRvolI",
    "outputId": "a614928f-0821-4a02-de97-0a3e025cd6bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function normaltest in module scipy.stats.stats:\n",
      "\n",
      "normaltest(a, axis=0, nan_policy='propagate')\n",
      "    Test whether a sample differs from a normal distribution.\n",
      "    \n",
      "    This function tests the null hypothesis that a sample comes\n",
      "    from a normal distribution.  It is based on D'Agostino and\n",
      "    Pearson's [1]_, [2]_ test that combines skew and kurtosis to\n",
      "    produce an omnibus test of normality.\n",
      "    \n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        The array containing the sample to be tested.\n",
      "    axis : int or None, optional\n",
      "        Axis along which to compute test. Default is 0. If None,\n",
      "        compute over the whole array `a`.\n",
      "    nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "        Defines how to handle when input contains nan. 'propagate' returns nan,\n",
      "        'raise' throws an error, 'omit' performs the calculations ignoring nan\n",
      "        values. Default is 'propagate'.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    statistic : float or array\n",
      "        ``s^2 + k^2``, where ``s`` is the z-score returned by `skewtest` and\n",
      "        ``k`` is the z-score returned by `kurtosistest`.\n",
      "    pvalue : float or array\n",
      "       A 2-sided chi squared probability for the hypothesis test.\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] D'Agostino, R. B. (1971), \"An omnibus test of normality for\n",
      "           moderate and large sample size\", Biometrika, 58, 341-348\n",
      "    \n",
      "    .. [2] D'Agostino, R. and Pearson, E. S. (1973), \"Tests for departure from\n",
      "           normality\", Biometrika, 60, 613-622\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> from scipy import stats\n",
      "    >>> pts = 1000\n",
      "    >>> np.random.seed(28041990)\n",
      "    >>> a = np.random.normal(0, 1, size=pts)\n",
      "    >>> b = np.random.normal(2, 1, size=pts)\n",
      "    >>> x = np.concatenate((a, b))\n",
      "    >>> k2, p = stats.normaltest(x)\n",
      "    >>> alpha = 1e-3\n",
      "    >>> print(\"p = {:g}\".format(p))\n",
      "    p = 3.27207e-11\n",
      "    >>> if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
      "    ...     print(\"The null hypothesis can be rejected\")\n",
      "    ... else:\n",
      "    ...     print(\"The null hypothesis cannot be rejected\")\n",
      "    The null hypothesis can be rejected\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(normaltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "colab_type": "code",
    "id": "2_8hazseumXH",
    "outputId": "605f8634-cefe-4516-b9f6-1493b9905d49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outside</th>\n",
       "      <th>Inside</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outside  Inside\n",
       "0        1       2\n",
       "1        2       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's calculate chi square test statistic, first by hand\n",
    "\n",
    "# 1 male wants to eat outside, 2 inside\n",
    "# 2 females want to eat outside, 1 inside\n",
    "chi_data = [[1, 2], [2, 1]]\n",
    "\n",
    "import pandas as pd\n",
    "chi_data = pd.DataFrame(chi_data, columns=['Outside', 'Inside'])\n",
    "chi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "AeNDtKi4zVck",
    "outputId": "07ace068-9726-4dd2-d947-06243bce8d5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Let's just type out/explain the margin counts\n",
    "# Total number of males (first row) = 3\n",
    "# Total number of females (second row) = 3\n",
    "# Total number of people who prefer outside = 3\n",
    "# Total number of people who prefer inside = 3\n",
    "\n",
    "# Now let's think about margin *proportions*\n",
    "# Proportion of first row = obs / total = (3 males) / (3 males + 3 females)\n",
    "# = 3/6 = 0.5\n",
    "# All the other rows/cols also have 0.5 proportion margins\n",
    "\n",
    "# Expected value for top left cell (males who want to eat outside)\n",
    "# (0.5 (proportion of males) * 0.5 (proportion of outside-eaters)) * 6 = 1.5\n",
    "\n",
    "# Because of symmetry of this little example, we know the expected value of\n",
    "# *all* cells is 1.5 (i.e. the same, because margins are all the same)\n",
    "\n",
    "# chi-square test statistic is the sum of square deviation from these E.V.\n",
    "expected_values = [[1.5, 1.5], [1.5, 1.5]]\n",
    "deviation = (((0.5)**2) / 1.5) * 4  # 0.5^2 deviation per cell, scaled and added\n",
    "print(deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OvMYOmoX2G10"
   },
   "outputs": [],
   "source": [
    "# Close but not all the way\n",
    "# https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CRRDSifm2cvC",
    "outputId": "db60a769-8413-4f9e-aeca-c6e57b035501"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A little bit more properly, but not fully from scratch\n",
    "\n",
    "def lazy_chisquare(observed, expected):\n",
    "  chisquare = 0\n",
    "  for row_obs, row_exp in zip(observed, expected):\n",
    "    for obs, exp in zip(row_obs, row_exp):\n",
    "      chisquare += (obs - exp)**2 / exp\n",
    "  return chisquare\n",
    "\n",
    "chi_data = [[1, 2], [2, 1]]\n",
    "expected_values = [[1.5, 1.5], [1.5, 1.5]]\n",
    "lazy_chisquare(chi_data, expected_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EdvyX9Xt3wQP"
   },
   "outputs": [],
   "source": [
    "# How do we interpret?\n",
    "# https://homepage.divms.uiowa.edu/~mbognar/applets/chisq.html\n",
    "# n-1 degrees of freedom! (where n=number of *cells* in table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XVwZ3BqH1dbN",
    "outputId": "67ee6fc9-52b1-4a07-d612-12a8e62817a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=0.6666666666666666, pvalue=0.8810148425137847)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's run it with scipy so we have a target\n",
    "from scipy.stats import chisquare  # One-way chi square test\n",
    "\n",
    "chisquare(chi_data, axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Ok9AOYR7aBK"
   },
   "outputs": [],
   "source": [
    "#help(stats.t.ppf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qW6k0dorM7Lz"
   },
   "outputs": [],
   "source": [
    "# Confidence intervals!\n",
    "# Similar to hypothesis testing, but centered at sample mean\n",
    "# Generally better than reporting the \"point estimate\" (sample mean)\n",
    "# Why? Because point estimates aren't always perfect\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "  \"\"\"\n",
    "  Calculate a confidence interval around a sample mean for given data.\n",
    "  Using t-distribution and two-tailed test, default 95% confidence. \n",
    "  \n",
    "  Arguments:\n",
    "    data - iterable (list or numpy array) of sample observations\n",
    "    confidence - level of confidence for the interval\n",
    "  \n",
    "  Returns:\n",
    "    tuple of (mean, lower bound, upper bound)\n",
    "  \"\"\"\n",
    "  data = np.array(data)\n",
    "  mean = np.mean(data)\n",
    "  n = len(data)\n",
    "  stderr = stats.sem(data)\n",
    "  interval = stderr * stats.t.ppf((1 + confidence) / 2., n - 1)\n",
    "  return (mean, mean - interval, mean + interval)\n",
    "\n",
    "def report_confidence_interval(confidence_interval):\n",
    "  \"\"\"\n",
    "  Return a string with a pretty report of a confidence interval.\n",
    "  \n",
    "  Arguments:\n",
    "    confidence_interval - tuple of (mean, lower bound, upper bound)\n",
    "  \n",
    "  Returns:\n",
    "    None, but prints to screen the report\n",
    "  \"\"\"\n",
    "  #print('Mean: {}'.format(confidence_interval[0]))\n",
    "  #print('Lower bound: {}'.format(confidence_interval[1]))\n",
    "  #print('Upper bound: {}'.format(confidence_interval[2]))\n",
    "  s = \"our mean lies in the interval [{:.2}, {:.2}]\".format(\n",
    "      confidence_interval[1], confidence_interval[2])\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "996i-p8i7xuO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is: 2\n"
     ]
    }
   ],
   "source": [
    "x = 2\n",
    "print('x is: {}'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "prOAm9iy73tz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1 0 0\n",
      " 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 1\n",
      " 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "coinflips = np.random.binomial(n=1, p=0.7, size=100)\n",
    "print(coinflips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gFCN5Nz7-aJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_1sampResult(statistic=3.8393760982130183, pvalue=0.00021755831055227402)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_1samp(coinflips, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxnZUMca8Srh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.468826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  100.000000\n",
       "mean     0.680000\n",
       "std      0.468826\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(coinflips)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R96w1a1d8XgC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68, 0.5869747161686512, 0.7730252838313489)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coinflip_interval = confidence_interval(coinflips)  # Default 95% conf\n",
    "coinflip_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIAJVwqi8vPL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'our mean lies in the interval [0.59, 0.77]'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_confidence_interval(coinflip_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qBtebUNS7IJe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function confidence_interval in module __main__:\n",
      "\n",
      "confidence_interval(data, confidence=0.95)\n",
      "    Calculate a confidence interval around a sample mean for given data.\n",
      "    Using t-distribution and two-tailed test, default 95% confidence. \n",
      "    \n",
      "    Arguments:\n",
      "      data - iterable (list or numpy array) of sample observations\n",
      "      confidence - level of confidence for the interval\n",
      "    \n",
      "    Returns:\n",
      "      tuple of (mean, lower bound, upper bound)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11OzdxWTM7UR"
   },
   "source": [
    "## Assignment - Build a confidence interval\n",
    "\n",
    "A confidence interval refers to a neighborhood around some point estimate, the size of which is determined by the desired p-value. For instance, we might say that 52% of Americans prefer tacos to burritos, with a 95% confidence interval of +/- 5%.\n",
    "\n",
    "52% (0.52) is the point estimate, and +/- 5% (the interval $[0.47, 0.57]$) is the confidence interval. \"95% confidence\" means a p-value $\\leq 1 - 0.95 = 0.05$.\n",
    "\n",
    "In this case, the confidence interval includes $0.5$ - which is the natural null hypothesis (that half of Americans prefer tacos and half burritos, thus there is no clear favorite). So in this case, we could use the confidence interval to report that we've failed to reject the null hypothesis.\n",
    "\n",
    "But providing the full analysis with a confidence interval, including a graphical representation of it, can be a helpful and powerful way to tell your story. Done well, it is also more intuitive to a layperson than simply saying \"fail to reject the null hypothesis\" - it shows that in fact the data does *not* give a single clear result (the point estimate) but a whole range of possibilities.\n",
    "\n",
    "How is a confidence interval built, and how should it be interpreted? It does *not* mean that 95% of the data lies in that interval - instead, the frequentist interpretation is \"if we were to repeat this experiment 100 times, we would expect the average result to lie in this interval ~95 times.\"\n",
    "\n",
    "For a 95% confidence interval and a normal(-ish) distribution, you can simply remember that +/-2 standard deviations contains 95% of the probability mass, and so the 95% confidence interval based on a given sample is centered at the mean (point estimate) and has a range of +/- 2 (or technically 1.96) standard deviations.\n",
    "\n",
    "Different distributions/assumptions (90% confidence, 99% confidence) will require different math, but the overall process and interpretation (with a frequentist approach) will be the same.\n",
    "\n",
    "Your assignment - using the data from the prior module ([congressional voting records](https://archive.ics.uci.edu/ml/datasets/Congressional+Voting+Records)):\n",
    "\n",
    "1. Generate and numerically represent a confidence interval\n",
    "2. Graphically (with a plot) represent the confidence interval\n",
    "3. Interpret the confidence interval - what does it tell you about the data and its distribution?\n",
    "\n",
    "Stretch goals:\n",
    "\n",
    "1. Write a summary of your findings, mixing prose and math/code/results. *Note* - yes, this is by definition a political topic. It is challenging but important to keep your writing voice *neutral* and stick to the facts of the data. Data science often involves considering controversial issues, so it's important to be sensitive about them (especially if you want to publish).\n",
    "2. Apply the techniques you learned today to your project data or other data of your choice, and write/discuss your findings here.\n",
    "3. Refactor your code so it is elegant, readable, and can be easily run for all issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ckcr4A4FM7cs",
    "outputId": "089c0534-ab10-416d-947c-4e1b78ddf59d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.455564635349653, 9.377768697983681)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO - your code!\n",
    "st = scipy.stats\n",
    "a = [0, 2, 4, 4, 8, 5, 2, 11, 5, 8, 13, 15]\n",
    "st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0s6t3uhbT9EV"
   },
   "outputs": [],
   "source": [
    "votedf = pd.read_excel('vote_record_1985.xls')\n",
    "repdf = votedf[votedf['Party'] == 'republican']\n",
    "demdf = votedf[votedf['Party'] == 'democrat']\n",
    "letters_to_numbers = {'n': 0, 'y': 1, '?':np.nan}\n",
    "votedf = votedf.replace(letters_to_numbers)\n",
    "nulldf = votedf[pd.isna(votedf).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-bafa790ce767>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-bafa790ce767>\"\u001b[0;36m, line \u001b[0;32m24\u001b[0m\n\u001b[0;31m    for i in range (1, len(issuelist)):\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "issuelist = ('Adoption of the budget resolution',\n",
    "             'Aid to contras', 'Anti satellite test ban',\n",
    "             'Crime', 'Duty-free exports', 'Education spending',\n",
    "             'El Salvador aid', 'Export admin act South Africa',\n",
    "             'Handicapped infants', 'Immigration', 'Mx missile',\n",
    "             'Physician fee freeze', 'Religious groups in schools',\n",
    "             'Superfund right to sue', 'Synfuels cutback', 'Water project cost sharing')\n",
    "\n",
    "print (len(issuelist))\n",
    "st = scipy.stats\n",
    "\n",
    "rep_issues_at_99 = {}\n",
    "rep_issues_at_95 = {}\n",
    "rep_issues_at_90 = {}\n",
    "\n",
    "dem_issues_at_99 = {}\n",
    "dem_issues_at_95 = {}\n",
    "dem_issues_at_90 = {}\n",
    "\n",
    "for i in range (1, len(issuelist)):\n",
    "    rep_issues_at_99[issuelist[i]] = st.t.interval(0.99, len(repdf[issuelist[i]]-1), loc=np.mean(repdf[issuelist[i]], scale = st.sem(repdf[issuelist[i]],\n",
    "    dem_issues_at_99[issuelist[i]] = st.t.interval(0.99, len(demdf[issuelist[i]]-1), loc=np.mean(demdf[issuelist[i]], scale = st.sem(demdf[issuelist[i]]\n",
    "  \n",
    "for i in range (1, len(issuelist)):\n",
    "    rep_issues_at_95[issuelist[i]] = st.t.interval(0.95, len(repdf[issuelist[i]]-1), loc=np.mean(repdf[issuelist[i]], scale = st.sem(repdf[issuelist[i]],\n",
    "    dem_issues_at_95[issuelist[i]] = st.t.interval(0.95, len(demdf[issuelist[i]]-1), loc=np.mean(demdf[issuelist[i]], scale = st.sem(demdf[issuelist[i]]  \n",
    "  \n",
    "for i in range (1, len(issuelist)):\n",
    "    rep_issues_at_90[issuelist[i]] = st.t.interval(0.90, len(repdf[issuelist[i]]-1), loc=np.mean(repdf[issuelist[i]], scale = st.sem(repdf[issuelist[i]],\n",
    "    dem_issues_at_90[issuelist[i]] = st.t.interval(0.90, len(demdf[issuelist[i]]-1), loc=np.mean(demdf[issuelist[i]], scale = st.sem(demdf[issuelist[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of LS_DS2_142_Sampling_Confidence_Intervals_and_Hypothesis_Testing.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
