{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_143_Introduction_to_Bayesian_Inference.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "H7OLbevlbd_Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lambda School Data Science Module 143\n",
        "\n",
        "## Introduction to Bayesian Inference\n",
        "\n",
        "!['Detector! What would the Bayesian statistician say if I asked him whether the--' [roll] 'I AM A NEUTRINO DETECTOR, NOT A LABYRINTH GUARD. SERIOUSLY, DID YOUR BRAIN FALL OUT?' [roll] '... yes.'](https://imgs.xkcd.com/comics/frequentists_vs_bayesians_2x.png)\n",
        "\n",
        "*[XKCD 1132](https://www.xkcd.com/1132/)*\n"
      ]
    },
    {
      "metadata": {
        "id": "3mz8p08BsN6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare - Bayes' Theorem and the Bayesian mindset"
      ]
    },
    {
      "metadata": {
        "id": "GhycNr-Sbeie",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Bayes' theorem possesses a near-mythical quality - a bit of math that somehow magically evaluates a situation. But this mythicalness has more to do with its reputation and advanced applications than the actual core of it - deriving it is actually remarkably straightforward.\n",
        "\n",
        "### The Law of Total Probability\n",
        "\n",
        "By definition, the total probability of all outcomes (events) if some variable (event space) $A$ is 1. That is:\n",
        "\n",
        "$$P(A) = \\sum_n P(A_n) = 1$$\n",
        "\n",
        "The law of total probability takes this further, considering two variables ($A$ and $B$) and relating their marginal probabilities (their likelihoods considered independently, without reference to one another) and their conditional probabilities (their likelihoods considered jointly). A marginal probability is simply notated as e.g. $P(A)$, while a conditional probability is notated $P(A|B)$, which reads \"probability of $A$ *given* $B$\".\n",
        "\n",
        "The law of total probability states:\n",
        "\n",
        "$$P(A) = \\sum_n P(A | B_n) P(B_n)$$\n",
        "\n",
        "In words - the total probability of $A$ is equal to the sum of the conditional probability of $A$ on any given event $B_n$ times the probability of that event $B_n$, and summed over all possible events in $B$.\n",
        "\n",
        "### The Law of Conditional Probability\n",
        "\n",
        "What's the probability of something conditioned on something else? To determine this we have to go back to set theory and think about the intersection of sets:\n",
        "\n",
        "The formula for actual calculation:\n",
        "\n",
        "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
        "\n",
        "We can see how this relates back to the law of total probability - multiply both sides by $P(B)$ and you get $P(A|B)P(B) = P(A \\cap B)$ - replaced back into the law of total probability we get $P(A) = \\sum_n P(A \\cap B_n)$.\n",
        "\n",
        "This may not seem like an improvement at first, but try to relate it back to the above picture - if you think of sets as physical objects, we're saying that the total probability of $A$ given $B$ is all the little pieces of it intersected with $B$, added together. The conditional probability is then just that again, but divided by the probability of $B$ itself happening in the first place.\n",
        "\n",
        "### Bayes Theorem\n",
        "\n",
        "Here is is, the seemingly magic tool:\n",
        "\n",
        "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
        "\n",
        "In words - the probability of $A$ conditioned on $B$ is the probability of $B$ conditioned on $A$, times the probability of $A$ and divided by the probability of $B$. These unconditioned probabilities are referred to as \"prior beliefs\", and the conditioned probabilities as \"updated.\"\n",
        "\n",
        "Why is this important? Scroll back up to the XKCD example - the Bayesian statistician draws a less absurd conclusion because their prior belief in the likelihood that the sun will go nova is extremely low. So, even when updated based on evidence from a detector that is $35/36 = 0.972$ accurate, the prior belief doesn't shift enough to change their overall opinion.\n",
        "\n",
        "There's many examples of Bayes' theorem - one less absurd example is to apply to [breathalyzer tests](https://www.bayestheorem.net/breathalyzer-example/). You may think that a breathalyzer test that is 100% accurate for true positives (detecting somebody who is drunk) is pretty good, but what if it also has 8% false positives (indicating somebody is drunk when they're not)? And furthermore, the rate of drunk driving (and thus our prior belief)  is 1/1000.\n",
        "\n",
        "What is the likelihood somebody really is drunk if they test positive? Some may guess it's 92% - the difference between the true positives and the false positives. But we have a prior belief of the background/true rate of drunk driving. Sounds like a job for Bayes' theorem!\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "P(Drunk | Positive) &= \\frac{P(Positive | Drunk)P(Drunk)}{P(Positive)} \\\\\n",
        "&= \\frac{1 \\times 0.001}{0.08} \\\\\n",
        "&= 0.0125\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "In other words, the likelihood that somebody is drunk given they tested positive with a breathalyzer in this situation is only 1.25% - probably much lower than you'd guess. This is why, in practice, it's important to have a repeated test to confirm (the probability of two false positives in a row is $0.08 * 0.08 = 0.0064$, much lower), and Bayes' theorem has been relevant in court cases where proper consideration of evidence was important."
      ]
    },
    {
      "metadata": {
        "id": "htI3DGvDsRJF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Live Lecture - Deriving Bayes' Theorem, Calculating Bayesian Confidence"
      ]
    },
    {
      "metadata": {
        "id": "moIJNQ-nbfe_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice that $P(A|B)$ appears in the above laws - in Bayesian terms, this is the belief in $A$ updated for the evidence $B$. So all we need to do is solve for this term to derive Bayes' theorem. Let's do it together!"
      ]
    },
    {
      "metadata": {
        "id": "ke-5EqJI0Tsn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Activity 2 - Use SciPy to calculate Bayesian confidence intervals\n",
        "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bayes_mvs.html#scipy.stats.bayes_mvs\n",
        "\n",
        "#From frequentist approach - yesterday's notebook\n",
        "def confidence_interval(data, confidence=0.95):\n",
        "    \"\"\"\n",
        "    We want to Calculate a confidence interval around a sample mean for\n",
        "    given data.\n",
        "    Using t-distribution and two-tailed test, default 95% confidence.\n",
        "    \n",
        "    Arguments:\n",
        "      data - iterable (list or numpy array) of sample observations\n",
        "      confidence - level of confidence for the interval\n",
        "      \n",
        "    Returns:\n",
        "      tuple of (mean, lower bound, upper bound)\n",
        "    \"\"\"\n",
        "    data = np.array(data)\n",
        "    mean = np.mean(data)\n",
        "    n = len(data)\n",
        "    stderr = stats.sem(data) # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.sem.html\n",
        "    interval = stderr * stats.t.ppf((1 + confidence) / 2., n - 1) #dividing by 2 cause it's 2tailed\n",
        "    # stats.t.ppf = gives the probability density function\n",
        "    return (mean, mean - interval, mean + interval)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3gb1nSc_maBL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "58YQwtvXmaFd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "coinflips = np.random.binomial(n=1, p=0.5, size=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F2i1zNNDmaMl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "dbbd5bc5-39f8-485c-e4bd-66b9436d16bc"
      },
      "cell_type": "code",
      "source": [
        "# More conservative interval - broader interval with frequentist approach vs Bayesian \n",
        "confidence_interval(coinflips)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.49, 0.39030929062808245, 0.5896907093719175)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "xgZOT630maKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "f41abd17-79f8-4d9e-c195-14f2e17580c8"
      },
      "cell_type": "code",
      "source": [
        "# Also gives stdev and variance with their interval\n",
        "# See cell below and see how it matches stdev by pandas\n",
        "stats.bayes_mvs(coinflips)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Mean(statistic=0.49, minmax=(0.40657889423317223, 0.5734211057668277)),\n",
              " Variance(statistic=0.2576288659793814, minmax=(0.20279939208271736, 0.32435028891692574)),\n",
              " Std_dev(statistic=0.506265071182084, minmax=(0.45033253500354303, 0.5695175931583902)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "4F-_GBwmnVtJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "c70f9be6-d2f1-4f0e-e248-1e59d7346168"
      },
      "cell_type": "code",
      "source": [
        "pd.DataFrame(coinflips).describe()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.490000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.502418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                0\n",
              "count  100.000000\n",
              "mean     0.490000\n",
              "std      0.502418\n",
              "min      0.000000\n",
              "25%      0.000000\n",
              "50%      0.000000\n",
              "75%      1.000000\n",
              "max      1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "cCjlukPlnhgT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "f85484bd-2765-4ff4-aeb3-3b060516760c"
      },
      "cell_type": "code",
      "source": [
        "# Let's do something else medical\n",
        "\n",
        "# Generating some data - condition that you recover from or don't and a treatment that you take or not\n",
        "# Treated people recover with prob of .65\n",
        "# Non-treated recover with prob .4\n",
        "\n",
        "treatment_group =  np.random.binomial(n=1, p=0.65, size=100)\n",
        "nontreated_group = np.random.binomial(n=1, p=0.4, size=100)\n",
        "\n",
        "print(treatment_group)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 1 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 1 1 0\n",
            " 1 1 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1\n",
            " 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6lBS-dmcnhnt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'treated': treatment_group, 'untreated':nontreated_group})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g6V2MXHYnhtH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "2513cfd6-d09e-44c6-db0c-fc2f7959feab"
      },
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>treated</th>\n",
              "      <th>untreated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.660000</td>\n",
              "      <td>0.420000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.476095</td>\n",
              "      <td>0.496045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          treated   untreated\n",
              "count  100.000000  100.000000\n",
              "mean     0.660000    0.420000\n",
              "std      0.476095    0.496045\n",
              "min      0.000000    0.000000\n",
              "25%      0.000000    0.000000\n",
              "50%      1.000000    0.000000\n",
              "75%      1.000000    1.000000\n",
              "max      1.000000    1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "GnECRROeniLA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e7a1bfb1-19a3-4a21-8338-70a4d675ce85"
      },
      "cell_type": "code",
      "source": [
        "# Frequentists hypothesis test\n",
        "stats.ttest_ind(df.treated, df.untreated)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=3.490646843296438, pvalue=0.0005939845864903332)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "dxJrfcMWniPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "e8649d81-c90d-4c15-df30-306970826ba4"
      },
      "cell_type": "code",
      "source": [
        "# Confidence intervals between treated and untreated groups don't even overlap\n",
        "# Statisticatly significance going on!\n",
        "# Meaning their means are very different\n",
        "# We reject the null\n",
        "# When we would to reject the null? = when the intervals overlap\n",
        "stats.bayes_mvs(df.treated)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Mean(statistic=0.66, minmax=(0.5809495693071084, 0.7390504306928917)),\n",
              " Variance(statistic=0.23134020618556705, minmax=(0.1821055765640728, 0.29125332066009674)),\n",
              " Std_dev(statistic=0.4797403673067261, minmax=(0.4267382998560978, 0.5396789051464738)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "cU5KbtEZnhl1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "7b3d0078-0abf-4269-8076-c7bd3ff383a7"
      },
      "cell_type": "code",
      "source": [
        "stats.bayes_mvs(df.untreated)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Mean(statistic=0.42, minmax=(0.33763713292148456, 0.5023628670785154)),\n",
              " Variance(statistic=0.2511340206185568, minmax=(0.19768680236634642, 0.3161733908770034)),\n",
              " Std_dev(statistic=0.4998428440976869, minmax=(0.4446198402752023, 0.5622929760160653)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "s7C9RUy_nhkK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# SUGGESTED TASK -> Write your own Bayes test function that compares CIs from stats.bayes_mvs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P-DzzRk5bf0z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment - Code it up!\n",
        "\n",
        "Most of the above was pure math - write Python code to reproduce the results. This is purposefully open ended - you'll have to think about how you should represent probabilities and events. You can and should look things up, and as a stretch goal - refactor your code into helpful reusable functions!\n",
        "\n",
        "If you're unsure where to start, check out [this blog post of Bayes theorem with Python](https://dataconomy.com/2015/02/introduction-to-bayes-theorem-with-python/) - you could and should create something similar!\n",
        "\n",
        "Stretch goal - apply a Bayesian technique to a problem you previously worked (in an assignment or project work) on from a frequentist (standard) perspective."
      ]
    },
    {
      "metadata": {
        "id": "xpVhZyUnbf7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO - code!\n",
        "#help(stats.bayes_mvs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jaEBQuyhTeas",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SYDByJEpVKgl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You might be interested in finding out a patient’s probability of having liver disease if they are an alcoholic. “Being an alcoholic” is the __test__ (kind of like a litmus test) for liver disease.\n",
        "\n",
        "__A__ could mean the event “Patient has liver disease.” Past data tells you that 10% of patients entering your clinic have liver disease. P(A) = 0.10.\n",
        "\n",
        "__B__ could mean the litmus test that “Patient is an alcoholic.” Five percent of the clinic’s patients are alcoholics. P(B) = 0.05.\n",
        "\n",
        "You might also know that among those patients diagnosed with liver disease, 7% are alcoholics. This is your __B|A__: the probability that a patient is alcoholic, given that they have liver disease, is 7%.\n",
        "\n",
        "Bayes’ theorem tells you:\n",
        "__P(A|B) = (0.07 * 0.1)/0.05 = 0.14__\n",
        "    \n",
        "In other words, if the patient is an alcoholic, their chances of having liver disease is 0.14 (14%). This is a large increase from the 10% suggested by past data. But it’s still unlikely that any particular patient has liver disease."
      ]
    },
    {
      "metadata": {
        "id": "nrxNQGWLVxWg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "liver_disease =  np.random.binomial(n=1, p=0.10, size=100)\n",
        "alcoholic = np.random.binomial(n=1, p=0.05, size=100)\n",
        "\n",
        "print(treatment_group)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2KOk8Gsgx3od",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction to Bayes Theorem in Python - [Article here](https://dataconomy.com/2015/02/introduction-to-bayes-theorem-with-python/)\n",
        "\n",
        "\n",
        "$P(A|B)*P(B) = P(B|A)*P(A)$\n",
        "\n",
        "Which implies:\n",
        "\n",
        "$P(A|B) = \\dfrac{P(B|A)*P(A)}{P(B)}$\n",
        "\n",
        "And plug in $θ$ for $A$ and $X$ for $B$:\n",
        "\n",
        "$P(\\theta|X) = \\dfrac{P(X|\\theta)*P(\\theta)}{P(X)}$\n",
        "\n",
        "Nice! Now we can plug in some terminology we know:\n",
        "\n",
        "$Posterior = \\dfrac{likelihood * prior}{P(X)}$\n",
        "\n",
        "But what is the $P(X)?$ Or in English, the probability of our data? That sounds weird… Let’s go back to some math and use B and A again:\n",
        "\n",
        "We know that $P(B)=∑AP(A,B)$ (check out [this page](http://en.wikipedia.org/wiki/Marginal_distribution) for a refresher)\n",
        "\n",
        "And from our definitions above, we know that:\n",
        "\n",
        "$P(A,B) = P(A|B)*P(A)$\n",
        "\n",
        "Thus:\n",
        "\n",
        "$P(B) = \\sum_{A} P(A|B)*P(A)$\n",
        "\n",
        "Plug in our $θ$ and $X$:\n",
        "\n",
        "$P(X) = \\sum_{\\theta} P(\\theta|X)*P(\\theta)$\n",
        "\n",
        "Plug in our terminology:\n",
        "\n",
        "$P(X) = \\sum_{\\theta} likelihood * prior$\n",
        "\n",
        "But what do we mean by $∑θ$. This means to sum over all the values of our parameters. _In our coin flip example, we defined 100 values for our parameter p_, so we would have to calculate __the likelihood * prior for each of these values and sum all those anwers__. That is our denominator for Bayes Theorem. Thus our final answer for Bayes is:\n",
        "\n",
        "$Posterior = \\dfrac{likelihood * prior}{\\sum_{\\theta} likelihood * prior}$"
      ]
    },
    {
      "metadata": {
        "id": "NZKALPlwx5Ms",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}