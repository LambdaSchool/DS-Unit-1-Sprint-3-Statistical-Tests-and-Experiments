{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/DanielMartinAlarcon/DS-Unit-1-Sprint-4-Statistical-Tests-and-Experiments/blob/master/module3-introduction-to-bayesian-inference/LS_DS_143_Introduction_to_Bayesian_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H7OLbevlbd_Z"
   },
   "source": [
    "# Lambda School Data Science Module 143\n",
    "\n",
    "## Introduction to Bayesian Inference\n",
    "\n",
    "!['Detector! What would the Bayesian statistician say if I asked him whether the--' [roll] 'I AM A NEUTRINO DETECTOR, NOT A LABYRINTH GUARD. SERIOUSLY, DID YOUR BRAIN FALL OUT?' [roll] '... yes.'](https://imgs.xkcd.com/comics/frequentists_vs_bayesians.png)\n",
    "\n",
    "*[XKCD 1132](https://www.xkcd.com/1132/)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3mz8p08BsN6p"
   },
   "source": [
    "## Prepare - Bayes' Theorem and the Bayesian mindset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GhycNr-Sbeie"
   },
   "source": [
    "Bayes' theorem possesses a near-mythical quality - a bit of math that somehow magically evaluates a situation. But this mythicalness has more to do with its reputation and advanced applications than the actual core of it - deriving it is actually remarkably straightforward.\n",
    "\n",
    "### The Law of Total Probability\n",
    "\n",
    "By definition, the total probability of all outcomes (events) if some variable (event space) $A$ is 1. That is:\n",
    "\n",
    "$$P(A) = \\sum_n P(A_n) = 1$$\n",
    "\n",
    "The law of total probability takes this further, considering two variables ($A$ and $B$) and relating their marginal probabilities (their likelihoods considered independently, without reference to one another) and their conditional probabilities (their likelihoods considered jointly). A marginal probability is simply notated as e.g. $P(A)$, while a conditional probability is notated $P(A|B)$, which reads \"probability of $A$ *given* $B$\".\n",
    "\n",
    "The law of total probability states:\n",
    "\n",
    "$$P(A) = \\sum_n P(A | B_n) P(B_n)$$\n",
    "\n",
    "In words - the total probability of $A$ is equal to the sum of the conditional probability of $A$ on any given event $B_n$ times the probability of that event $B_n$, and summed over all possible events in $B$.\n",
    "\n",
    "### The Law of Conditional Probability\n",
    "\n",
    "What's the probability of something conditioned on something else? To determine this we have to go back to set theory and think about the intersection of sets:\n",
    "\n",
    "The formula for actual calculation:\n",
    "\n",
    "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
    "\n",
    "We can see how this relates back to the law of total probability - multiply both sides by $P(B)$ and you get $P(A|B)P(B) = P(A \\cap B)$ - replaced back into the law of total probability we get $P(A) = \\sum_n P(A \\cap B_n)$.\n",
    "\n",
    "This may not seem like an improvement at first, but try to relate it back to the above picture - if you think of sets as physical objects, we're saying that the total probability of $A$ given $B$ is all the little pieces of it intersected with $B$, added together. The conditional probability is then just that again, but divided by the probability of $B$ itself happening in the first place.\n",
    "\n",
    "### Bayes Theorem\n",
    "\n",
    "Here is is, the seemingly magic tool:\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "In words - the probability of $A$ conditioned on $B$ is the probability of $B$ conditioned on $A$, times the probability of $A$ and divided by the probability of $B$. These unconditioned probabilities are referred to as \"prior beliefs\", and the conditioned probabilities as \"updated.\"\n",
    "\n",
    "Why is this important? Scroll back up to the XKCD example - the Bayesian statistician draws a less absurd conclusion because their prior belief in the likelihood that the sun will go nova is extremely low. So, even when updated based on evidence from a detector that is $35/36 = 0.972$ accurate, the prior belief doesn't shift enough to change their overall opinion.\n",
    "\n",
    "There's many examples of Bayes' theorem - one less absurd example is to apply to [breathalyzer tests](https://www.bayestheorem.net/breathalyzer-example/). You may think that a breathalyzer test that is 100% accurate for true positives (detecting somebody who is drunk) is pretty good, but what if it also has 8% false positives (indicating somebody is drunk when they're not)? And furthermore, the rate of drunk driving (and thus our prior belief)  is 1/1000.\n",
    "\n",
    "What is the likelihood somebody really is drunk if they test positive? Some may guess it's 92% - the difference between the true positives and the false positives. But we have a prior belief of the background/true rate of drunk driving. Sounds like a job for Bayes' theorem!\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(Drunk | Positive) &= \\frac{P(Positive | Drunk)P(Drunk)}{P(Positive)} \\\\\n",
    "&= \\frac{1 \\times 0.001}{0.08} \\\\\n",
    "&= 0.0125\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "In other words, the likelihood that somebody is drunk given they tested positive with a breathalyzer in this situation is only 1.25% - probably much lower than you'd guess. This is why, in practice, it's important to have a repeated test to confirm (the probability of two false positives in a row is $0.08 * 0.08 = 0.0064$, much lower), and Bayes' theorem has been relevant in court cases where proper consideration of evidence was important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "htI3DGvDsRJF"
   },
   "source": [
    "## Live Lecture - Deriving Bayes' Theorem, Calculating Bayesian Confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "moIJNQ-nbfe_"
   },
   "source": [
    "Notice that $P(A|B)$ appears in the above laws - in Bayesian terms, this is the belief in $A$ updated for the evidence $B$. So all we need to do is solve for this term to derive Bayes' theorem. Let's do it together!\n",
    "\n",
    "$x = 2$ is an inline equation.\n",
    "\n",
    "$$\n",
    "x = 2\n",
    "$$\n",
    "\n",
    "is a block equation.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x &= 2 \\\\\n",
    "&= 1 + 1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Now let's derive Bayes!\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "P(A \\cap B) &= P(B \\cap A) \\\\\n",
    "\\\\\n",
    "P(A|B) &= \\frac{P(A \\cap B)}{P(B)} \\\\\n",
    "\\Rightarrow P(A|B)P(B) &= P(A \\cap B) \\\\\n",
    "P(B|A) &= \\frac{P(B \\cap A)}{P(A)} \\\\\n",
    "\\Rightarrow P(B|A)P(A) &= P(B \\cap A) = P(A \\cap B) \\\\\n",
    "\\Rightarrow P(A|B)P(B) &= P(B|A)P(A) \\\\\n",
    "\\Rightarrow P(A|B)&= \\frac{P(B|A)P(A)}{P(B)}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "ke-5EqJI0Tsn",
    "outputId": "c6f027e2-da5c-40eb-a32a-3f31110d90c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 1 1 0 1 1\n",
      " 0 1 1 0 0 1 1 1 0 0 0 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0 0 0 0 0 1 1 0 0 1\n",
      " 1 1 0 0 1 1 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Activity 2 - Use SciPy to calculate Bayesian confidence intervals\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bayes_mvs.html#scipy.stats.bayes_mvs\n",
    "\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "coinflips = np.random.binomial(n=1, p=0.5, size=100)\n",
    "print(coinflips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jL7qqrafmMEY",
    "outputId": "42aa3b94-a844-4d06-d794-272c11cca9c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48, 0.38036914695852936, 0.5796308530414707)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequentist approach (from yesterday)\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "  \"\"\"\n",
    "  Calculate a confidence interval around a sample mean for given data.\n",
    "  Using t-distribution and two-tailed test, default 95% confidence. \n",
    "  \n",
    "  Arguments:\n",
    "    data - iterable (list or numpy array) of sample observations\n",
    "    confidence - level of confidence for the interval\n",
    "  \n",
    "  Returns:\n",
    "    tuple of (mean, lower bound, upper bound)\n",
    "  \"\"\"\n",
    "  data = np.array(data)\n",
    "  mean = np.mean(data)\n",
    "  n = len(data)\n",
    "  stderr = stats.sem(data)\n",
    "  interval = stderr * stats.t.ppf((1 + confidence) / 2., n - 1)\n",
    "  return (mean, mean - interval, mean + interval)\n",
    "\n",
    "confidence_interval(coinflips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "TsUDVTHQnMR_",
    "outputId": "f284e9d7-1ef0-4888-9d56-0aa511b3d44a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.502117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  100.000000\n",
       "mean     0.480000\n",
       "std      0.502117\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      0.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(coinflips).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "VR5B9HHSmchp",
    "outputId": "52a689c2-93f9-4d8a-afec-2fc2a189f378"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Mean(statistic=0.48, minmax=(0.3966289819625553, 0.5633710180374446)),\n",
       " Variance(statistic=0.2573195876288659, minmax=(0.20255593542955685, 0.3239609128197866)),\n",
       " Std_dev(statistic=0.5059610993316946, minmax=(0.45006214618600937, 0.5691756432067228)))"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.bayes_mvs(coinflips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "Vlqae8ZqmqBh",
    "outputId": "480894db-fbba-4587-8fe3-b0062bdab0bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Let's do something else medical\n",
    "import random\n",
    "\n",
    "# We have two groups of people, one treated one non-treated\n",
    "# Treated people recover with probability 0.65\n",
    "# Non-treated people recover with probability 0.4\n",
    "treatment_group = np.random.binomial(n=1, p=0.65, size=40)\n",
    "nontreated_group = np.random.binomial(n=1, p=0.4, size=40)\n",
    "\n",
    "print(treatment_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "EHnC227wq6WA",
    "outputId": "8418afc4-4a15-4335-d5a4-1f8812fcc62c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treated</th>\n",
       "      <th>untreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.452203</td>\n",
       "      <td>0.474342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         treated  untreated\n",
       "count  40.000000  40.000000\n",
       "mean    0.725000   0.325000\n",
       "std     0.452203   0.474342\n",
       "min     0.000000   0.000000\n",
       "25%     0.000000   0.000000\n",
       "50%     1.000000   0.000000\n",
       "75%     1.000000   1.000000\n",
       "max     1.000000   1.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'treated': treatment_group,\n",
    "                   'untreated': nontreated_group})\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "r2BImsQhrJcG",
    "outputId": "6c60eaf8-a0d0-4012-9dc2-d33ce1b86635"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treated</th>\n",
       "      <th>untreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treated  untreated\n",
       "0        1          1\n",
       "1        1          1\n",
       "2        1          0\n",
       "3        0          1\n",
       "4        1          1"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "GWOO804dr9Dj",
    "outputId": "74211e83-99bd-470c-b3f5-327f15249f99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=3.8602451395362736, pvalue=0.0002321740575055488)"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequentist hypothesis test\n",
    "from scipy import stats\n",
    "stats.ttest_ind(df.treated, df.untreated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "TTlkpwAht6_x",
    "outputId": "f1da5b67-03de-41f0-b00f-014851557674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Mean(statistic=0.725, minmax=(0.6045322597650726, 0.8454677402349273)),\n",
       " Variance(statistic=0.2155405405405406, minmax=(0.14613660331455472, 0.3103669520480209)),\n",
       " Std_dev(statistic=0.46113747645565806, minmax=(0.382278175305045, 0.5571058714894511)))"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.bayes_mvs(df.treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "b1T_lU1auPQq",
    "outputId": "be787b08-72d4-43b8-912b-66cb46ee0693"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Mean(statistic=0.325, minmax=(0.198634366037695, 0.451365633962305)),\n",
       " Variance(statistic=0.23716216216216224, minmax=(0.16079607449344424, 0.3415009409681986)),\n",
       " Std_dev(statistic=0.4837139755627448, minmax=(0.40099385842359764, 0.5843808184464978)))"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.bayes_mvs(df.untreated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sLWQbmscuvdk"
   },
   "outputs": [],
   "source": [
    "# Suggested task - write your own Bayes test function\n",
    "# that compares CIs from stats.bayes_mvs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-DzzRk5bf0z"
   },
   "source": [
    "\n",
    "## Assignment - Code it up!\n",
    "\n",
    "Most of the above was pure math - write Python code to reproduce the results. This is purposefully open ended - you'll have to think about how you should represent probabilities and events. You can and should look things up, and as a stretch goal - refactor your code into helpful reusable functions!\n",
    "\n",
    "If you're unsure where to start, check out [this blog post of Bayes theorem with Python](https://dataconomy.com/2015/02/introduction-to-bayes-theorem-with-python/) - you could and should create something similar!\n",
    "\n",
    "Stretch goal - apply a Bayesian technique to a problem you previously worked (in an assignment or project work) on from a frequentist (standard) perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Political party predictor\n",
    "Using the congressional voting database from earlier this week, I'm going to graphically show how a particular candidate's voting record helps us predict whether they are a republican or democrat.  When you encounter a new congressperson, you may not know whether they are R or D. As they vote on important issues, though, each vote updates your beliefs about their affiliation.  You start out just knowing the relative proportions of R's and D's, but for each vote you can update based on whether that vote matched the party line or not.  How much to update depends on how partisan the issue is. For a new candidate, how many votes will it take to determine with 95% confidence what party they belong to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data' \n",
    "names = ['party','handicapped-infants','water-project-cost-sharing','adoption-of-the-budget-resolution','physician-fee-freeze','el-salvador-aid','religious-groups-in-schools','anti-satellite-test-ban','aid-to-nicaraguan-contras','mx-missile','immigration','synfuels-corporation-cutback','education-spending','superfund-right-to-sue','crime','duty-free-exports','export-administration-act-south-africa']\n",
    "issues = names[1:]\n",
    "roster = pd.read_csv(url, na_values='?', names=names)\n",
    "roster.replace(['y','n'],[1,-1], inplace=True)\n",
    "\n",
    "reps = roster[roster.party == 'republican']\n",
    "dems = roster[roster.party == 'democrat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine a congressperson, Alice, of unknown party affiliation.  How many of her votes in this dataset do we need to uncover in order to be reasonably sure of her party?\n",
    "\n",
    "Eur first guess (our prior) about her party affiliation should be the current split in congress. This is probability that Alice is a Democrat:\n",
    "\n",
    "$P(Dem) = \\dfrac{current\\:Democrats}{total\\:current\\:congresspeople}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6137931034482759"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(Dem)\n",
    "prob_dem = len(dems)/len(roster)\n",
    "prob_dem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, then.  We start with a  a prior belief that Alice is 61.3% likely to be a Democrat.\n",
    "\n",
    "Now, let's start uncovering her voting record.  How should we update our beliefs for each new issue in which she votes?  For any new vote, our update should follow Bayes' Rule:\n",
    "\n",
    "$P(Dem|Vote) = \\dfrac{P(Vote|Dem)*P(Dem)}{P(Vote)}$\n",
    "\n",
    "$P(Dem)$ represents our prior belief that she's a democrat. This parameter will change with each update, as we learn more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(Vote|Dem)\n",
    "def prob_vote_given_dem(issue, vote):\n",
    "    \"\"\"\n",
    "    Calculates the probability that a democrat voted a given way for a given issue. \n",
    "    Vote should be -1 for no, 1 for yes. Note that here we're only considering\n",
    "    yes and no votes; we ignore all the NaNs.\n",
    "    \"\"\"\n",
    "    dem_votes = len(dems[dems[issue] == vote]) # Dems who voted that way\n",
    "    dem_opposite_votes = len(dems[dems[issue] == -vote]) # Dems that voted the opposite\n",
    "    \n",
    "    return dem_votes / (dem_votes + dem_opposite_votes) \n",
    "\n",
    "\n",
    "# P(Vote)\n",
    "def prob_vote(issue, vote):\n",
    "    \"\"\"\n",
    "    Calculates the probability of a given vote for a given issue. \n",
    "    Vote should be -1 for no, 1 for yes.\n",
    "    \"\"\"\n",
    "    votes = len(roster[roster[issue] == vote])\n",
    "    opposite_votes = len(roster[roster[issue] == -vote])\n",
    "    \n",
    "    return votes / (votes + opposite_votes) \n",
    "\n",
    "\n",
    "# P(Dem|Vote)\n",
    "def dem_given_vote(prior, issue, vote):\n",
    "    \"\"\"\n",
    "    Updates our expected probability that a candidate is a democrat, based on their voting record.\n",
    "    \n",
    "    Inputs:\n",
    "    prior (float in the unit interval) - prior probability, based on all pre-existing knowledge\n",
    "    issue (string) - one of the issues in the DataFrame roster\n",
    "    vote (0 or 1) - Their vote; -1 for no, 1 for yes.\n",
    "    \n",
    "    Returns:\n",
    "    Updated probability\n",
    "    \"\"\"\n",
    "    posterior = prob_vote_given_dem(issue, vote) * prior / prob_vote(issue, vote)\n",
    "    return posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And so, starting with our initial prior of P(Dem), we can start updating our best guess for each new vote.  Let's look at the real voting record of one random congressperson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "party                                     democrat\n",
       "handicapped-infants                             -1\n",
       "water-project-cost-sharing                      -1\n",
       "adoption-of-the-budget-resolution                1\n",
       "physician-fee-freeze                            -1\n",
       "el-salvador-aid                                 -1\n",
       "religious-groups-in-schools                      1\n",
       "anti-satellite-test-ban                          1\n",
       "aid-to-nicaraguan-contras                        1\n",
       "mx-missile                                       1\n",
       "immigration                                      1\n",
       "synfuels-corporation-cutback                    -1\n",
       "education-spending                               1\n",
       "superfund-right-to-sue                          -1\n",
       "crime                                            1\n",
       "duty-free-exports                                1\n",
       "export-administration-act-south-africa         NaN\n",
       "Name: 234, dtype: object"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roster.loc[234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Issue: handicapped-infants\n",
      "Vote:     -1.0\n",
      "Prior:     0.614\n",
      "Posterior: 0.435\n",
      "P(Vote|Dem): 0.395\n",
      "P(Vote): 0.558\n",
      "P(Dem|Vote): 0.435\n",
      "\n",
      "Issue: water-project-cost-sharing\n",
      "Vote:     -1.0\n",
      "Prior:     0.435\n",
      "Posterior: 0.437\n",
      "P(Vote|Dem): 0.498\n",
      "P(Vote): 0.496\n",
      "P(Dem|Vote): 0.437\n",
      "\n",
      "Issue: adoption-of-the-budget-resolution\n",
      "Vote:      1.0\n",
      "Prior:     0.437\n",
      "Posterior: 0.65\n",
      "P(Vote|Dem): 0.888\n",
      "P(Vote): 0.597\n",
      "P(Dem|Vote): 0.65\n",
      "\n",
      "Issue: physician-fee-freeze\n",
      "Vote:     -1.0\n",
      "Prior:      0.65\n",
      "Posterior: 1.06\n",
      "P(Vote|Dem): 0.946\n",
      "P(Vote): 0.583\n",
      "P(Dem|Vote): 1.06\n",
      "\n",
      "Issue: el-salvador-aid\n",
      "Vote:     -1.0\n",
      "Prior:      1.06\n",
      "Posterior: 1.67\n",
      "P(Vote|Dem): 0.784\n",
      "P(Vote): 0.495\n",
      "P(Dem|Vote): 1.67\n",
      "\n",
      "Issue: religious-groups-in-schools\n",
      "Vote:      1.0\n",
      "Prior:      1.67\n",
      "Posterior: 1.24\n",
      "P(Vote|Dem): 0.477\n",
      "P(Vote): 0.642\n",
      "P(Dem|Vote): 1.24\n",
      "\n",
      "Issue: anti-satellite-test-ban\n",
      "Vote:      1.0\n",
      "Prior:      1.24\n",
      "Posterior: 1.69\n",
      "P(Vote|Dem): 0.772\n",
      "P(Vote): 0.568\n",
      "P(Dem|Vote): 1.69\n",
      "\n",
      "Issue: aid-to-nicaraguan-contras\n",
      "Vote:      1.0\n",
      "Prior:      1.69\n",
      "Posterior: 2.43\n",
      "P(Vote|Dem): 0.829\n",
      "P(Vote): 0.576\n",
      "P(Dem|Vote): 2.43\n",
      "\n",
      "Issue: mx-missile\n",
      "Vote:      1.0\n",
      "Prior:      2.43\n",
      "Posterior: 3.68\n",
      "P(Vote|Dem): 0.758\n",
      "P(Vote): 0.501\n",
      "P(Dem|Vote): 3.68\n",
      "\n",
      "Issue: immigration\n",
      "Vote:      1.0\n",
      "Prior:      3.68\n",
      "Posterior: 3.43\n",
      "P(Vote|Dem): 0.471\n",
      "P(Vote): 0.505\n",
      "P(Dem|Vote): 3.43\n",
      "\n",
      "Issue: synfuels-corporation-cutback\n",
      "Vote:     -1.0\n",
      "Prior:      3.43\n",
      "Posterior: 2.66\n",
      "P(Vote|Dem): 0.494\n",
      "P(Vote): 0.638\n",
      "P(Dem|Vote): 2.66\n",
      "\n",
      "Issue: education-spending\n",
      "Vote:      1.0\n",
      "Prior:      2.66\n",
      "Posterior: 0.909\n",
      "P(Vote|Dem): 0.145\n",
      "P(Vote): 0.423\n",
      "P(Dem|Vote): 0.909\n",
      "\n",
      "Issue: superfund-right-to-sue\n",
      "Vote:     -1.0\n",
      "Prior:     0.909\n",
      "Posterior: 1.32\n",
      "P(Vote|Dem): 0.71\n",
      "P(Vote): 0.49\n",
      "P(Dem|Vote): 1.32\n",
      "\n",
      "Issue: crime\n",
      "Vote:      1.0\n",
      "Prior:      1.32\n",
      "Posterior: 0.777\n",
      "P(Vote|Dem): 0.35\n",
      "P(Vote): 0.593\n",
      "P(Dem|Vote): 0.777\n",
      "\n",
      "Issue: duty-free-exports\n",
      "Vote:      1.0\n",
      "Prior:     0.777\n",
      "Posterior: 1.16\n",
      "P(Vote|Dem): 0.637\n",
      "P(Vote): 0.428\n",
      "P(Dem|Vote): 1.16\n"
     ]
    }
   ],
   "source": [
    "# Starting with this person's voting record\n",
    "prior = prob_dem\n",
    "\n",
    "votes = roster.loc[234][1:].dropna() # voting record for this particular candidate.\n",
    "# issues is the list of issues, defined earlier\n",
    "\n",
    "for issue, vote in zip(issues, votes):\n",
    "    posterior = dem_given_vote(prior, issue, vote)\n",
    "    \n",
    "    print('\\nIssue: {}'.format(issue))\n",
    "    print('Vote: {:8}'.format(vote))\n",
    "    print('Prior: {:9.3}'.format(prior))\n",
    "    print('Posterior: {:.3}'.format(posterior))\n",
    "    print('P(Vote|Dem): {:.3}'.format(prob_vote_given_dem(issue, vote)))\n",
    "    print('P(Vote): {:.3}'.format(prob_vote(issue, vote)))\n",
    "    print('P(Dem|Vote): {:.3}'.format(dem_given_vote(prior, issue, vote)))\n",
    "    prior = posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the hell.  Some of these posteriors go past 1.  How does that happen? I suspect that I've been working with the wrong form of the equation.  I should probably have been using odds ratios.  Let's do that now.\n",
    "\n",
    "$posterior\\:odds = K*prior\\:odds$\n",
    "\n",
    "or, alternatively\n",
    "\n",
    "$\\dfrac{P(Dem|Vote)}{P(Rep|Vote)} = K* \\dfrac{P(Dem)}{P(Rep)}$\n",
    "\n",
    "and\n",
    "\n",
    "$K = \\dfrac{P(Vote|Dem)}{P(Vote|Rep)}$\n",
    "\n",
    "Note that we can continue to update based on K after we learn from each new vote.  What changes is the prior, which will start with just the relative proportions of Dems and Reps in congress but will change as we learn more about this particular candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5892857142857144"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(Dem)\n",
    "prob_dem = len(dems)/len(roster)\n",
    "\n",
    "# P(Rep)\n",
    "prob_rep = len(reps)/len(roster)\n",
    "\n",
    "initial_prior_odds = prob_dem / prob_rep\n",
    "initial_prior_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(Vote|Dem)\n",
    "def prob_vote_given_dem(issue, vote):\n",
    "    \"\"\"\n",
    "    Calculates the probability that a democrat voted a given way for a given issue. \n",
    "    Vote should be -1 for no, 1 for yes. Note that here we're only considering\n",
    "    yes and no votes; we ignore all the NaNs.\n",
    "    \"\"\"\n",
    "    dem_votes = len(dems[dems[issue] == vote]) # Dems who voted that way\n",
    "    dem_opposite_votes = len(dems[dems[issue] == -vote]) # Dems that voted the opposite\n",
    "    \n",
    "    return dem_votes / (dem_votes + dem_opposite_votes) \n",
    "\n",
    "# P(Vote|Rep)\n",
    "def prob_vote_given_rep(issue, vote):\n",
    "    \"\"\"\n",
    "    Calculates the probability that a Republican voted a given way for a given issue. \n",
    "    Vote should be -1 for no, 1 for yes. Note that here we're only considering\n",
    "    yes and no votes; we ignore all the NaNs.\n",
    "    \"\"\"\n",
    "    rep_votes = len(reps[reps[issue] == vote]) # reps who voted that way\n",
    "    rep_opposite_votes = len(reps[reps[issue] == -vote]) # reps that voted the opposite\n",
    "    \n",
    "    return rep_votes / (rep_votes + rep_opposite_votes) \n",
    "\n",
    "# K = P(Vote|Dem) / P(Vote|Rep)\n",
    "# posterior odds = K * prior odds\n",
    "\n",
    "def update_based_on_K(prior_odds, issue, vote):\n",
    "    \"\"\"\n",
    "    Updates our odds ratio (P(Dem)/P(Rep)) by considering the weight of new evidence.\n",
    "    \n",
    "    Inputs:\n",
    "    prior_odds (float) - prior odds ratio, based on all pre-existing knowledge\n",
    "    issue (string) - one of the issues in the DataFrame roster\n",
    "    vote (0 or 1) - Their vote; -1 for no, 1 for yes.\n",
    "    \n",
    "    Returns:\n",
    "    Updated odds ratio, the posterior_odds\n",
    "    \"\"\"\n",
    "    posterior_odds = prior_odds * prob_vote_given_dem(issue, vote) / prob_vote_given_rep(issue, vote)\n",
    "    \n",
    "    return posterior_odds\n",
    "\n",
    "def print_final_odds_ratio(roster_index):\n",
    "    \"\"\"\n",
    "    For a given congressperson, prints out the odds ration and what it should tend towards.\n",
    "    This function prints only the final odds ratio.\n",
    "    \"\"\"\n",
    "    votes = roster.loc[roster_index][1:].dropna() # voting record for this particular candidate.\n",
    "    # issues is the list of issues, defined earlier\n",
    "\n",
    "    # Initialize the odds based on the composition of the senate, our starting point.\n",
    "    prior_odds = initial_prior_odds = prob_dem / prob_rep\n",
    "\n",
    "    # Header\n",
    "    party = roster.loc[roster_index][0]\n",
    "    print('\\nCandidate #{}, {}'.format(random_candidate, party))\n",
    "    print('Odds ratio should tend towards {}'.format('0' if party == 'republican' else 'infinity'))\n",
    "\n",
    "    for issue, vote in zip(issues, votes):\n",
    "        posterior_odds = update_based_on_K(prior_odds, issue, vote)\n",
    "\n",
    "        # These lines are run only in print_all_odds_ratio_updates\n",
    "    #     print('\\nIssue: {}'.format(issue))\n",
    "    #     print('Vote: {:8}'.format(vote))\n",
    "    #     print('Prior odds ratio: {:9.3}'.format(prior_odds))\n",
    "    #     print('Posterior odds ratio: {:.3}'.format(posterior_odds))\n",
    "        prior_odds = posterior_odds\n",
    "\n",
    "    print('Final odds ratio: {}'.format(posterior_odds))\n",
    "    \n",
    "    \n",
    "def print_all_odds_ratio_updates(roster_index):\n",
    "    \"\"\"\n",
    "    Exactly ike print_final_odds_ratio, but it prints internal steps so you can see \n",
    "    each individual update\n",
    "    \"\"\"\n",
    "    votes = roster.loc[roster_index][1:].dropna() # voting record for this particular candidate.\n",
    "    # issues is the list of issues, defined earlier\n",
    "\n",
    "    # Initialize the odds based on the composition of the senate, our starting point.\n",
    "    prior_odds = initial_prior_odds = prob_dem / prob_rep\n",
    "\n",
    "    # Header\n",
    "    party = roster.loc[roster_index][0]\n",
    "    print('\\nCandidate #{}, {}'.format(random_candidate, party))\n",
    "    print('Odds ratio should tend towards {}'.format('0' if party == 'republican' else 'infinity'))\n",
    "\n",
    "    for issue, vote in zip(issues, votes):\n",
    "        posterior_odds = update_based_on_K(prior_odds, issue, vote)\n",
    "\n",
    "        # These lines were used for debugging\n",
    "        print('\\nIssue: {}'.format(issue))\n",
    "        print('Vote: {:8}'.format(vote))\n",
    "        print('Prior odds ratio: {:9.3}'.format(prior_odds))\n",
    "        print('Posterior odds ratio: {:.3}'.format(posterior_odds))\n",
    "        prior_odds = posterior_odds\n",
    "\n",
    "    print('\\nFinal odds ratio: {}'.format(posterior_odds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, finally, we can evaluate the voting record of arbitrary candidates. Let's start with one random candidate and see how each update pushes us more towards certainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate #119, republican\n",
      "Odds ratio should tend towards 0\n",
      "\n",
      "Issue: handicapped-infants\n",
      "Vote:     -1.0\n",
      "Prior odds ratio:      1.59\n",
      "Posterior odds ratio: 0.774\n",
      "\n",
      "Issue: water-project-cost-sharing\n",
      "Vote:     -1.0\n",
      "Prior odds ratio:     0.774\n",
      "Posterior odds ratio: 0.781\n",
      "\n",
      "Issue: adoption-of-the-budget-resolution\n",
      "Vote:     -1.0\n",
      "Prior odds ratio:     0.781\n",
      "Posterior odds ratio: 0.101\n",
      "\n",
      "Issue: physician-fee-freeze\n",
      "Vote:      1.0\n",
      "Prior odds ratio:     0.101\n",
      "Posterior odds ratio: 0.0055\n",
      "\n",
      "Issue: el-salvador-aid\n",
      "Vote:      1.0\n",
      "Prior odds ratio:    0.0055\n",
      "Posterior odds ratio: 0.00125\n",
      "\n",
      "Issue: religious-groups-in-schools\n",
      "Vote:      1.0\n",
      "Prior odds ratio:   0.00125\n",
      "Posterior odds ratio: 0.000663\n",
      "\n",
      "Issue: anti-satellite-test-ban\n",
      "Vote:     -1.0\n",
      "Prior odds ratio:  0.000663\n",
      "Posterior odds ratio: 0.000199\n",
      "\n",
      "Issue: aid-to-nicaraguan-contras\n",
      "Vote:     -1.0\n",
      "Prior odds ratio:  0.000199\n",
      "Posterior odds ratio: 4.02e-05\n",
      "\n",
      "Issue: mx-missile\n",
      "Vote:     -1.0\n",
      "Prior odds ratio:  4.02e-05\n",
      "Posterior odds ratio: 1.1e-05\n",
      "\n",
      "Issue: immigration\n",
      "Vote:     -1.0\n",
      "Prior odds ratio:   1.1e-05\n",
      "Posterior odds ratio: 1.31e-05\n",
      "\n",
      "Issue: synfuels-corporation-cutback\n",
      "Vote:     -1.0\n",
      "Prior odds ratio:  1.31e-05\n",
      "Posterior odds ratio: 7.47e-06\n",
      "\n",
      "Issue: education-spending\n",
      "Vote:      1.0\n",
      "Prior odds ratio:  7.47e-06\n",
      "Posterior odds ratio: 1.24e-06\n",
      "\n",
      "Issue: superfund-right-to-sue\n",
      "Vote:      1.0\n",
      "Prior odds ratio:  1.24e-06\n",
      "Posterior odds ratio: 4.17e-07\n",
      "\n",
      "Issue: crime\n",
      "Vote:      1.0\n",
      "Prior odds ratio:  4.17e-07\n",
      "Posterior odds ratio: 1.49e-07\n",
      "\n",
      "Issue: duty-free-exports\n",
      "Vote:     -1.0\n",
      "Prior odds ratio:  1.49e-07\n",
      "Posterior odds ratio: 5.93e-08\n",
      "\n",
      "Issue: export-administration-act-south-africa\n",
      "Vote:     -1.0\n",
      "Prior odds ratio:  5.93e-08\n",
      "Posterior odds ratio: 1.12e-08\n",
      "\n",
      " Final odds ratio: 1.1231828723092409e-08\n"
     ]
    }
   ],
   "source": [
    "random_politician = np.random.choice(range(244))\n",
    "\n",
    "print_all_odds_ratio_updates(random_politician)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's run the abridged version of that function for a random sample of 10 candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate #119, republican\n",
      "Odds ratio should tend towards 0\n",
      "Final odds ratio: 8.277705704011084e-08\n",
      "\n",
      "Candidate #119, democrat\n",
      "Odds ratio should tend towards infinity\n",
      "Final odds ratio: 149323900.83007842\n",
      "\n",
      "Candidate #119, republican\n",
      "Odds ratio should tend towards 0\n",
      "Final odds ratio: 2.185538133764586e-05\n",
      "\n",
      "Candidate #119, democrat\n",
      "Odds ratio should tend towards infinity\n",
      "Final odds ratio: 144852673796.17267\n",
      "\n",
      "Candidate #119, republican\n",
      "Odds ratio should tend towards 0\n",
      "Final odds ratio: 1.0108850441273107e-05\n",
      "\n",
      "Candidate #119, democrat\n",
      "Odds ratio should tend towards infinity\n",
      "Final odds ratio: 7.632284770161243\n",
      "\n",
      "Candidate #119, democrat\n",
      "Odds ratio should tend towards infinity\n",
      "Final odds ratio: 11474815183.886442\n",
      "\n",
      "Candidate #119, republican\n",
      "Odds ratio should tend towards 0\n",
      "Final odds ratio: 0.0007754537264390776\n",
      "\n",
      "Candidate #119, republican\n",
      "Odds ratio should tend towards 0\n",
      "Final odds ratio: 157200.35905003446\n",
      "\n",
      "Candidate #119, democrat\n",
      "Odds ratio should tend towards infinity\n",
      "Final odds ratio: 200853997560.9059\n"
     ]
    }
   ],
   "source": [
    "bunch_of_politicians = np.random.choice(range(244), size=10)\n",
    "\n",
    "for i in bunch_of_politicians:\n",
    "    print_final_odds_ratio(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, finally, the odds ratios are updating as I hoped!  Success!!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "LS DS 143 Introduction to Bayesian Inference.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
