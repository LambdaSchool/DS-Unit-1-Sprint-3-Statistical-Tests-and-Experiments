{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS3_143_Introduction_to_Bayesian_Inference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nolanole/DS-Unit-1-Sprint-4-Statistical-Tests-and-Experiments/blob/master/LS_DS3_143_Introduction_to_Bayesian_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "H7OLbevlbd_Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Lambda School Data Science Module 143\n",
        "\n",
        "## Introduction to Bayesian Inference\n",
        "\n",
        "!['Detector! What would the Bayesian statistician say if I asked him whether the--' [roll] 'I AM A NEUTRINO DETECTOR, NOT A LABYRINTH GUARD. SERIOUSLY, DID YOUR BRAIN FALL OUT?' [roll] '... yes.'](https://imgs.xkcd.com/comics/frequentists_vs_bayesians.png)\n",
        "\n",
        "*[XKCD 1132](https://www.xkcd.com/1132/)*\n"
      ]
    },
    {
      "metadata": {
        "id": "3mz8p08BsN6p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Prepare - Bayes' Theorem and the Bayesian mindset"
      ]
    },
    {
      "metadata": {
        "id": "GhycNr-Sbeie",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Bayes' theorem possesses a near-mythical quality - a bit of math that somehow magically evaluates a situation. But this mythicalness has more to do with its reputation and advanced applications than the actual core of it - deriving it is actually remarkably straightforward.\n",
        "\n",
        "### The Law of Total Probability\n",
        "\n",
        "By definition, the total probability of all outcomes (events) if some variable (event space) $A$ is 1. That is:\n",
        "\n",
        "$$P(A) = \\sum_n P(A_n) = 1$$\n",
        "\n",
        "The law of total probability takes this further, considering two variables ($A$ and $B$) and relating their marginal probabilities (their likelihoods considered independently, without reference to one another) and their conditional probabilities (their likelihoods considered jointly). A marginal probability is simply notated as e.g. $P(A)$, while a conditional probability is notated $P(A|B)$, which reads \"probability of $A$ *given* $B$\".\n",
        "\n",
        "The law of total probability states:\n",
        "\n",
        "$$P(A) = \\sum_n P(A | B_n) P(B_n)$$\n",
        "\n",
        "In words - the total probability of $A$ is equal to the sum of the conditional probability of $A$ on any given event $B_n$ times the probability of that event $B_n$, and summed over all possible events in $B$.\n",
        "\n",
        "### The Law of Conditional Probability\n",
        "\n",
        "What's the probability of something conditioned on something else? To determine this we have to go back to set theory and think about the intersection of sets:\n",
        "\n",
        "The formula for actual calculation:\n",
        "\n",
        "$$P(A|B) = \\frac{P(A \\cap B)}{P(B)}$$\n",
        "\n",
        "![Visualization of set intersection](https://upload.wikimedia.org/wikipedia/commons/9/99/Venn0001.svg)\n",
        "\n",
        "Think of the overall rectangle as the whole probability space, $A$ as the left circle, $B$ as the right circle, and their intersection as the red area. Try to visualize the ratio being described in the above formula, and how it is different from just the $P(A)$ (not conditioned on $B$).\n",
        "\n",
        "We can see how this relates back to the law of total probability - multiply both sides by $P(B)$ and you get $P(A|B)P(B) = P(A \\cap B)$ - replaced back into the law of total probability we get $P(A) = \\sum_n P(A \\cap B_n)$.\n",
        "\n",
        "This may not seem like an improvement at first, but try to relate it back to the above picture - if you think of sets as physical objects, we're saying that the total probability of $A$ given $B$ is all the little pieces of it intersected with $B$, added together. The conditional probability is then just that again, but divided by the probability of $B$ itself happening in the first place.\n",
        "\n",
        "### Bayes Theorem\n",
        "\n",
        "![Baye's Theorem with Labels](https://www.probabilisticworld.com/wp-content/uploads/2016/06/bayes-theorem-with-description-2.png)\n",
        "\n",
        "Here is is, the seemingly magic tool:\n",
        "\n",
        "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
        "\n",
        "In words - the probability of $A$ conditioned on $B$ is the probability of $B$ conditioned on $A$, times the probability of $A$ and divided by the probability of $B$. These unconditioned probabilities are referred to as \"prior beliefs\", and the conditioned probabilities as \"updated.\"\n",
        "\n",
        "Why is this important? Scroll back up to the XKCD example - the Bayesian statistician draws a less absurd conclusion because their prior belief in the likelihood that the sun will go nova is extremely low. So, even when updated based on evidence from a detector that is $35/36 = 0.972$ accurate, the prior belief doesn't shift enough to change their overall opinion.\n",
        "\n",
        "There's many examples of Bayes' theorem - one less absurd example is to apply to [breathalyzer tests](https://www.bayestheorem.net/breathalyzer-example/). You may think that a breathalyzer test that is 100% accurate for true positives (detecting somebody who is drunk) is pretty good, but what if it also has 8% false positives (indicating somebody is drunk when they're not)? And furthermore, the rate of drunk driving (and thus our prior belief)  is 1/1000.\n",
        "\n",
        "What is the likelihood somebody really is drunk if they test positive? Some may guess it's 92% - the difference between the true positives and the false positives. But we have a prior belief of the background/true rate of drunk driving. Sounds like a job for Bayes' theorem!\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "P(Drunk | Positive) &= \\frac{P(Positive | Drunk)P(Drunk)}{P(Positive)} \\\\\n",
        "&= \\frac{1 \\times 0.001}{0.08} \\\\\n",
        "&= 0.0125\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "In other words, the likelihood that somebody is drunk given they tested positive with a breathalyzer in this situation is only 1.25% - probably much lower than you'd guess. This is why, in practice, it's important to have a repeated test to confirm (the probability of two false positives in a row is $0.08 * 0.08 = 0.0064$, much lower), and Bayes' theorem has been relevant in court cases where proper consideration of evidence was important."
      ]
    },
    {
      "metadata": {
        "id": "9nXGvtPQPnsM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Derive Baye's Rule\n",
        "\n",
        "\\begin{align}\n",
        "P(A|B) &= \\frac{P(A \\cap B)}{P(B)}\\\\\n",
        "\\Rightarrow P(A|B)P(B) &= P(A \\cap B)\\\\\n",
        "P(B|A) &= \\frac{P(B \\cap A)}{P(A)}\\\\\n",
        "\\Rightarrow P(B|A)P(A) &= P(B \\cap A)\\\\\n",
        "\\Rightarrow P(A|B)P(B) &= P(B|A)P(A) \\\\\n",
        "P(A \\cap B) &= P(B \\cap A)\\\\\n",
        "P(A|B) &= \\frac{P(B|A) \\times P(A)}{P(B)}\n",
        "\\end{align}"
      ]
    },
    {
      "metadata": {
        "id": "htI3DGvDsRJF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Live Lecture - Deriving Bayes' Theorem, Calculating Bayesian Confidence"
      ]
    },
    {
      "metadata": {
        "id": "moIJNQ-nbfe_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice that $P(A|B)$ appears in the above laws - in Bayesian terms, this is the belief in $A$ updated for the evidence $B$. So all we need to do is solve for this term to derive Bayes' theorem. Let's do it together!"
      ]
    },
    {
      "metadata": {
        "id": "ke-5EqJI0Tsn",
        "colab_type": "code",
        "outputId": "fac5ddb8-7e57-459b-de2a-3ca8239f0323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Activity 2 - Use SciPy to calculate Bayesian confidence intervals\n",
        "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bayes_mvs.html#scipy.stats.bayes_mvs\n",
        "\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(seed=42)\n",
        "\n",
        "coinflips = np.random.binomial(n=1, p=.5, size=100)\n",
        "print(coinflips)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 1 1 0 1 0 0 1 1 1 0\n",
            " 0 1 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 1\n",
            " 1 1 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 1 1 1 1 0 1 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "M3uEoarwS078",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def confidence_interval(data, confidence=.95):\n",
        "  n = len(data)\n",
        "  mean = sum(data)/n\n",
        "  data = np.array(data)\n",
        "  stderr = stats.sem(data)\n",
        "  interval = stderr * stats.t.ppf((1 + confidence) / 2.0, n-1)\n",
        "  return (mean , mean-interval, mean+interval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YO_gus1vUjFy",
        "colab_type": "code",
        "outputId": "c242ea5b-3ddf-4b0e-e7ec-451b62db6dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "confidence_interval(coinflips)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.47, 0.3704689875017368, 0.5695310124982632)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "nl8s32H5U84O",
        "colab_type": "code",
        "outputId": "b94ffacc-dd54-449c-c866-b6205f485b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1496
        }
      },
      "cell_type": "code",
      "source": [
        "help(stats.bayes_mvs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function bayes_mvs in module scipy.stats.morestats:\n",
            "\n",
            "bayes_mvs(data, alpha=0.9)\n",
            "    Bayesian confidence intervals for the mean, var, and std.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    data : array_like\n",
            "        Input data, if multi-dimensional it is flattened to 1-D by `bayes_mvs`.\n",
            "        Requires 2 or more data points.\n",
            "    alpha : float, optional\n",
            "        Probability that the returned confidence interval contains\n",
            "        the true parameter.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    mean_cntr, var_cntr, std_cntr : tuple\n",
            "        The three results are for the mean, variance and standard deviation,\n",
            "        respectively.  Each result is a tuple of the form::\n",
            "    \n",
            "            (center, (lower, upper))\n",
            "    \n",
            "        with `center` the mean of the conditional pdf of the value given the\n",
            "        data, and `(lower, upper)` a confidence interval, centered on the\n",
            "        median, containing the estimate to a probability ``alpha``.\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    mvsdist\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    Each tuple of mean, variance, and standard deviation estimates represent\n",
            "    the (center, (lower, upper)) with center the mean of the conditional pdf\n",
            "    of the value given the data and (lower, upper) is a confidence interval\n",
            "    centered on the median, containing the estimate to a probability\n",
            "    ``alpha``.\n",
            "    \n",
            "    Converts data to 1-D and assumes all data has the same mean and variance.\n",
            "    Uses Jeffrey's prior for variance and std.\n",
            "    \n",
            "    Equivalent to ``tuple((x.mean(), x.interval(alpha)) for x in mvsdist(dat))``\n",
            "    \n",
            "    References\n",
            "    ----------\n",
            "    T.E. Oliphant, \"A Bayesian perspective on estimating mean, variance, and\n",
            "    standard-deviation from data\", http://scholarsarchive.byu.edu/facpub/278,\n",
            "    2006.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    First a basic example to demonstrate the outputs:\n",
            "    \n",
            "    >>> from scipy import stats\n",
            "    >>> data = [6, 9, 12, 7, 8, 8, 13]\n",
            "    >>> mean, var, std = stats.bayes_mvs(data)\n",
            "    >>> mean\n",
            "    Mean(statistic=9.0, minmax=(7.103650222612533, 10.896349777387467))\n",
            "    >>> var\n",
            "    Variance(statistic=10.0, minmax=(3.176724206..., 24.45910382...))\n",
            "    >>> std\n",
            "    Std_dev(statistic=2.9724954732045084, minmax=(1.7823367265645143, 4.945614605014631))\n",
            "    \n",
            "    Now we generate some normally distributed random data, and get estimates of\n",
            "    mean and standard deviation with 95% confidence intervals for those\n",
            "    estimates:\n",
            "    \n",
            "    >>> n_samples = 100000\n",
            "    >>> data = stats.norm.rvs(size=n_samples)\n",
            "    >>> res_mean, res_var, res_std = stats.bayes_mvs(data, alpha=0.95)\n",
            "    \n",
            "    >>> import matplotlib.pyplot as plt\n",
            "    >>> fig = plt.figure()\n",
            "    >>> ax = fig.add_subplot(111)\n",
            "    >>> ax.hist(data, bins=100, density=True, label='Histogram of data')\n",
            "    >>> ax.vlines(res_mean.statistic, 0, 0.5, colors='r', label='Estimated mean')\n",
            "    >>> ax.axvspan(res_mean.minmax[0],res_mean.minmax[1], facecolor='r',\n",
            "    ...            alpha=0.2, label=r'Estimated mean (95% limits)')\n",
            "    >>> ax.vlines(res_std.statistic, 0, 0.5, colors='g', label='Estimated scale')\n",
            "    >>> ax.axvspan(res_std.minmax[0],res_std.minmax[1], facecolor='g', alpha=0.2,\n",
            "    ...            label=r'Estimated scale (95% limits)')\n",
            "    \n",
            "    >>> ax.legend(fontsize=10)\n",
            "    >>> ax.set_xlim([-4, 4])\n",
            "    >>> ax.set_ylim([0, 0.5])\n",
            "    >>> plt.show()\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W7_B5LBmVOvL",
        "colab_type": "code",
        "outputId": "29514271-eab3-4919-aea5-d3da0e255945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#0.37046898750173674\n",
        "#0.3704689875017368\n",
        "\n",
        "stats.bayes_mvs(coinflips, alpha=.95)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Mean(statistic=0.47, minmax=(0.37046898750173674, 0.5695310124982632)),\n",
              " Variance(statistic=0.25680412371134015, minmax=(0.1939698977025208, 0.3395533426586547)),\n",
              " Std_dev(statistic=0.5054540733507159, minmax=(0.44042013771229943, 0.5827120581030176)))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "qdXcYoYWXg4K",
        "colab_type": "code",
        "outputId": "ffb741ad-9563-42f4-c672-dc0a2d255126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "coinflips_mean_dist, _, _ = stats.mvsdist(coinflips)\n",
        "coinflips_mean_dist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<scipy.stats._distn_infrastructure.rv_frozen at 0x7f6cae48a908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "mhevBBrHXsmj",
        "colab_type": "code",
        "outputId": "2be755b0-e435-4b53-ab3a-c2948ec51828",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "help(coinflips_mean_dist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on rv_frozen in module scipy.stats._distn_infrastructure object:\n",
            "\n",
            "class rv_frozen(builtins.object)\n",
            " |  # Frozen RV class\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, dist, *args, **kwds)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  cdf(self, x)\n",
            " |  \n",
            " |  entropy(self)\n",
            " |  \n",
            " |  expect(self, func=None, lb=None, ub=None, conditional=False, **kwds)\n",
            " |  \n",
            " |  interval(self, alpha)\n",
            " |  \n",
            " |  isf(self, q)\n",
            " |  \n",
            " |  logcdf(self, x)\n",
            " |  \n",
            " |  logpdf(self, x)\n",
            " |  \n",
            " |  logpmf(self, k)\n",
            " |  \n",
            " |  logsf(self, x)\n",
            " |  \n",
            " |  mean(self)\n",
            " |  \n",
            " |  median(self)\n",
            " |  \n",
            " |  moment(self, n)\n",
            " |  \n",
            " |  pdf(self, x)\n",
            " |  \n",
            " |  pmf(self, k)\n",
            " |  \n",
            " |  ppf(self, q)\n",
            " |  \n",
            " |  rvs(self, size=None, random_state=None)\n",
            " |  \n",
            " |  sf(self, x)\n",
            " |  \n",
            " |  stats(self, moments='mv')\n",
            " |  \n",
            " |  std(self)\n",
            " |  \n",
            " |  var(self)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  random_state\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RItX-_WoX8sR",
        "colab_type": "code",
        "outputId": "92438435-47f6-4c0c-ff8a-1a3ac7d15ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "coinflips_mean_dist.rvs(100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.47447628, 0.51541425, 0.54722018, 0.4589882 , 0.51501386,\n",
              "       0.53819192, 0.43382292, 0.53546659, 0.47026173, 0.44967562,\n",
              "       0.4621107 , 0.42691904, 0.37324325, 0.47531437, 0.46052277,\n",
              "       0.48711257, 0.52456771, 0.43332181, 0.49545882, 0.44671454,\n",
              "       0.47520117, 0.47047251, 0.41828918, 0.50159477, 0.42965501,\n",
              "       0.45273383, 0.48045849, 0.45342529, 0.48238344, 0.53966291,\n",
              "       0.48230241, 0.48073422, 0.48553525, 0.47962228, 0.41274185,\n",
              "       0.42892633, 0.5170948 , 0.42678096, 0.42249309, 0.51499109,\n",
              "       0.47059199, 0.39903942, 0.41790336, 0.46406817, 0.42232382,\n",
              "       0.42163269, 0.47848227, 0.48232842, 0.4731858 , 0.51077244,\n",
              "       0.3957508 , 0.48504646, 0.49014295, 0.53252732, 0.45495376,\n",
              "       0.47883978, 0.60393033, 0.4492549 , 0.44797902, 0.54782121,\n",
              "       0.43380002, 0.5760073 , 0.36941266, 0.44467418, 0.4939245 ,\n",
              "       0.45278835, 0.55635162, 0.48695459, 0.39080983, 0.45948606,\n",
              "       0.2941779 , 0.35950718, 0.44805696, 0.4725126 , 0.42218381,\n",
              "       0.45985418, 0.47545393, 0.44317753, 0.46267013, 0.4458753 ,\n",
              "       0.44204707, 0.51334913, 0.50914181, 0.49923748, 0.46895674,\n",
              "       0.43892798, 0.45984946, 0.44984632, 0.53560791, 0.45865723,\n",
              "       0.48646824, 0.55937503, 0.41464303, 0.50701457, 0.46934196,\n",
              "       0.37681534, 0.42748113, 0.49812825, 0.48278895, 0.4964763 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "vxIOroqAYyFE",
        "colab_type": "code",
        "outputId": "9c53d848-6604-4fb2-9071-a72359c55702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(coinflips).describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.470000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.501614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                0\n",
              "count  100.000000\n",
              "mean     0.470000\n",
              "std      0.501614\n",
              "min      0.000000\n",
              "25%      0.000000\n",
              "50%      0.000000\n",
              "75%      1.000000\n",
              "max      1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "P-DzzRk5bf0z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Assignment - Code it up!\n",
        "\n",
        "Most of the above was pure math - now write Python code to reproduce the results! This is purposefully open ended - you'll have to think about how you should represent probabilities and events. You can and should look things up, and as a stretch goal - refactor your code into helpful reusable functions!\n",
        "\n",
        "Specific goals/targets:\n",
        "\n",
        "1. Write a function `def prob_drunk_given_positive(prob_drunk_prior, prob_positive, prob_positive_drunk)` that reproduces the example from lecture, and use it to calculate and visualize a range of situations\n"
      ]
    },
    {
      "metadata": {
        "id": "xpVhZyUnbf7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def prob_drunk_given_positive(prob_drunk_prior, prob_false_positive, prob_true_positive):\n",
        "  return prob_true_positive*prob_drunk_prior/prob_false_positive\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zNbXT2aBztuG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f097e09-62ee-4028-9157-67b059563022"
      },
      "cell_type": "code",
      "source": [
        "prob_drunk_prior = 1/1000\n",
        "prob_false_positive = 8/100\n",
        "prob_true_positive = 1\n",
        "\n",
        "prob_drunk_given_positive(prob_drunk_prior, prob_false_positive, prob_true_positive)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "iQk4ORI70PGJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2. Explore `scipy.stats.bayes_mvs` - read its documentation, and experiment with it on data you've tested in other ways earlier this week\n"
      ]
    },
    {
      "metadata": {
        "id": "xpA7uSy30Yok",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#lets try the congressional voting data- first copy/paste some code from prev assignments:\n",
        "\n",
        "#1) Load and clean the data:\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data'\n",
        "\n",
        "cols = ['party', 'Handicapped Infants', 'Water Project Cost Sharing', 'Budget Resolution', \n",
        "        'Physician Fee Freeze', 'El Salvador Aid', 'Religious Groups in Schools', \n",
        "        'Anti satelite Test Ban', 'Aid to Nicaraguan Contras', 'Mx-Missile', 'Immigration', \n",
        "        'Synfuels Corporation Cutback', 'Education Spending', 'Superfund Right to Sue',\n",
        "        'Crime', 'Duty-Free Exports', 'Export Administration Act S Africa']\n",
        "\n",
        "data = pd.read_csv(url, header=None, names=cols, na_values='?')\n",
        "data = data.replace({'y':1,'n':0})\n",
        "\n",
        "#split into 2 dataframes by party affiliation:\n",
        "\n",
        "rep = data[data['party'] == 'republican']\n",
        "\n",
        "dem = data[data['party'] == 'democrat']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eSjUd7lB4Ghx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "3d843b39-1d14-4a0b-d333-2a0ea2cf5fb8"
      },
      "cell_type": "code",
      "source": [
        "'''Generate confidence intervals for each issue by looping thru the columns and\n",
        "recording the mean, lower bound, and upper bound for 95% confidence level.'''\n",
        "\n",
        "rep_conf_intervals = []\n",
        "dem_conf_intervals = []\n",
        "\n",
        "for col in cols[1:]:\n",
        "  mean, lower_bound, upper_bound = (confidence_interval(rep[col].dropna(), confidence=0.95))\n",
        "  rep_conf_intervals.append([col, mean, lower_bound, upper_bound])\n",
        "\n",
        "for col in cols[1:]:\n",
        "  mean, lower_bound, upper_bound = (confidence_interval(dem[col].dropna(), confidence=0.95))\n",
        "  dem_conf_intervals.append([col, mean, lower_bound, upper_bound])\n",
        "  \n",
        "\n",
        "#convert these into dataframes\n",
        "\n",
        "rep_conf_df = pd.DataFrame(rep_conf_intervals)\n",
        "\n",
        "dem_conf_df = pd.DataFrame(dem_conf_intervals)\n",
        "\n",
        "rep_conf_df = rep_conf_df.rename(columns = {0:'issue', 1:'mean', 2:'lower_bound', 3:'upper_bound'})\n",
        "rep_conf_df['party'] = 'Republican'\n",
        "dem_conf_df = dem_conf_df.rename(columns = {0:'issue', 1:'mean', 2:'lower_bound', 3:'upper_bound'})\n",
        "dem_conf_df['party'] = 'Democrat'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c13186546a40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mconfidence_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mrep_conf_intervals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower_bound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupper_bound\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'confidence_interval' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-qnqh_QT2GTc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stats.bayes_mvs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D1JtahJQ0ZLv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3. Create a visualization comparing the results of a Bayesian approach to a traditional/frequentist approach\n"
      ]
    },
    {
      "metadata": {
        "id": "UEJCJlfv0aPy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HqqRJ6JK0e-3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "4. In your own words, summarize the difference between Bayesian and Frequentist statistics\n",
        "\n",
        "If you're unsure where to start, check out [this blog post of Bayes theorem with Python](https://dataconomy.com/2015/02/introduction-to-bayes-theorem-with-python/) - you could and should create something similar!\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "uy8Lk3c90hmi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YCZjum5j0iK1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Stretch goals:\n",
        "\n",
        "- Apply a Bayesian technique to a problem you previously worked (in an assignment or project work) on from a frequentist (standard) perspective\n",
        "- Check out [PyMC3](https://docs.pymc.io/) (note this goes beyond hypothesis tests into modeling) - read the guides and work through some examples\n",
        "- Take PyMC3 further - see if you can build something with it!"
      ]
    },
    {
      "metadata": {
        "id": "uWgWjp3PQ3Sq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Resources"
      ]
    },
    {
      "metadata": {
        "id": "QRgHqmYIQ9qn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- [Worked example of Bayes rule calculation](https://en.wikipedia.org/wiki/Bayes'_theorem#Examples) (helpful as it fully breaks out the denominator)\n",
        "- [Source code for mvsdist in scipy](https://github.com/scipy/scipy/blob/90534919e139d2a81c24bf08341734ff41a3db12/scipy/stats/morestats.py#L139)"
      ]
    }
  ]
}