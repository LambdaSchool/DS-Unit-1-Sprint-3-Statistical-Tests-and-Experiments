{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_Unit_1_Sprint_Challenge_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unburied/DS-Unit-1-Sprint-3-Statistical-Tests-and-Experiments/blob/master/DS_Unit_1_Sprint_Challenge_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NooAiTdnafkz",
        "colab_type": "text"
      },
      "source": [
        "# Data Science Unit 1 Sprint Challenge 3\n",
        "\n",
        "## Exploring Data, Testing Hypotheses\n",
        "\n",
        "In this sprint challenge you will look at a dataset of people being approved or rejected for credit.\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/Credit+Approval\n",
        "\n",
        "Data Set Information: This file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect confidentiality of the data. This dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values. There are also a few missing values.\n",
        "\n",
        "Attribute Information:\n",
        "- A1: b, a.\n",
        "- A2: continuous.\n",
        "- A3: continuous.\n",
        "- A4: u, y, l, t.\n",
        "- A5: g, p, gg.\n",
        "- A6: c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff.\n",
        "- A7: v, h, bb, j, n, z, dd, ff, o.\n",
        "- A8: continuous.\n",
        "- A9: t, f.\n",
        "- A10: t, f.\n",
        "- A11: continuous.\n",
        "- A12: t, f.\n",
        "- A13: g, p, s.\n",
        "- A14: continuous.\n",
        "- A15: continuous.\n",
        "- A16: +,- (class attribute)\n",
        "\n",
        "Yes, most of that doesn't mean anything. A16 (the class attribute) is the most interesting, as it separates the 307 approved cases from the 383 rejected cases. The remaining variables have been obfuscated for privacy - a challenge you may have to deal with in your data science career.\n",
        "\n",
        "Sprint challenges are evaluated based on satisfactory completion of each part. It is suggested you work through it in order, getting each aspect reasonably working, before trying to deeply explore, iterate, or refine any given step. Once you get to the end, if you want to go back and improve things, go for it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wch6ksCbJtZ",
        "colab_type": "text"
      },
      "source": [
        "## Part 1 - Load and validate the data\n",
        "\n",
        "- Load the data as a `pandas` data frame.\n",
        "- Validate that it has the appropriate number of observations (you can check the raw file, and also read the dataset description from UCI).\n",
        "- UCI says there should be missing data - check, and if necessary change the data so pandas recognizes it as na\n",
        "- Make sure that the loaded features are of the types described above (continuous values should be treated as float), and correct as necessary\n",
        "\n",
        "This is review, but skills that you'll use at the start of any data exploration. Further, you may have to do some investigation to figure out which file to load from - that is part of the puzzle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q79xDLckzibS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5pVJ3LI6GJZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a376fdff-d5dc-43ba-c896-57d4e3a79ec1"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-03 01:20:24--  https://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32218 (31K) [application/x-httpd-php]\n",
            "Saving to: ‘crx.data’\n",
            "\n",
            "\rcrx.data              0%[                    ]       0  --.-KB/s               \rcrx.data            100%[===================>]  31.46K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-06-03 01:20:25 (461 KB/s) - ‘crx.data’ saved [32218/32218]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncWWorZH6GS7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bcb12146-2f6b-495b-ec4b-18f5d7138c92"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Credit+Approval  crx.data  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52cmFUQy6GVK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "3f73b27a-2f26-4a9a-e730-c04f6417512b"
      },
      "source": [
        "!head -5 crx.data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b,30.83,0,u,g,w,v,1.25,t,t,01,f,g,00202,0,+\n",
            "a,58.67,4.46,u,g,q,h,3.04,t,t,06,f,g,00043,560,+\n",
            "a,24.50,0.5,u,g,q,h,1.5,t,f,0,f,g,00280,824,+\n",
            "b,27.83,1.54,u,g,w,v,3.75,t,t,05,t,g,00100,3,+\n",
            "b,20.17,5.625,u,g,w,v,1.71,t,f,0,f,s,00120,0,+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmnb1TcO6GY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns = [f'A{i}' for i in range(1, 17)]\n",
        "\n",
        "df = pd.read_csv('crx.data', names = columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5vXgJUj6GcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5fadd4a3-db82-4612-e5e3-646598860c28"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>A9</th>\n",
              "      <th>A10</th>\n",
              "      <th>A11</th>\n",
              "      <th>A12</th>\n",
              "      <th>A13</th>\n",
              "      <th>A14</th>\n",
              "      <th>A15</th>\n",
              "      <th>A16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>30.83</td>\n",
              "      <td>0.000</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.25</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>1</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00202</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>58.67</td>\n",
              "      <td>4.460</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>3.04</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>6</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00043</td>\n",
              "      <td>560</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>24.50</td>\n",
              "      <td>0.500</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>q</td>\n",
              "      <td>h</td>\n",
              "      <td>1.50</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>g</td>\n",
              "      <td>00280</td>\n",
              "      <td>824</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>b</td>\n",
              "      <td>27.83</td>\n",
              "      <td>1.540</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>3.75</td>\n",
              "      <td>t</td>\n",
              "      <td>t</td>\n",
              "      <td>5</td>\n",
              "      <td>t</td>\n",
              "      <td>g</td>\n",
              "      <td>00100</td>\n",
              "      <td>3</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>b</td>\n",
              "      <td>20.17</td>\n",
              "      <td>5.625</td>\n",
              "      <td>u</td>\n",
              "      <td>g</td>\n",
              "      <td>w</td>\n",
              "      <td>v</td>\n",
              "      <td>1.71</td>\n",
              "      <td>t</td>\n",
              "      <td>f</td>\n",
              "      <td>0</td>\n",
              "      <td>f</td>\n",
              "      <td>s</td>\n",
              "      <td>00120</td>\n",
              "      <td>0</td>\n",
              "      <td>+</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  A1     A2     A3 A4 A5 A6 A7    A8 A9 A10  A11 A12 A13    A14  A15 A16\n",
              "0  b  30.83  0.000  u  g  w  v  1.25  t   t    1   f   g  00202    0   +\n",
              "1  a  58.67  4.460  u  g  q  h  3.04  t   t    6   f   g  00043  560   +\n",
              "2  a  24.50  0.500  u  g  q  h  1.50  t   f    0   f   g  00280  824   +\n",
              "3  b  27.83  1.540  u  g  w  v  3.75  t   t    5   t   g  00100    3   +\n",
              "4  b  20.17  5.625  u  g  w  v  1.71  t   f    0   f   s  00120    0   +"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMysbxRy6G8I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1d33304-c772-4eea-c93d-73e875d704f3"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(690, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAIvmREf6HH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "d68ae8ed-0ae0-4d73-ab88-be10123672fa"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A3</th>\n",
              "      <th>A8</th>\n",
              "      <th>A11</th>\n",
              "      <th>A15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>690.000000</td>\n",
              "      <td>690.000000</td>\n",
              "      <td>690.00000</td>\n",
              "      <td>690.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.758725</td>\n",
              "      <td>2.223406</td>\n",
              "      <td>2.40000</td>\n",
              "      <td>1017.385507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.978163</td>\n",
              "      <td>3.346513</td>\n",
              "      <td>4.86294</td>\n",
              "      <td>5210.102598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.165000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.207500</td>\n",
              "      <td>2.625000</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>395.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>28.500000</td>\n",
              "      <td>67.00000</td>\n",
              "      <td>100000.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               A3          A8        A11            A15\n",
              "count  690.000000  690.000000  690.00000     690.000000\n",
              "mean     4.758725    2.223406    2.40000    1017.385507\n",
              "std      4.978163    3.346513    4.86294    5210.102598\n",
              "min      0.000000    0.000000    0.00000       0.000000\n",
              "25%      1.000000    0.165000    0.00000       0.000000\n",
              "50%      2.750000    1.000000    0.00000       5.000000\n",
              "75%      7.207500    2.625000    3.00000     395.500000\n",
              "max     28.000000   28.500000   67.00000  100000.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbgaSvVb9NQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "b159fc64-91f2-4880-ce34-ff7bb77241af"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A1      object\n",
              "A2      object\n",
              "A3     float64\n",
              "A4      object\n",
              "A5      object\n",
              "A6      object\n",
              "A7      object\n",
              "A8     float64\n",
              "A9      object\n",
              "A10     object\n",
              "A11      int64\n",
              "A12     object\n",
              "A13     object\n",
              "A14     object\n",
              "A15      int64\n",
              "A16     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFTCtZ-L9NZm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2789aeea-89cc-47ca-c9aa-d7b829b5f0e0"
      },
      "source": [
        "#replace all ? with NA values\n",
        "#in hindsight couldve used df.replace \n",
        "\n",
        "for col in columns:\n",
        "  df[col] = np.where(df[col] == '?', np.NaN, df[col])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  result = method(y)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWPU5mQS9NbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#corrected data types per documentation \n",
        "\n",
        "df['A2'] = df.A2.astype('float')\n",
        "df['A14'] = df.A14.astype('float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7csCMbx9NgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "5419a5bc-6d4a-4fad-f979-b49f06f7398e"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A1      object\n",
              "A2     float64\n",
              "A3     float64\n",
              "A4      object\n",
              "A5      object\n",
              "A6      object\n",
              "A7      object\n",
              "A8     float64\n",
              "A9      object\n",
              "A10     object\n",
              "A11    float64\n",
              "A12     object\n",
              "A13     object\n",
              "A14    float64\n",
              "A15    float64\n",
              "A16     object\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stHADvyE9NjV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "886565c6-9813-4f1e-c810-ad67f2a19139"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "A1     12\n",
              "A2     12\n",
              "A3      0\n",
              "A4      6\n",
              "A5      6\n",
              "A6      9\n",
              "A7      9\n",
              "A8      0\n",
              "A9      0\n",
              "A10     0\n",
              "A11     0\n",
              "A12     0\n",
              "A13     0\n",
              "A14    13\n",
              "A15     0\n",
              "A16     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7rLytbrO38L",
        "colab_type": "text"
      },
      "source": [
        "## Part 2 - Exploring data, Testing hypotheses\n",
        "\n",
        "The only thing we really know about this data is that A16 is the class label. Besides that, we have 6 continuous (float) features and 9 categorical features.\n",
        "\n",
        "Explore the data: you can use whatever approach (tables, utility functions, visualizations) to get an impression of the distributions and relationships of the variables. In general, your goal is to understand how the features are different when grouped by the two class labels (`+` and `-`).\n",
        "\n",
        "For the 6 continuous features, how are they different when split between the two class labels? Choose two features to run t-tests (again split by class label) - specifically, select one feature that is *extremely* different between the classes, and another feature that is notably less different (though perhaps still \"statistically significantly\" different). You may have to explore more than two features to do this.\n",
        "\n",
        "For the categorical features, explore by creating \"cross tabs\" (aka [contingency tables](https://en.wikipedia.org/wiki/Contingency_table)) between them and the class label, and apply the Chi-squared test to them. [pandas.crosstab](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html) can create contingency tables, and [scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) can calculate the Chi-squared statistic for them.\n",
        "\n",
        "There are 9 categorical features - as with the t-test, try to find one where the Chi-squared test returns an extreme result (rejecting the null that the data are independent), and one where it is less extreme.\n",
        "\n",
        "**NOTE** - \"less extreme\" just means smaller test statistic/larger p-value. Even the least extreme differences may be strongly statistically significant.\n",
        "\n",
        "Your *main* goal is the hypothesis tests, so don't spend too much time on the exploration/visualization piece. That is just a means to an end - use simple visualizations, such as boxplots or a scatter matrix (both built in to pandas), to get a feel for the overall distribution of the variables.\n",
        "\n",
        "This is challenging, so manage your time and aim for a baseline of at least running two t-tests and two Chi-squared tests before polishing. And don't forget to answer the questions in part 3, even if your results in this part aren't what you want them to be."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl2ARRxEDgSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWqu33UqARA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "approved = df[df.A16 == '+']\n",
        "denied = df[df.A16 == '-']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8_gXyu7ARIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.pairplot(approved, kind = 'reg');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3slArsX3ARJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.pairplot(denied, kind = 'reg');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtbjVAwCAROm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "approved.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckKvq109ARSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "denied.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCcOuSKNART4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91386f6e-ee2b-4b0c-9f43-255cf98c5094"
      },
      "source": [
        "stats.ttest_ind(approved.A11, denied.A11, equal_var = False, nan_policy = 'omit')\n",
        "#Reject null hypothesis that the mean of Approved column A11 is equal to Denied column A11\n",
        "#most extreme"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=10.6384190682749, pvalue=4.310254123415665e-23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsd3JtnEARXB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a57a1a5b-f47d-40e6-ee0d-029484753e8a"
      },
      "source": [
        "stats.ttest_ind(approved.A14, denied.A14, equal_var = False, nan_policy = 'omit')\n",
        "#Reject null hypothesis that the mean of Approved column A14 is equal to Denied column A14\n",
        "#least extreme"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=-2.6696493137915973, pvalue=0.0077778250827957)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEjn7xxSARYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test features using chi_squared and determine most and least significant \n",
        "def chi(features):\n",
        "  chi_stats = {}\n",
        "  \n",
        "  #list to use object columns\n",
        "  cols = [col for col in features if df[col].dtype == 'O']\n",
        "  \n",
        "  #initiate chi test for each column and store in dictionary\n",
        "  for column in cols:\n",
        "    table = pd.crosstab(df[column], df.A16) #compare all to class labels\n",
        "    chi, pval, _,_ = stats.chi2_contingency(table)\n",
        "    chi_stats[column] = [chi,pval]\n",
        "  \n",
        "  #del test for A16 against itself\n",
        "  del chi_stats['A16']\n",
        "  \n",
        "  return chi_stats\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6lQY4CtARca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e1043b27-da9b-4bd5-8130-c165467f479e"
      },
      "source": [
        "tests = chi(columns)\n",
        "tests"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'A1': [0.31128326491619945, 0.5768937883001117],\n",
              " 'A10': [143.06956205083145, 5.675727374527571e-33],\n",
              " 'A12': [0.568273300792113, 0.45094587758631943],\n",
              " 'A13': [9.191570451545383, 0.010094291370456362],\n",
              " 'A4': [26.234074966202144, 2.010680204180363e-06],\n",
              " 'A5': [26.234074966202144, 2.010680204180363e-06],\n",
              " 'A6': [98.32520342679135, 3.4999300402715717e-15],\n",
              " 'A7': [45.03420714024056, 3.62545287237226e-07],\n",
              " 'A9': [355.2038167412799, 3.1185900878457007e-79]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM8JckA2bgnp",
        "colab_type": "text"
      },
      "source": [
        "## Part 3 - Analysis and Interpretation\n",
        "\n",
        "Now that you've looked at the data, answer the following questions:\n",
        "\n",
        "- Interpret and explain the two t-tests you ran - what do they tell you about the relationships between the continuous features you selected and the class labels?\n",
        "- Interpret and explain the two Chi-squared tests you ran - what do they tell you about the relationships between the categorical features you selected and the class labels?\n",
        "- What was the most challenging part of this sprint challenge?\n",
        "\n",
        "Answer with text, but feel free to intersperse example code/results or refer to it from earlier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIozLDNG2Uhu",
        "colab_type": "text"
      },
      "source": [
        "####Interpret and explain the two t-tests you ran - what do they tell you about the relationships ####between the continuous features you selected and the class labels?\n",
        "\n",
        "Ttest_indResult(statistic=10.6384190682749, pvalue=4.310254123415665e-23)\n",
        "Reject null hypothesis that the mean of Approved column A11 is equal to Denied column A11\n",
        "\n",
        "This was the most extreme example due to the means being so significantly different. Not only were the means different, but the variance in the approved set was several times larger than the variance of the denied set. Due to the smaller (but not smallest) totals and the large variance, I'm going to infer this columns represents the number of Trade Lines on a credit report. The relationship to the class labels is significant.\n",
        "\n",
        "Ttest_indResult(statistic=-2.6696493137915973, pvalue=0.0077778250827957)\n",
        "Reject null hypothesis that the mean of Approved column A14 is equal to Denied column A14\n",
        "\n",
        "This was the least extreme comparison made among continuous variables involved. This was also one of the only features where the approved set had lower statistical values overall compared to the denied set. I would infer this has something to do with credit utilization. Most likely it is associated with the monthly payments due on current credit accounts. Applicants with better credit tend to pay off debt quicker, which leads to lower monthly payments. The relationship to the class labels is less significant, although still essential. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rATD-S5hVvcP",
        "colab_type": "text"
      },
      "source": [
        "####Interpret and explain the two Chi-squared tests you ran - what do they tell you about the relationships between the categorical features you selected and the class labels?\n",
        "\n",
        "{'A1': [0.31128326491619945, 0.5768937883001117],\n",
        "\n",
        " 'A10': [143.06956205083145, 5.675727374527571e-33],\n",
        " \n",
        " 'A12': [0.568273300792113, 0.45094587758631943],\n",
        " \n",
        " 'A13': [9.191570451545383, 0.010094291370456362],\n",
        " \n",
        " 'A4': [26.234074966202144, 2.010680204180363e-06],\n",
        " \n",
        " 'A5': [26.234074966202144, 2.010680204180363e-06],\n",
        " \n",
        " 'A6': [98.32520342679135, 3.4999300402715717e-15],\n",
        " \n",
        " 'A7': [45.03420714024056, 3.62545287237226e-07],\n",
        " \n",
        " 'A9': [355.2038167412799, 3.1185900878457007e-79]}\n",
        " \n",
        " I thought it was curious that there were 4 binomial features. Of those 4, half were statistically dependant with relation to the class labels.The other 2 features (A1, A12) were the only features were we failed to reject the null hypothesis. Even more interesting is that 3 out of those 4 had the same identifiers 't' and 'f', but 1(A12) was not anywhere near showing significant signs of dependance. All other features showed some level of dependancy with relation to the class labels, with the most significant being A9, one of the four mentioned above. One of the least extreme yet still significant features was A13 with a p-value of 1%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFWHAGNPbK5f",
        "colab_type": "text"
      },
      "source": [
        "####What was the most challenging part of this sprint challenge?\n",
        "\n",
        "The most difficult aspect of this sprint challenge was controlling the urge to explore the data more. I wanted to find concrete expamples and 'solve' the code to find what was hidden. I had to balance that urge with the need to manage my time wisely to ensure I completed each and every task. I did feel a little more comfortable with the concepts involved, but there was still a feeling that I hadn't done the tasks correctly or completely. "
      ]
    }
  ]
}